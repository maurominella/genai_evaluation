{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c784d56-d236-4acb-bbb7-63ae85ef23a6",
   "metadata": {},
   "source": [
    "# Variables, Constants and Libraries definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74ff1473-041f-4802-94e9-a2c27028ac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f34c9140-3264-47d3-8426-fdf36d8fa5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv # requires python-dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider #requires azure-identity\n",
    "from openai import AzureOpenAI\n",
    "import openai, os, json, time, glob, kagglehub # openai is used for error catching, otherwise we use AzureOpenAI\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv(\"./../config/credentials_my.env\")\n",
    "\n",
    "openai_endpoint       = os.environ[\"azure_openai_endpoint\"]\n",
    "openai_api_key        = os.environ[\"azure_openai_api_key\"]\n",
    "openai_api_version    = os.environ[\"openai_api_version\"]\n",
    "azure_deployment_name = os.environ[\"azure_openai_chat_deployment_name\"]\n",
    "\n",
    "credential            = DefaultAzureCredential()\n",
    "\n",
    "token_provider        = get_bearer_token_provider(\n",
    "    DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "folder_path = \"./enrichment\"\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "output_file_name = os.path.join(folder_path, \"questions_enriched\")\n",
    "\n",
    "# Get the current user's home directory\n",
    "home_dir = os.path.expanduser(\"~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda2da8c-5ca6-4a6b-847c-d7faa07f3c8b",
   "metadata": {},
   "source": [
    "# [Single-Topic RAG Evaluation Dataset](https://www.kaggle.com/datasets/samuelmatsuoharris/single-topic-rag-evaluation-dataset) retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a624b79b-c1a1-4fea-b5ba-9a48e1bb3484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\mauromi\\.cache\\kagglehub\\datasets\\samuelmatsuoharris\\single-topic-rag-evaluation-dataset\\versions\\4\n",
      "\n",
      "\n",
      "dataframe #0 <documents>:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>source_url</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://enterthegungeon.fandom.com/wiki/Bullet...</td>\n",
       "      <td>Bullet Kin\\nBullet Kin are one of the most com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.dropbox.com/scl/fi/ljtdg6eaucrbf1a...</td>\n",
       "      <td>---The Paths through the Underground/Underdark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://bytes-and-nibbles.web.app/bytes/stici-...</td>\n",
       "      <td>Semantic and Textual Inference Chatbot Interfa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://github.com/llmware-ai/llmware</td>\n",
       "      <td>llmware\\n\\nBuilding Enterprise RAG Pipelines w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://docs.marimo.io/recipes.html</td>\n",
       "      <td>Recipes\\nThis page includes code snippets or “...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                         source_url  \\\n",
       "0      0  https://enterthegungeon.fandom.com/wiki/Bullet...   \n",
       "1      1  https://www.dropbox.com/scl/fi/ljtdg6eaucrbf1a...   \n",
       "2      2  https://bytes-and-nibbles.web.app/bytes/stici-...   \n",
       "3      3              https://github.com/llmware-ai/llmware   \n",
       "4      4                https://docs.marimo.io/recipes.html   \n",
       "\n",
       "                                                text  \n",
       "0  Bullet Kin\\nBullet Kin are one of the most com...  \n",
       "1  ---The Paths through the Underground/Underdark...  \n",
       "2  Semantic and Textual Inference Chatbot Interfa...  \n",
       "3  llmware\\n\\nBuilding Enterprise RAG Pipelines w...  \n",
       "4  Recipes\\nThis page includes code snippets or “...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "dataframe #1 <multi_passage_answer_questions>:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_index</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Which enemy types wield an AK-47?</td>\n",
       "      <td>Assault-rifle wielding Bullet and Tankers wiel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>What makes jammed enemies different?</td>\n",
       "      <td>Jammed Keybullet Kin drop 2 keys instead of 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>What enemies are encountered in the second enc...</td>\n",
       "      <td>26 kobolds and 1 kobold inventor are encounter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>What monsters are encountered in this journey?</td>\n",
       "      <td>Ropers, kobolds, kobold inventors, fire giants...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>What framework was chosen to execute the RAG p...</td>\n",
       "      <td>The LangChain framework was used to orchestrat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document_index                                           question  \\\n",
       "0               0                  Which enemy types wield an AK-47?   \n",
       "1               0               What makes jammed enemies different?   \n",
       "2               1  What enemies are encountered in the second enc...   \n",
       "3               1     What monsters are encountered in this journey?   \n",
       "4               2  What framework was chosen to execute the RAG p...   \n",
       "\n",
       "                                              answer  \n",
       "0  Assault-rifle wielding Bullet and Tankers wiel...  \n",
       "1  Jammed Keybullet Kin drop 2 keys instead of 1,...  \n",
       "2  26 kobolds and 1 kobold inventor are encounter...  \n",
       "3  Ropers, kobolds, kobold inventors, fire giants...  \n",
       "4  The LangChain framework was used to orchestrat...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "dataframe #2 <no_answer_questions>:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_index</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How much health does the Mutant Bullet Kin have?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Where can bishops be found?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>What happened on day 10?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>What did the goblins say?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Why was the H100 GPU chosen for computation?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document_index                                          question\n",
       "0               0  How much health does the Mutant Bullet Kin have?\n",
       "1               0                       Where can bishops be found?\n",
       "2               1                          What happened on day 10?\n",
       "3               1                         What did the goblins say?\n",
       "4               2      Why was the H100 GPU chosen for computation?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "dataframe #3 <single_passage_answer_questions>:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_index</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What do keybullet kin drop?</td>\n",
       "      <td>Keybullet kin drop a key upon death.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>What kind of gun does the bandana bullet kin use?</td>\n",
       "      <td>The bandana bullet kin wields a machine pistol.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>What do the giants look like?</td>\n",
       "      <td>One giant is burly, grey-skinned, and 20 feet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>What happens on day 2?</td>\n",
       "      <td>After a few miles of winding tunnel, you emerg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>What were the requirements for the project?</td>\n",
       "      <td>The tool had the following requirements:\\n- Ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document_index                                           question  \\\n",
       "0               0                        What do keybullet kin drop?   \n",
       "1               0  What kind of gun does the bandana bullet kin use?   \n",
       "2               1                      What do the giants look like?   \n",
       "3               1                             What happens on day 2?   \n",
       "4               2        What were the requirements for the project?   \n",
       "\n",
       "                                              answer  \n",
       "0               Keybullet kin drop a key upon death.  \n",
       "1    The bandana bullet kin wields a machine pistol.  \n",
       "2  One giant is burly, grey-skinned, and 20 feet ...  \n",
       "3  After a few miles of winding tunnel, you emerg...  \n",
       "4  The tool had the following requirements:\\n- Ch...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the relative path from the home directory for the Kaggle dataset\n",
    "dataset_relative_path = \".cache/kagglehub/datasets/samuelmatsuoharris/single-topic-rag-evaluation-dataset/versions/3\"\n",
    "\n",
    "dataset_path = os.path.join(home_dir, dataset_relative_path)\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    dataset_path = kagglehub.dataset_download(\"samuelmatsuoharris/single-topic-rag-evaluation-dataset\") # Download latest version\n",
    "\n",
    "print(\"Path to dataset files:\", dataset_path)\n",
    "\n",
    "# Find all CSV files in the directory\n",
    "csv_files = glob.glob(os.path.join(dataset_path, \"*.csv\"))\n",
    "\n",
    "# Load each CSV file into a DataFrame and store them in a list\n",
    "dfs = [(os.path.splitext(os.path.basename(file))[0], pd.read_csv(file)) for file in csv_files]\n",
    "i=0\n",
    "for df in dfs:\n",
    "    print(f\"\\n\\ndataframe #{i} <{df[0]}>:\")\n",
    "    display(df[1].head())\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d22e4b8a-c774-4937-94aa-5956fae1cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df      = dfs[0][1] # documents\n",
    "ko_df        = dfs[2][1] # no_answer_questions\n",
    "questions_df = pd.concat([dfs[3][1], dfs[1][1]]) # single_passage_answer_questions + multi_passage_answer_questions\n",
    "docs_df[\"text\"].to_csv(f\"{folder_path}/documents.txt\", index=False, header=False, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43eeeab-4aef-4813-847f-aba21bacda5c",
   "metadata": {},
   "source": [
    "# Open AI client via Azure OpenAI SDK (with Responses API's)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eeefc70-3274-4170-ae4d-01eaec73fb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Making a great pizza involves ...\n"
     ]
    }
   ],
   "source": [
    "client = AzureOpenAI(\n",
    "    azure_ad_token_provider = token_provider,\n",
    "    api_version = openai_api_version)\n",
    "\n",
    "response = client.responses.create(\n",
    "    model = azure_deployment_name,\n",
    "    input=\"how can I make a good pizza?\")\n",
    "\n",
    "print(f\"Response: {response.output_text[:30]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bbad0a-c01b-4906-980b-3737c39bbadc",
   "metadata": {},
   "source": [
    "# Create full evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dda855e5-d80f-4a23-878f-86261ea4cbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_dataset(content: dict) -> dict:\n",
    "\n",
    "    system_message = \"\"\"\n",
    "    given a json dictionary whose keys are \"context\", \"query\", \"ground_truth\", please generate two outputs:\n",
    "    1) \"response_correct\": another correct answer, possibly shorter and simpler, equivalent to the original one but with different words.\n",
    "    2) \"response_wrong\": a wrong answer that is contextualized and may look correct to a person who doesn't know the document well, using the same style as the ground truth and the second truth\n",
    "    \"\"\"\n",
    "\n",
    "    input = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": json.dumps(content)}\n",
    "    ]\n",
    "    \n",
    "    text = {\n",
    "        \"format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"name\": \"enriched_dataset\",\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"response_correct\": {\"type\": \"string\"},\n",
    "                    \"response_wrong\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"response_correct\", \"response_wrong\"],\n",
    "                \"additionalProperties\": False\n",
    "            },\n",
    "            \"strict\": True\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = client.responses.create(\n",
    "        model = azure_deployment_name,\n",
    "        input = input,\n",
    "        text  = text\n",
    "    )\n",
    "\n",
    "    return json.loads(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986e406f-9110-418b-9830-10f1fef9d67a",
   "metadata": {},
   "source": [
    "# Consolidate the source dataframes into a single one called `consolidated_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac2924fe-a42f-4446-8e84-646e737fe470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_index</th>\n",
       "      <th>context</th>\n",
       "      <th>query</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Bullet Kin\\nBullet Kin are one of the most com...</td>\n",
       "      <td>What do keybullet kin drop?</td>\n",
       "      <td>Keybullet kin drop a key upon death.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Bullet Kin\\nBullet Kin are one of the most com...</td>\n",
       "      <td>What kind of gun does the bandana bullet kin use?</td>\n",
       "      <td>The bandana bullet kin wields a machine pistol.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>---The Paths through the Underground/Underdark...</td>\n",
       "      <td>What do the giants look like?</td>\n",
       "      <td>One giant is burly, grey-skinned, and 20 feet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>---The Paths through the Underground/Underdark...</td>\n",
       "      <td>What happens on day 2?</td>\n",
       "      <td>After a few miles of winding tunnel, you emerg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Semantic and Textual Inference Chatbot Interfa...</td>\n",
       "      <td>What were the requirements for the project?</td>\n",
       "      <td>The tool had the following requirements:\\n- Ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document_index                                            context  \\\n",
       "0               0  Bullet Kin\\nBullet Kin are one of the most com...   \n",
       "1               0  Bullet Kin\\nBullet Kin are one of the most com...   \n",
       "2               1  ---The Paths through the Underground/Underdark...   \n",
       "3               1  ---The Paths through the Underground/Underdark...   \n",
       "4               2  Semantic and Textual Inference Chatbot Interfa...   \n",
       "\n",
       "                                               query  \\\n",
       "0                        What do keybullet kin drop?   \n",
       "1  What kind of gun does the bandana bullet kin use?   \n",
       "2                      What do the giants look like?   \n",
       "3                             What happens on day 2?   \n",
       "4        What were the requirements for the project?   \n",
       "\n",
       "                                        ground_truth  \n",
       "0               Keybullet kin drop a key upon death.  \n",
       "1    The bandana bullet kin wields a machine pistol.  \n",
       "2  One giant is burly, grey-skinned, and 20 feet ...  \n",
       "3  After a few miles of winding tunnel, you emerg...  \n",
       "4  The tool had the following requirements:\\n- Ch...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join DataFrames on docs_df.index == multi_df.document_index\n",
    "consolidated_df = questions_df.merge(docs_df, left_on='document_index', right_on='index')\n",
    "\n",
    "# Rename columns\n",
    "consolidated_df = consolidated_df.rename(columns={'text': 'context', 'question': 'query', 'answer': 'ground_truth'})\n",
    "\n",
    "# Drop unwanted columns\n",
    "consolidated_df = consolidated_df.drop(columns=['index', 'source_url'])\n",
    "\n",
    "# Reorder columns\n",
    "consolidated_df = consolidated_df[['document_index', 'context', 'query', 'ground_truth']]\n",
    "\n",
    "consolidated_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a52831-1170-4416-894c-de4e93d2e1cc",
   "metadata": {},
   "source": [
    "# Enrich `consolidated_df` into `enriched_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adc4f741-00cb-48e3-a2b6-cb367a228212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0/79:\n",
      "- second_truth: <Keybullet Kin provide a key when defeated.>\n",
      "- wrong_answer: <Keybullet Kin release multiple bullets as they die.>\n",
      "\n",
      "Index 1/79:\n",
      "- second_truth: <Bandana Bullet Kin use machine pistols.>\n",
      "- wrong_answer: <Bandana Bullet Kin wield revolvers.>\n",
      "\n",
      "Index 2/79:\n",
      "- second_truth: <One giant is robust, with grey skin, standing 20 feet tall. It wears heavy dark armor with metal spikes. It leans against the wall, holding two large spiked shields.\n",
      "\n",
      "The second giant is tall and dressed in lighter iron armor, holding a massive maul. It appears uninterested.>\n",
      "- wrong_answer: <The first giant is sleek, golden-skinned, and 15 feet tall. It wears light leather armor studded with jewels, leaning casually against a chamber wall. It carries a long sword and shield with intricate designs.\n",
      "\n",
      "The second giant is around the same size, adorned in colorful robes, wielding a staff crackling with magic, seemingly curious.>\n",
      "\n",
      "Index 3/79:\n",
      "- second_truth: <You arrive at a damp grotto, unsure of the nearby water source. There, you encounter two ropers as you search for the next Kryn-burrowed entrance.>\n",
      "- wrong_answer: <On day 2, you discover the Kryn tunnels filled with sparkling crystals and uninterrupted tranquility, progressing without encountering any dangers.>\n",
      "\n",
      "Index 4/79:\n",
      "- second_truth: <The project needed a chatbot to answer questions using unstructured text, with no conversational memory. It had to be fast, run efficiently on a MacBook without causing performance problems, and operate locally for privacy and cost-free operation.>\n",
      "- wrong_answer: <The project required a chatbot designed for high-speed processing and cloud-based operation to handle large data sets with conversational memory. It relied on structured text inputs and was intended to operate using external servers for better performance.>\n",
      "\n",
      "Index 5/79:\n",
      "- second_truth: <The prototype was tested using Wikipedia pages of Grace Hopper and Alan Turing.>\n",
      "- wrong_answer: <The prototype testing relied on documents about Ada Lovelace and Charles Babbage from historical archives.>\n",
      "\n",
      "Index 6/79:\n",
      "- second_truth: <Quick start uses SQLite3 and ChromaDB without installation. For larger scale projects, MongoDB and Milvus require setup via Docker Compose. PostgreSQL is used for both text and vector storage and also needs Docker Compose. There are multiple options for varying combinations: three text databases and ten vector databases are supported, including Milvus and Neo4j.>\n",
      "- wrong_answer: <For most applications, you should rely on Oracle and MySQL which are universally accepted across platforms. Alternatively, a single vector database option like ChromaDB offers streamlined integration without needing Docker Compose setups.>\n",
      "\n",
      "Index 7/79:\n",
      "- second_truth: <Support for UTF-8 encoding in European languages was introduced on April 3rd in the v0.2.7 update.>\n",
      "- wrong_answer: <The update for UTF-8 encoding support for European languages was announced on May 12th in the v0.2.13 release.>\n",
      "\n",
      "Index 8/79:\n",
      "- second_truth: <import marimo as mo\n",
      "\n",
      "button = mo.ui.run_button()\n",
      "\n",
      "mo.stop(not button.value, \"Press 'run' to see a random number\")\n",
      "\n",
      "import random\n",
      "random.randint(0, 1000)>\n",
      "- wrong_answer: <import marimo as mo\n",
      "\n",
      "button = mo.ui.toggle_button()\n",
      "\n",
      "mo.stop(button.value, \"Click 'run' to see something fun\")\n",
      "\n",
      "import random\n",
      "return random.choice(['apple', 'banana', 'cherry'])>\n",
      "\n",
      "Index 9/79:\n",
      "- second_truth: <Caching is useful for storing results of costly computations like t-SNE, UMAP, or PyMDE embeddings to speed up workflows.>\n",
      "- wrong_answer: <Caching is useful when you need to store the outputs of UI element interactions to prevent code cells from running unnecessarily.>\n",
      "\n",
      "Index 10/79:\n",
      "- second_truth: <The article focuses on: the importance of prioritizing impact for both managers and individual contributors, the challenges of focusing on impact, strategies to maximize impact, and ways to address obstacles in creating real impact.>\n",
      "- wrong_answer: <The key topics of this article are about learning coding skills, managing data effectively, and collaborating with other teams in a business environment.>\n",
      "\n",
      "Index 11/79:\n",
      "- second_truth: <You can receive recognition for contributing to impactful work, even if you're not solely responsible. For instance, if your analysis leads to a pricing adjustment that saves the company money, you deserve part of the credit.>\n",
      "- wrong_answer: <To be acknowledged, you need to be the sole person responsible for any significant impact. Only then can you truly take credit for the results achieved.>\n",
      "\n",
      "Index 12/79:\n",
      "- second_truth: <Certain AI systems that pose high risks and are used by public authorities must be registered in a public EU database, but those used for law enforcement and migration are kept in a non-public section accessible only to supervisory authorities.>\n",
      "- wrong_answer: <Only law enforcement AI models need to be registered publicly, while others used in migration must remain in the general public database for transparency.>\n",
      "\n",
      "Index 13/79:\n",
      "- second_truth: <General-purpose AI models utilizing over 10^25 FLOPs are deemed to have systemic risks due to their advanced capabilities. The AI Office may adjust this threshold and identify additional models based on factors like user numbers or model autonomy.>\n",
      "- wrong_answer: <AI systems with any kind of machine learning capability, regardless of computing power, are considered to have systemic risks and must be regulated by the AI Office without any threshold changes.>\n",
      "\n",
      "Index 14/79:\n",
      "- second_truth: <The Emperor assigns the quest \"Visit the Emperor's Old Hideout.\">\n",
      "- wrong_answer: <The Emperor offers the quest titled \"Explore the Mind Flayer Territory.\">\n",
      "\n",
      "Index 15/79:\n",
      "- second_truth: <The party is ambushed by the Gish'ra warriors at Wyrm's Lookout.>\n",
      "- wrong_answer: <A group of mind flayers ambushes the party at Wyrm's Lookout on their way to Baldur's Gate.>\n",
      "\n",
      "Index 16/79:\n",
      "- second_truth: <You enjoyed txakoli at the pintxo bars.>\n",
      "- wrong_answer: <You had sangria at the pintxo bars.>\n",
      "\n",
      "Index 17/79:\n",
      "- second_truth: <You loved the four days spent hiking the Camino the most.>\n",
      "- wrong_answer: <You enjoyed your stay in Bilbao the most, exploring the Guggenheim Museum and trying Italian food.>\n",
      "\n",
      "Index 18/79:\n",
      "- second_truth: <The infrared scenes highlight the contrast between the Polish family and those who support Nazi ideals. It signifies their inability to express their true selves in public but also sets them apart for their humanity.>\n",
      "- wrong_answer: <The infrared scenes are used to show that the Polish family has secret ties with the Nazis, marking their dual life and hidden allegiance.>\n",
      "\n",
      "Index 19/79:\n",
      "- second_truth: <The Zone of Interest portrays both the perpetrators and those who support them without making a clear distinction between the two.>\n",
      "- wrong_answer: <The Zone of Interest highlights a sympathetic view of those complicit, suggesting they were unaware of the atrocities happening around them.>\n",
      "\n",
      "Index 20/79:\n",
      "- second_truth: <To ease tensions in Parliament, all MPs will be required to practice Tai Chi for half an hour each day.>\n",
      "- wrong_answer: <To address stress in Parliament, all MPs will be encouraged to take thirty-minute cooking classes daily.>\n",
      "\n",
      "Rate limit exceeded. Waiting for 90 seconds before retrying...\n",
      "\n",
      "Index 21/79:\n",
      "- second_truth: <The British Museum plans to add a Daddy’s section to complement the Mummy exhibit.>\n",
      "- wrong_answer: <The British Museum will introduce a section about British inventions as a new attraction alongside the current Mummy exhibition.>\n",
      "\n",
      "Index 22/79:\n",
      "- second_truth: <The Tesla A100 is up to 1.70 times faster than the Tesla V100 when using certain transformer tasks.>\n",
      "- wrong_answer: <The Tesla A100 is twice as fast as the Tesla V100 across all tasks, including SE-ResNeXt101 and Masked-R-CNN models.>\n",
      "\n",
      "Index 23/79:\n",
      "- second_truth: <The criticism was about your work on training sparse networks.>\n",
      "- wrong_answer: <You received criticism for reducing FLOPS in your low-precision computation research.>\n",
      "\n",
      "Index 24/79:\n",
      "- second_truth: <Python functions are automatically public, while Gleam functions require 'pub' to be public.>\n",
      "- wrong_answer: <In Gleam, functions are always public unless specified otherwise, whereas Python requires a special keyword to make functions private.>\n",
      "\n",
      "Index 25/79:\n",
      "- second_truth: <In Gleam, the pipe operator is represented by '|>'.>\n",
      "- wrong_answer: <The pipe operator in Gleam is represented by ':>'.>\n",
      "\n",
      "Index 26/79:\n",
      "- second_truth: <Negative infinity values are used to mask future tokens so they become zero after the softmax operation.>\n",
      "- wrong_answer: <The top-right values are set to help the model focus on past tokens by enhancing their importance in the calculation of attention scores.>\n",
      "\n",
      "Index 27/79:\n",
      "- second_truth: <To prevent a variable from being updated during training in MLX, prepend '_' to the variable name. This indicates that MLX treats it as non-trainable.>\n",
      "- wrong_answer: <To freeze a variable during training in MLX, set its gradient to zero manually within the update step.>\n",
      "\n",
      "Index 28/79:\n",
      "- second_truth: <The narrator and Perry are siblings.>\n",
      "- wrong_answer: <Perry is the narrator's cousin.>\n",
      "\n",
      "Index 29/79:\n",
      "- second_truth: <The narrator has been sober for two years.>\n",
      "- wrong_answer: <The narrator has been sober for over a year.>\n",
      "\n",
      "Index 30/79:\n",
      "- second_truth: <The station is known as \"Babystation Beta.\">\n",
      "- wrong_answer: <The space station is named \"Childcare Alpha.\">\n",
      "\n",
      "Index 31/79:\n",
      "- second_truth: <The humans speak one language comparable to Cantonese.>\n",
      "- wrong_answer: <The people primarily speak English, as indicated by the name of the planet.>\n",
      "\n",
      "Index 32/79:\n",
      "- second_truth: <The option to adopt pets from Marnie's shop starting from year two was added in patch 1.6.3.>\n",
      "- wrong_answer: <The pet adoption feature was introduced with the initial release of Stardew Valley.>\n",
      "\n",
      "Index 33/79:\n",
      "- second_truth: <Mushroom trees stopped dropping wood in version 1.4.0.>\n",
      "- wrong_answer: <Mushroom trees stopped dropping wood in version 1.6.8.>\n",
      "\n",
      "Index 34/79:\n",
      "- second_truth: <Alan Wake 2 was unveiled at The Game Awards 2021.>\n",
      "- wrong_answer: <Alan Wake 2 was officially announced at Gamescom 2023.>\n",
      "\n",
      "Rate limit exceeded. Waiting for 90 seconds before retrying...\n",
      "\n",
      "Index 35/79:\n",
      "- second_truth: <The game takes place in 2023, thirteen years after Alan Wake.>\n",
      "- wrong_answer: <This game is set in 2010, directly after the original events of Alan Wake.>\n",
      "\n",
      "Index 36/79:\n",
      "- second_truth: <Rebecca Ross is the author of 'Divine Rivals'.>\n",
      "- wrong_answer: <Malka Older wrote 'Divine Rivals'.>\n",
      "\n",
      "Index 37/79:\n",
      "- second_truth: <Lou was revived alongside several other women who were victims of the same serial killer.>\n",
      "- wrong_answer: <Lou was brought back to life with other victims of a disastrous space mission.>\n",
      "\n",
      "Index 38/79:\n",
      "- second_truth: <The paper divides the RAG technique into four categories: pre-retrieval, retrieval, post-retrieval, and generation.>\n",
      "- wrong_answer: <The paper categorizes the RAG technique into three areas: data collection, retrieval process, and output generation.>\n",
      "\n",
      "Index 39/79:\n",
      "- second_truth: <Research by Cuconasu et al. (2024) shows that irrelevant documents can actually enhance the accuracy of RAG systems.>\n",
      "- wrong_answer: <Including unrelated documents tends to decrease the performance and leads to more inaccuracies in RAG systems.>\n",
      "\n",
      "Index 40/79:\n",
      "- second_truth: <Assault Bullet Kin and Tanker enemies use AK-47s.>\n",
      "- wrong_answer: <Assault-rifle wielding Bullet, Fallen Bullet Kin, and Shroomers use AK-47s.>\n",
      "\n",
      "Index 41/79:\n",
      "- second_truth: <Jammed Keybullet Kin drop two keys instead of one, Jammed Chance Kins might drop double loot, and Jammed red-Caped Bullet Kin cause contact damage. Also, Jammed variations are quicker and vanish faster if not defeated.>\n",
      "- wrong_answer: <Jammed enemies have higher health and deal more damage, while also moving slower than regular enemies, making them easier to defeat.>\n",
      "\n",
      "Index 42/79:\n",
      "- second_truth: <26 kobolds and a single kobold inventor are faced in the second encounter.>\n",
      "- wrong_answer: <26 ropers and 1 roper inventor are encountered in the second encounter.>\n",
      "\n",
      "Index 43/79:\n",
      "- second_truth: <Ropers, kobolds, kobold inventors, and fire giants including dreadnoughts.>\n",
      "- wrong_answer: <Ropers, kobolds, and goblins are encountered during this journey.>\n",
      "\n",
      "Index 44/79:\n",
      "- second_truth: <LangChain was selected to manage the RAG process, with alternatives such as LlamaIndex and LitGPT explored. Llmware came up as an option after the initial development.>\n",
      "- wrong_answer: <The RAG process was executed using LlamaIndex, with other alternatives like LangChain and LitGPT considered. Llmware was briefly evaluated but not chosen for final use.>\n",
      "\n",
      "Index 45/79:\n",
      "- second_truth: <Models considered were tinyllama-1.1b, Phi 3, bartowski/dolphin, Mistroll-7B, and Meta-Llama-3, alongside Chroma, Qdrant, and Vespa databases.>\n",
      "- wrong_answer: <The chosen adaptations were the ChatGPT-3 series and Google Dialogflow, combined with MongoDB and Apache Flink for database solutions.>\n",
      "\n",
      "Index 46/79:\n",
      "- second_truth: <The bling-phi-3 model is part of the BLING series, known for being small CPU-based models optimized for RAG and following instructions. It's among the most accurate models in its category.>\n",
      "- wrong_answer: <The bling-phi-3 model is a large GPU-based model, specifically designed for generative tasks, with high performance suitable for running complex AI applications.>\n",
      "\n",
      "Index 47/79:\n",
      "- second_truth: <SLIM models saw updates in versions 0.2.3, 0.2.6, 0.2.12, 0.3.0, and 0.3.1.>\n",
      "- wrong_answer: <The update for SLIM models was only mentioned in versions 0.2.5 and 0.3.2.>\n",
      "\n",
      "Index 48/79:\n",
      "- second_truth: <UI elements can be grouped using:\n",
      "- Arrays\n",
      "- Dictionaries\n",
      "- Embedding dynamically\n",
      "- hstack/vstack\n",
      "- Table columns\n",
      "- Forms with multiple elements.>\n",
      "- wrong_answer: <UI elements can only be grouped by creating lists, but this method does not work well with the UI bindings. It's recommended to use individual elements instead.>\n",
      "\n",
      "Index 49/79:\n",
      "- second_truth: <The mo.ui.text function accepts optional parameters like label and placeholder.>\n",
      "- wrong_answer: <mo.ui.text requires mandatory parameters for size and color, which customize the input field's appearance.>\n",
      "\n",
      "Index 50/79:\n",
      "- second_truth: <Some examples are: creating an analysis that isn’t acted upon; conducting experiments without results being utilized; building predictive models not adopted by the team; and creating dashboards that are ignored.>\n",
      "- wrong_answer: <Examples include a manager not sharing an analysis, workers ignoring experiment results, models failing due to lack of data, and dashboards that lack visual appeal.>\n",
      "\n",
      "Index 51/79:\n",
      "- second_truth: <1. Identify what impact means in your role and assess your achievements based on that. 2. Make sure your work addresses genuine business needs. 3. Obtain support from key stakeholders for your projects. 4. Prioritize work that will have the greatest impact.>\n",
      "- wrong_answer: <The four steps are: Step 1: Improve technical skills to boost your productivity; Step 2: Execute tasks faster; Step 3: Concentrate on generating more data outputs; Step 4: Work harder to complete more projects.>\n",
      "\n",
      "Index 52/79:\n",
      "- second_truth: <AI systems are classified into minimal risk, high risk, unacceptable risk, and specific transparency risk categories.>\n",
      "- wrong_answer: <The risk classifications include low risk, moderate risk, extreme risk, and transparency risk categories.>\n",
      "\n",
      "Index 53/79:\n",
      "- second_truth: <General-purpose AI models with computing power exceeding 10^25 FLOPs must tackle systemic risks through governance rules applicable 12 months post AI Act enforcement. Providers must report energy usage, while free/open-source models are mostly exempt, except those carrying systemic risks.>\n",
      "- wrong_answer: <General-purpose AI models developed using any computing power are required to comply with full regulations immediately upon the AI Act's enforcement. All providers, including free and open-source, must disclose energy consumption and follow governance rules without exceptions.>\n",
      "\n",
      "Rate limit exceeded. Waiting for 90 seconds before retrying...\n",
      "\n",
      "Index 54/79:\n",
      "- second_truth: <The Emperor is also referred to as the \"Dream Guardian\", \"Dream Visitor\", and \"Balduran.\">\n",
      "- wrong_answer: <The Emperor's aliases include \"Mind Master\", \"Brain Keeper\", and \"Dark Sovereign.\">\n",
      "\n",
      "Index 55/79:\n",
      "- second_truth: <Duke Stelmane was involved with the Knights of the Shield, secretly manipulated by the Emperor for her own purposes.>\n",
      "- wrong_answer: <Duke Stelmane was an adventurer who founded Baldur's Gate and later became the Emperor, manipulating political events directly.>\n",
      "\n",
      "Index 56/79:\n",
      "- second_truth: <You enjoyed a puff pastry and Basque cheesecake at Otaegui, and there was cake offered on the camino.>\n",
      "- wrong_answer: <You tasted desserts at the Guggenheim restaurant and in the Salamanca neighborhood shops.>\n",
      "\n",
      "Index 57/79:\n",
      "- second_truth: <You went hiking and surfing.>\n",
      "- wrong_answer: <You explored various museums and played beach volleyball every afternoon with your friends.>\n",
      "\n",
      "Index 58/79:\n",
      "- second_truth: <The film centers around Rudolf Hoss and his family, including his wife Hedwig, two sons, three daughters, and Hedwig's mother.>\n",
      "- wrong_answer: <The movie focuses on the family of Rudolf Hoss, which includes him, his wife Hedwig, their three sons, and two daughters.>\n",
      "\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     15\u001b[39m         \u001b[38;5;66;03m# Call enrich_dataset() for each row\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m         enriched_data = \u001b[43menrich_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcontext\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mground_truth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mground_truth\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m         \u001b[38;5;66;03m# Ensure the expected keys exist\u001b[39;00m\n\u001b[32m     23\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mresponse_correct\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m enriched_data \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mresponse_wrong\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m enriched_data:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36menrich_dataset\u001b[39m\u001b[34m(content)\u001b[39m\n\u001b[32m     14\u001b[39m text = {\n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mformat\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m     16\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mjson_schema\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m     }\n\u001b[32m     29\u001b[39m }\n\u001b[32m     31\u001b[39m response = client.responses.create(\n\u001b[32m     32\u001b[39m     model = azure_deployment_name,\n\u001b[32m     33\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28minput\u001b[39m,\n\u001b[32m     34\u001b[39m     text  = text\n\u001b[32m     35\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutput_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\genai_evaluation\\Lib\\json\\__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\genai_evaluation\\Lib\\json\\decoder.py:338\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    334\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    335\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    336\u001b[39m \n\u001b[32m    337\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m     end = _w(s, end).end()\n\u001b[32m    340\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\genai_evaluation\\Lib\\json\\decoder.py:356\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    354\u001b[39m     obj, end = \u001b[38;5;28mself\u001b[39m.scan_once(s, idx)\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# Initialize empty lists for the new columns\n",
    "response_correct_list = []\n",
    "response_wrong_list = []\n",
    "\n",
    "enriched_df = consolidated_df.copy()\n",
    "\n",
    "i = 0\n",
    "total_rows = len(enriched_df)-1\n",
    "\n",
    "# Iterate over the rows using a loop\n",
    "for _, row in enriched_df.iterrows():\n",
    "    if i >= len(response_correct_list):\n",
    "        while True:\n",
    "            try:\n",
    "                # Call enrich_dataset() for each row\n",
    "                enriched_data = enrich_dataset({\n",
    "                    \"context\": row['context'],\n",
    "                    \"query\": row['query'],\n",
    "                    \"ground_truth\": row['ground_truth']\n",
    "                })\n",
    "\n",
    "                # Ensure the expected keys exist\n",
    "                if 'response_correct' in enriched_data and 'response_wrong' in enriched_data:\n",
    "                    response_correct_list.append(enriched_data['response_correct'])\n",
    "                    response_wrong_list.append(enriched_data['response_wrong'])\n",
    "\n",
    "                    print(f\"Index {i}/{total_rows}:\\n- second_truth: <{response_correct_list[i]}>\\n- wrong_answer: <{response_wrong_list[i]}>\\n\")\n",
    "                    break  # Exit loop on success\n",
    "                else:\n",
    "                    print(\"Missing keys in enriched_data, retrying...\\n\")\n",
    "            except openai.RateLimitError:\n",
    "                print(\"Rate limit exceeded. Waiting for 90 seconds before retrying...\\n\")\n",
    "                time.sleep(90)  # Wait before retrying\n",
    "    else:\n",
    "        print(f\"Index {i}/{total_rows} (skipping):\\n- second_truth: <{response_correct_list[i]}>\\n- wrong_answer: <{response_wrong_list[i]}>\\n\")\n",
    "\n",
    "    i += 1\n",
    "\n",
    "\n",
    "# Assign the lists as new columns in the DataFrame\n",
    "enriched_df['response_correct'] = response_correct_list\n",
    "enriched_df['response_wrong'] = response_wrong_list\n",
    "\n",
    "# Display the updated DataFrame\n",
    "display(enriched_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775fe2f8-ed8a-4a76-8681-a1f287c0ed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_df.to_csv (f\"{output_file_name}.csv\", index=False)\n",
    "enriched_df.to_json(f\"{output_file_name}_records.jsonl\", orient=\"records\", lines=True)\n",
    "enriched_df.to_json(f\"{output_file_name}_split.json\", orient=\"split\")\n",
    "enriched_df.to_json(f\"{output_file_name}_table.json\", orient=\"table\")\n",
    "enriched_df.to_json(f\"{output_file_name}_index.json\", orient=\"index\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Generative AI evaluation",
   "language": "python",
   "name": "genai_evaluation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
