document_index,context,query,ground_truth,response_correct,response_wrong
8,"so into northern spain!
our magical urban-plus-outdoor-adventure itinerary
CAROLINE CHAMBERS
MAY 29, 2024

I recently returned from a trip to Northern Spain with two of my best friends, Lily and Nellie, sponsored by elsewhere, a travel company that works with local experts to create truly unique travel experiences.

On our last day in Spain, we had an incredible private tour of the Guggenheim Museum Bilbao, and then partook in our favorite trip ritual: hopping around from pintxo bar to pintxo bar (pintxos = small little plates of food — similar to tapas but they are typically sitting on the bar and you point to what you want), drinking txakoli (a lightly effervescent white wine that is very, very popular in the region), and playing gin rummy.

We then headed back to our hotel room, crammed onto the bed with, well, another bottle of txakoli, and recorded what I can only assume was the greatest podcast episode of all time. We recapped the full trip, what we loved, what we would change. We shared the most absurd moments. We laughed so hard and made so much fun of each other in a way that only really old friends who have just spent 12 days straight together can do. I’ve been so excited to share it.

But… the recording failed. I have no idea what happened, but I blame the txakoli.

I thought about re-recording with them remotely, but the magic of that moment, being there together on the last night of a truly perfect trip, is gone. So instead, I’ll share the highlights here! Full itinerary with ALL the details is here.


We spent two nights in Madrid and could have spent at least four. There’s so much to see and do here, and we barely scratched the surface. Our highlights were shopping in the Chueca and Salamanca neighborhoods — Malababa, Soeur, and Sessùn were some of our favorite shops. We had a wonderful meal at Charrúa Madrid and fun cocktails at Ficus Bar. You can find all of our favorite shops, tapas bars, and many places that we didn’t get to explore but wanted to on my Spain map here.


strolling the charming, windy streets of chueca!

San Sebastián is the coolest town — worth a trip to Spain all on its own. It’s a coastal town on the Northern coast of Spain, right next to the French border, and it fully charmed us. It’s that perfect European blend of old meets new — hip young surfers going to 200-year-old pintxo bars to meet up with their friends after surfing all afternoon, 100-year-old pastry shops next door to chic Spanish design ateliers. We spent three nights there and loved every minute, but these were our highlights:

cooking in a private gastronomic club
When you’re wandering the cobblestone streets of San Sebastián looking for your next pintxo, you might find yourself stumbling through the doorway of a friendly looking restaurant, only to be turned away. “Disculpa, privado!” they’ll tell you — “Sorry, private!”

You’ve stumbled into a sociedad gastronómica — one of San Sebastián’s 100+ private gastronomic clubs. Each one has its own personality and offering, but at its core is this: it’s a private social club centered around cooking and eating with fellow members. Members reserve a time to cook — depending on the size of the club, three to four members can cook at a time — and they can invite guests to join them. Members will head to one of the many local markets, grab their food, and then bring it back to the shared kitchen to cook for/with their friends and family.


post-lunch txakoli on the deck at the club
The only hitch? You have to be with a member to go inside of one! This was the coolest tour that elsewhere set up for us — Jani, our guide, was an incredibly cool young mom and entrepreneur (she owns her own tour company) and is a member of several clubs. She picked us up at our hotel, took us to her favorite local market and farmer’s market to grab ingredients, and then back to her club, which was a stone building with wooden beams and felt like a scene out of a Game of Thrones banquet. We cooked a local fish dish, a tomato salad, and seared white asparagus, and she taught us all about Basque cuisine and the local gastronomic clubs.

We spent the entire afternoon cooking and eating and drinking txakoli on the deck of her club overlooking the city. A cannot miss experience if you find yourself in San Seb! Here’s a great Saveur article if you want to read more about the clubs.

pintxo hopping
Pick three or four pintxos bars that are close together, and hop from bar to bar, eating a snack and having a glass of txakoli at each one. This is always my favorite way to explore a new place on limited time — an appetizer at one spot, a meal at another, after-dinner drinks at a third, so the pintxos culture really allows you to see a lot of places in one night!

My map has a lot of great pintxos bars saved, but here’s an especially great hop (these are all on my map):

Start at Ganbara and grab whatever looks good — we had delightful fried padrón peppers.

Walk over to Txepetxa Taberna for a little sandwich — my favorites were the simple ones filled with local jámon and idiazábal cheese (similar to manchego).

The cheesy risotto at Borda Berri was phenomenal.

Finish your night at Otaegui, the oldest bakery in the city, for pantxineta, a delightful puff pastry and custard-filled local treat, and a slice of Basque cheesecake.


pintxo hopping around the old town!
surfing
Nellie is a big surfer and after a full 24 hours of pestering, finally convinced me to go out with her. There are tons of surf shops that rent wetsuits and boards lining the beach, so it was really easy to get into the water. The waves were absolutely perfect. Gentle, clear water, no getting-stuck-in-a-washing-machine vibes when you fall of your board. It was so, so much fun.



My favorite part of the trip was our four days on the camino. The Camino de Santiago, also known as the Way of Saint James, is a well-trod pilgrimage route that traverses Spain, culminating at the Cathedral of Santiago de Compostela in Galicia. The camino has origins back to the medieval era and has four routes connecting different parts of Spain to Galicia. The routes consist of trails, modern roads, and original medieval stone pathways…


that pass through everything from modern city to medieval village…


to small fishing town…


to stunning wilderness landscapes.


The flysch was truly breathtaking. If you wind up in San Sabastián and want to walk just one day of the camino, walk from Orio to Zumaia, all the way out past the town to see the flysch, then sleep at Hotel Iturregi that night!
The Camino Francés is the most popular route, but my friends and I did a small portion of the Camino Norte, which San Sebastián is right on. The Norte is challenging and stunningly beautiful, with steep, rugged terrain, but with plenty of stopping places for pintxos and a glass of wine along the way. It’s hard to sum up what a wonderful experience hiking it was.

We originally wanted to hike directly from one location to the next — to hike from one hotel to the next without ever getting in a car — 15 to 20 miles per day on the camino. However, the hotels along the route are rustic, more rustic than we were up for, so we wound up switching to stay at a gorgeous hotel in a txakoli vineyard, and just took cabs to and from the camino for our last two days.

Hiking the camino was a bucket list experience — we hiked through fishing villages and past a truly breathtaking flysch rock formation, a cult tried to recruit us by beckoning us in with warm tea and cake, we talked about everything, we talked about nothing, we laughed so hard it hurt. I cannot wait to get back to the camino one day.


Bilbao was an excellent urban re-introduction at the end of four days on the camino. We really didn’t know what to expect, and we were pleasantly surprised. I wouldn’t make a trip to Spain specifically for Bilbao, but I’d certainly make an effort to visit if I was in Northern Spain.

The Guggenheim alone could occupy an entire day — it’s a massive collection of modern and contemporary art. The architecture itself is reason alone to visit. We loved touring the museum with a private tour guide who regaled us with detailed information about every single piece.


We strolled along the river from the Guggenheim all the way to the seven streets area, where we bopped between shops and pintxo bars for the rest of the day. Admittedly, we enjoyed a lot of Italian food in Bilbao as we were feeling a little burnt out on Basque food by this point in the trip. No shame in dabbling in a little pizza while in Spain! You’ll find lots of Basque and Italian recs on my map!

After two nights in Bilbao, we headed home. It was a truly magical trip that we’ll still be laughing and reminiscing about when we’re old ladies.



I love electrolyte powders but so many brands have a lot of sodium in them, which can make me feel really bloated. Ultima is lower-sodium and the flavors are great!

Lily had a lanyard strap iPhone case that I was really jealous of. Kind of dorky looking but who cares, it was so convenient to have her phone handy for photos and looking up directions!

I will never stop yappin’ about my Owala water bottle. Having the ability to drink out of the straw or tilt it and chug it never gets old!

I brought disposable cameras for each of us and I can’t wait to get the film back!! Mattis saw them and has been begging me to get him one — it would be fun to give your kids a disposable camera to capture a summer trip!



Pan-fried dover sole with buttery tomato sauce and corn risotto. The reviews on this week’s recipe are RAVING! It really is so good and fancy feeling. You have to make this one ASAP, especially if you travel somewhere with access to great fish this summer!

Sunshine curry was a cult fave last summer — of yours and of mine! I love making a huge batch and eating it for lunch all week long (a perk of the fact that my kids won’t touch it, though I know many kids love this one!).

My summer tomato galette is the stuff of summer produce dreams. Buy a store-bought pie crust to make it even easier, but it’s worth making the crust from scratch if you have 15 extra minutes! PS: Make the boursin summer squash galette while you’re at it. Two summery galettes + a simple salad of romaine tossed with salt, pepper, really good extra-virgin olive oil, and balsamic, with shaved Parm, and chopped almonds would be such a chic little meal.

Chicken panzanella is one of my all-time faves. Crisp croutons, juicy tomatoes, perfectly cooked chicken, balsamic, olive oil, basil, with big hunks of melty goat cheese. It’s the perfect summer lunch or dinner! Don’t let your croutons burn!


I loved reading about all of your happy places in the comments of last week’s post! My number one takeaway is that I need to spend more time in Maine — so many of your happy places are there! Including this week’s winner, Heather.


Dreamy! And now you can bring your new pair of Lake Pajamas to Boothbay Harbor this summer! Email me your size and address!

Do you have any Spain recs to add? Anyone taking an exciting trip this summer? We’re staying local for most of the summer so that we can enjoy our new cabin, minus our annual two-week Southern voyage to DeBordieu, SC to visit George’s family and Bald Head Island, NC to visit mine!",Which part of the trip did I like the most?,Your favourite part of the trip was your four days on the Camino.,You loved the four days spent on the Camino.,Your favorite part was visiting the Guggenheim Museum Bilboa and pintxo hopping.
2,"Semantic and Textual Inference Chatbot Interface (STICI-Note) - Part 1: Planning and Prototyping

The start of my RAG to riches story

STICI-note

Published: Mon, 27 May 2024

Last modified: Tue, 04 Jun 2024

Introduction

In this three-part series, I will be talking you through how I built the Semantic and Textual Inference Chatbot Interface (or STICI-note for short), a locally run RAG chatbot that uses unstructured text documents to enhance its responses. I came up with the name when I was discussing this project with a friend and asked him whether he had any ideas of what to call it. He said, ""You should call it sticky because it sounds funny."" The name... stuck...

The code for this project is available here.

In this part, I will be planning the project from the tech stack to the techniques I will use, and I will be building a prototype. I will be discussing all of the choices I made and all of the choices I didn’t make, so I hope you find this insightful. Without further ado, let’s get started.

The Problem

In my spare time, I occasionally play Dungeons and Dragons (DnD), a tabletop roleplaying game, and the stories are often told over several months, so details can be easily lost or forgotten over time. I can write notes on my laptop, but sometimes regular text search does not always provide me with the results I want when trying to search for specific notes. Some common examples include when a keyword is used often (e.g., I might write a lot about the actions of “Miles Lawson,” but only one segment of text might describe who he is, making searching for information on his character like finding a needle in a haystack) or when I simply cannot think of the correct keyword to search (e.g., what if I search “silver” instead of “gold”?).

One day, I thought to myself that it’d be great if I had a tool that I could write my DnD notes into in an unstructured way and retrieve the information at any time with simple questions like “Who is Miles Lawson?” or “How much silver did I pay for a stay in ye olde tavern?”. This tool could be extended to be used for querying my notes on many things that are not available online (and therefore not searchable on a search engine), such as documentation on software that I build, notes on things that I’m learning about, such as AWS cloud infrastructure, and my diary of my deepest thoughts and feelings (at least I hope this is not available online). And thus, I decided to start working on STICI-note because the tools available online that do this cost money and run on the cloud, and I’m a tight-fisted guy who’s very sceptical about company promises to not sell your data.

Narrowing Down Features

As with all projects, I began by deciding what features I needed from this tool.

Required features:

Chatbot that you can ask questions and get answers in response (conversational memory is not required).
Information is taken from an unstructured text file.
It must be able to tell me if it doesn’t know the answer to my question.
Fast.
Efficient enough to run on my MacBook with other programs without any performance issues.
Locally run for privacy and to ensure it will always be free, runnable, and consistent.
Conversational memory is the memory of previous interactions given to an LLM. I decided not to require it as a feature because I just need the AI to answer my questions about the given text. It might be added as a feature in the future if I feel like I need it, but I do not plan to include it in the initial version of STICI-note.

I knew that limiting it to running on my M1 MacBook with 8 GB of memory would greatly limit the performance of the tool as I would not be able to access truly large language models like GPT-4 and Claude 3 Opus, but I decided to do it anyway primarily for privacy but also to remove dependencies on external organisations to reduce the maintenance required for the tool in the future.

Planning How to Evaluate and Compare Solutions

If you don’t evaluate a solution, how do you know whether it’s an effective solution? You don’t.

I next planned how I would evaluate different variations of the tool. While I do not evaluate anything in this part, I decided to sketch out a rough plan of how I would evaluate different solutions to encourage designing a testable AI in the same way that Test-Driven Development (TDD) encourages you to write testable code.

At first, I considered using Wikipedia pages as the data source and making my own questions about the content of the pages before I realised that this would lead to data leakage as many LLMs are trained on Wikipedia data.

An alternative dataset that I considered using for evaluation is the TREC 2024 RAG Corpus. This is a 28 GB corpus of text documents scraped from the internet. This corpus comes with thousands of queries, and the relevant documents for each query have been tagged as such. This is an amazing corpus for training and evaluating vector DataBase (DBs). Ignoring the fact that its questions do not come with answers, meaning I would have to write my own answers to use the document, there is one glaring flaw that makes it unusable for my use case: the documents are generally relatively short and describe a large variety of things. In my use case, I expect documents to be long and typically written about the same topic. If I were to use the corpus, I would have to stick documents together to present a realistic challenge in the semantic search of the vector DB vector space, but as each document will likely be about very different topics (e.g., one might be about aviation while another might be about economics), context retrieval would be unrealistically easy.

Another alternative evaluation dataset that I considered using was a synthetic dataset. By following a method like this, I can use an LLM to generate synthetic context and questions automatically. I decided not to do this as I was concerned that this would produce bad-quality data with a massive bias towards things an LLM might already know, despite the use case expecting data that the LLM does not already know.

Because the documents in my evaluation corpus need to be thousands of words in length while staying relevant to a topic and they need to include information that will not be in the LLM’s training data, I decided that it would be best to manually curate a small dataset to evaluate my models. I plan to create documents from sources on the internet like videogame wikis, people’s blogs, and scientific journals and write my own pairs of questions and answers about them. I will then evaluate the difference between the model’s answer and my answer using a semantic similarity score.

RAG vs a Really Big Context Window vs Infinite Context

To be able to answer questions about documents, the LLM would need to have access to information from the documents. I thought of three potential solutions for this:

Retrieval Augmented Generation (RAG)
An LLM with a really big context window
An LLM that supports infinite context length
Using an LLM with a really big context window such as Anthropic’s Claude 3 and Google’s Gemini 1.5 would certainly give me the best results as it would allow inference using completely unfiltered and uncompressed context as they can handle inputs of over 700,000 words, but these models are closed-source, and there is absolutely no chance of a model of this size fitting into my tiny M1 MacBook with 8 GB of memory.

By “an LLM that supports infinite context length,” I mean models like Mamba, Megalodon, and Infini-attention that compress context into a finite space. I decided not to use a model like this for two main reasons. Firstly, I have concerns about the performance. These architectures are in their infancy, and I do not expect them to outperform equivalently-sized traditional transformers. Secondly, as these architectures are very new and experimental, I do not expect much support for them, especially for Apple’s M-series of chips, which have their own graphics API, metal, that is required for GPU acceleration on my MacBook. These architectures are very interesting, and I would love to try them out, but for this project, I will have to settle for a more tried-and-tested approach.

The more tried and tested approach that I settled with is RAG. It is an incredibly popular technique for allowing LLMs to make use of information that is too big to fit in their context windows. This technique is known to perform very well, is incredibly well supported by LLM frameworks like LangChain and llamaindex, and works well in resource-constrained environments like on my laptop. Given all this, RAG was an obvious choice.

Optimising Models for Limited Memory Environments

Next, I decided to investigate what kinds of optimisation strategies were available to use to try to fit bigger models into my M1 chip, as bigger LLMs typically perform better (I know, a groundbreaking revelation). To optimise the LLMs that I use, I considered four different techniques:

Quantisation
Model pruning
Model/knowledge distillation
AirLLM
Quantisation is the most common method for making ML models smaller (and therefore faster and more capable of fitting into smaller spaces). It’s well known for improving speed and memory usage with little loss in accuracy in return, which makes it very popular for production-level AI. Quantising a model would require being able to fit it into your GPU, but I’m trying to quantise a model so that it can fit into my GPU, so without additional computing power, it’s a bit of a chicken and egg problem. Luckily, because this is such a popular technique, there are many quantised versions of large, high-performance LLMs available on HuggingFace that I can use, so there is no need to do this myself.

Model pruning is a less common method for reducing model sizes, but it is not a technique that one should overlook. This is a technique that can be combined with quantisation (or used on its own) to further reduce models at the expense of accuracy, but I do not plan to apply it myself due to its complexity and the fact that quantisation has the same effect. There are pruned models available on HuggingFace, but they don’t typically perform as well as equivalently sized quantised models, so I do not plan to use any unless they have particularly good evaluation results on a common LLM benchmark.

Model/knowledge distillation is another size reduction technique that I considered. Unlike the previous techniques, model distillation can actually improve accuracy in domain-specific tasks while making a smaller model. As with quantisation and model pruning, I will use pre-distiled models, but I will not distil any models myself due to the computing power it requires (which admittedly is far less than training a model from scratch) and the complexity it would add to the project.

The final optimisation technique that I considered, AirLLM, is quite different from the others in that instead of optimising the model weights, it optimises the model inference. Typically, LLMs are loaded onto the GPU in their entirety, requiring a lot of VRAM to run the larger, better-performing models. AirLLM is an open-source library that tackles this problem by using layered inference, an inference technique that involves loading layers individually when they are needed instead of all at once. This allows larger models to fit into smaller memory spaces without degrading performance. This method definitely has a high potential for accuracy, but I decided not to use it as I am concerned about compatibility and reliability issues as it is a new tool and the GitHub repo has been developed by a single person, so support for it is likely to be limited. Additionally, my M1 chip only has 8 GB of memory shared between the CPU and GPU, which is excellent for reducing data loading overhead costs, but it means that larger models that require AirLLM will be loaded directly from the SSD, so I am concerned that the model layer loading and unloading will become a massive bottleneck when doing inference on larger models. I will reconsider this option if I find that the models that can run on my MacBook do not have satisfactory accuracy.

What Models Even Run on My MacBook?

After getting an idea of what kinds of optimisation techniques were available, I decided to conduct some tests to find out what LLMs would actually run on my MacBook. You could argue that since I am only building a prototype right now, I only need to find one LLM that performs well on my MacBook, but I decided to find five models instead to give me an idea of what kinds of models I will be able to use. In particular, I wanted to know how big the models I could run were and what precision the weights would likely be.

I tested models that I had heard were good or showed decent results on the Hugging Face H4 Open LLM Leaderboard. I found LM Studio incredibly useful for testing out LLMs without having to write any code, which saved me a lot of time. Below are the five suitable models that I found that could run on my MacBook and were fast enough to satisfy me:

tinyllama-1.1b-chat-v1.0 Q6_K
Phi 3 Q4_K_M
bartowski/dolphin-2.8-experiment26-7b-GGUF Q3_K_L
mgonzs13/Mistroll-7B-v2.2-GGU
QuantFactory/Meta-Llama-3-8B-Instruct Q3_K_M
These models range from 1.17 GB up to 4.02 GB in size. I chose not to use any models that were any larger than 4 GB, as with only 8 GB of memory available, I expect that models that are any bigger would seriously impact the other applications that the user (i.e., me) is running on their device.

I will likely test out more models than this while testing out different configurations for the tool, but for the prototype, this is enough.

A Model Without a Framework is Like a Car Engine Without a Chassis

To run my models, I could have written a framework for loading, unloading, and executing the models, passing context and queries to the models, and integrating the vector DB (more on that later) with the inference model from scratch, but I didn’t because I’m not insane and I am not trying to learn how to make ML frameworks. A lot of university students (myself included) are conditioned to try to build things from scratch for fear of plagiarism and because they are used to building things from scratch as a learning exercise (a very effective one in my opinion), so it’s difficult to unlearn the DIY mindset, but it’s simply a lot quicker and a lot more reliable to use libraries than to reinvent the wheel. Saying that, I decided to use a relatively simple tech stack.

Python was an obvious choice for me, given that I have a lot of experience with it and that it has an abundance of support for machine learning applications. I decided to use LangChain to orchestrate my RAG process from the vector DB to the inference, as it is a flexible tool for composing NLP pipelines. It is very popular and reliable, and it includes a lot of tools that make developing NLP applications easier. I considered using LlamaIndex as it is built more specifically for RAG applications, but LangChain is more general-purpose, which I expect will make it more extensible for times when I might want to add more features in the future. Additionally, I am more likely to use LangChain again for other applications in the future, so the experience will be more useful. I also considered using LitGPT, but I had some issues getting it to work with the M1 chip’s Metal Performance Shaders (MPS), so I decided not to use it for fear of incompatibility. LitGPT is also intended more for training and fine-tuning LLMs, so it is likely not the best tool for simply deploying them in an application.

To run inference on my models, I will need another library to actually execute the model. As I am using a range of pre-trained models, I will mainly use HuggingFace’s transformers library and the Python bindings for llama.cpp library to load and execute models, as these provide simple interfaces for inference, and I don’t need the additional control that deep learning frameworks like TensorFlow, PyTorch, and JAX provide as I’m using pre-trained models. As I mentioned earlier, AirLLM is still on the table if I need better performance, but I will find out while evaluating models whether this is necessary.

Magnitude + Direction DBs

Since I was using RAG, I needed a vector DB. Deciding which one to use was the final step of the research and also the most difficult one, as vector DBs are the technology that I am least familiar with. For the vector DB, my main requirements were simple: it needed to be lightweight, locally runnable on a laptop, fast, and compatible with my MacBook. Lightweight and locally runnable sound like similar things, but I mean different things by each phrase. The locally runnable one is quite self-explanatory, but by lightweight, I mean quite minimal computation requirements that don’t add features like heavy amounts of redundancy and heavy caching, which are useful for large-scale systems, but will simply drain resources in my application that is designed to run alongside an LLM and the user’s other applications on 8 GB of memory shared between the CPU and GPU.

I considered sixteen different vector DBs, but there were three different solutions that stood out to me for my use case: Chroma, Qdrant, and Vespa. These were all lightweight vector DBs that fit all of my requirements, but I decided to pick Chroma out of the three of them because it has a very batteries included approach, which is very useful for getting an application working quickly.

Below is an overview of my planned tech stack. I did not include any UI, as there are many options for this, and I plan to decide on the UI when building the final product.

The tech stack and data flow that I plan to use for STICI-note.
The tech stack and data flow that I plan to use for STICI-note.

Making the Prototype (A.K.A. the Easy Part)

The final step was to actually build the prototype/proof of concept (PoC) to find out whether this idea can actually be implemented using the tech stack that I have picked. I decided to implement it using the smallest of the 5 models that I had found earlier, tinyllama-1.1b-chat-v1.0 Q6_K, to minimise the chances of having any memory issues.

You can find my prototype code here.

For the prototype, I decided to make very basic configurations for everything to develop it quickly, and I tested it by asking a question about Grace Hopper, one of the most influential programmers to have ever lived, in two versions of the prototype: one with Grace Hopper’s Wikipedia page in its vector DB and one with Alan Turing’s Wikipedia page in its vector DB.

The question was:

“What programming language was Grace Hopper known for creating?”

As expected, the version with Alan Turing’s Wikipedia page failed miserably, hallucinating its entire response:

Grace Hopper was a computer scientist who is best known for her work on developing an early version of BASIC, which was one of the first low-level programming languages designed for mainframe computers. Hopper worked at Digital Equipment Corporation (DEC) in the mid-1960s and was responsible for creating several key BASIC versions that were used by DEC's mainframe computers. In 1973, she left DEC to work on a new low-level programming language called PASCAL, which became one of the most popular programming languages of its time. However, her contributions to BASIC are still remembered today as it was one of the first widely used and easy-to-understand programming languages for mainframe computers.

This behaviour of hallucinating will need to be fixed in the final product, likely through prompt engineering.

As expected, the version with Grace Hopper’s Wikipedia page gave a much more accurate response but it unexpectedly contained far more spelling errors:

Grace Hopper is credited with creating the first computer programming languaige called FLOW-MATIC. This language was developed in 1954 and was based on English words. Hopper's work on this languaige led to a machine-indepenent programming language, COBOL, which used English words instead of symbols for input and output. Her compiler, A-0, also utilized the FLOW-MATIIC language as its basis for compiling programs into executable code. In 1952, Hopper published her first paper on the topic of compiler design, ""The Compiler"" in the IEEE Transactions on Computers, in which she discussed her work with A-0 and other programming languaiges.

Unfortunately, this response was not free from hallucinations either. Hopper’s A-0 compiler did not use the FLOW-MATIC programming language, and she never published a paper called “The Compiler” in IEEE Transactions on Computers (a real journal that is not mentioned in the Wikipedia page). It looks like hallucinations are likely to be a major issue for this tool, but that is a problem I will solve when refining the AI.

On the bright side, inference was ~120 tokens/second, so at least this model will output words much faster than I can read them.

Conclusion

In this blog, I built a locally run prototype for my chatbot for querying unstructured text documents. It doesn’t have a UI, and it hallucinates a lot, but it is nonetheless capable of querying unstructured text.

It’s such a shame that after I had done the research and written all of the code, while I was writing this blog, I read about llmware, a very promising Python framework for building RAG pipelines with small models (sound familiar?). It was even chosen for GitHub Accelerator 2024, a competition for open-source projects on GitHub where chosen projects are given funding, mentorship, and access to resources to help them grow their project. Since I had already built the prototype in LangChain, it didn’t make much sense to tear it down and rebuild it in a fancy new framework that wasn’t as tried-and-tested. I’d love to try the framework out one day if I build another RAG application after this one.

In the next part of the STICI-note blog series, I will be building an evaluation suite to test and compare different inference models and vector DB configurations, so stay tuned and follow me on LinkedIn to be notified when it comes out!",What data did was used to test the prototype?,Grace Hopper's Wikipedia page and Alan Turing's Wikipedia page were used to test the prototype.,Wikipedia pages of Grace Hopper and Alan Turing were used to test the prototype.,The prototype was tested using a selection of academic papers and blog posts about early computer scientists.
4,"Recipes
This page includes code snippets or “recipes” for a variety of common tasks. Use them as building blocks or examples when making your own notebooks.

In these recipes, each code block represents a cell.

Control Flow
Show an output conditionally
Use cases. Hide an output until a condition is met (e.g., until algorithm parameters are valid), or show different outputs depending on the value of a UI element or some other Python object

Recipe.

Use an if expression to choose which output to show.

# condition is a boolean, True of False
condition = True
""condition is True"" if condition else None
Run a cell on a timer
Use cases.

Load new data periodically, and show updated plots or other outputs. For example, in a dashboard monitoring a training run, experiment trial, real-time weather data, …

Run a job periodically

Recipe.

Import packages

import marimo as mo
Create a mo.ui.refresh timer that fires once a second:

refresh = mo.ui.refresh(default_interval=""1s"")
# This outputs a timer that fires once a second
refresh
Reference the timer by name to make this cell run once a second

import random

# This cell will run once a second!
refresh

mo.md(""#"" + """" * random.randint(1, 10))
Require form submission before sending UI value
Use cases. UI elements automatically send their values to the Python when they are interacted with, and run all cells referencing the elements. This makes marimo notebooks responsive, but it can be an issue when the downstream cells are expensive, or when the input (such as a text box) needs to be filled out completely before it is considered valid. Forms let you gate submission of UI element values on manual confirmation, via a button press.

Recipe.

Import packages

import marimo as mo
Create a submittable form.

form = mo.ui.text(label=""Your name"").form()
form
Get the value of the form.

form.value
Stop execution of a cell and its descendants
Use cases. For example, don’t run a cell or its descendants if a form is unsubmitted.

Recipe.

Import packages

import marimo as mo
Create a submittable form.

form = mo.ui.text(label=""Your name"").form()
form
Use mo.stop to stop execution when the form is unsubmitted.

mo.stop(form.value is None, mo.md(""Submit the form to continue""))

mo.md(f""Hello, {form.value}!"")
Grouping UI elements together
Create an array of UI elements
Use cases. In order to synchronize UI elements between the frontend and backend (Python), marimo requires you to assign UI elements to global variables. But sometimes you don’t know the number of elements to make until runtime: for example, maybe you want o make a list of sliders, and the number of sliders to make depends on the value of some other UI element.

You might be tempted to create a Python list of UI elements, such as l = [mo.ui.slider(1, 10) for i in range(number.value)]: however, this won’t work, because the sliders are not bound to global variables.

For such cases, marimo provides the “higher-order” UI element mo.ui.array, which lets you make a new UI element out of a list of UI elements: l = mo.ui.array([mo.ui.slider(1, 10) for i in range(number.value)]). The value of an array element is a list of the values of the elements it wraps (in this case, a list of the slider values). Any time you interact with any of the UI elements in the array, all cells referencing the array by name (in this case, “l”) will run automatically.

Recipe.

Import packages.

import marimo as mo
Use mo.ui.array to group together many UI elements into a list.

import random

# instead of random.randint, in your notebook you'd use the value of
# an upstream UI element or other Python object
array = mo.ui.array([mo.ui.text() for i in range(random.randint(1, 10))])
array
Get the value of the UI elements using array.value

array.value
Create a dictionary of UI elements
Use cases. Same as for creating an array of UI elements, but lets you name each of the wrapped elements with a string key.

Recipe.

Import packages.

import marimo as mo
Use mo.ui.dictionary to group together many UI elements into a list.

import random

# instead of random.randint, in your notebook you'd use the value of
# an upstream UI element or other Python object
dictionary = mo.ui.dictionary({str(i): mo.ui.text() for i in range(random.randint(1, 10))})
dictionary
Get the value of the UI elements using dictionary.value

dictionary.value
Embed a dynamic number of UI elements in another output
Use cases. When you want to embed a dynamic number of UI elements in other outputs (like tables or markdown).

Recipe.

Import packages

import marimo as mo
Group the elements with mo.ui.dictionary or mo.ui.array, then retrieve them from the container and display them elsewhere.

import random

n_items = random.randint(2, 5)

# Create a dynamic number of elements using `mo.ui.dictionary` and
# `mo.ui.array`
elements = mo.ui.dictionary(
    {
        ""checkboxes"": mo.ui.array([mo.ui.checkbox() for _ in range(n_items)]),
        ""texts"": mo.ui.array(
            [mo.ui.text(placeholder=""task ..."") for _ in range(n_items)]
        ),
    }
)

mo.md(
    f""""""
    Here's a TODO list of {n_items} items\n\n
    """"""
    + ""\n\n"".join(
        # Iterate over the elements and embed them in markdown
        [
            f""{checkbox} {text}""
            for checkbox, text in zip(
                elements[""checkboxes""], elements[""texts""]
            )
        ]
    )
)
Get the value of the elements

elements.value
Create a hstack (or vstack) of UI elements with on_change handlers
Use cases. Arrange a dynamic number of UI elements in a hstack or vstack, for example some number of buttons, and execute some side-effect when an element is interacted with, e.g. when a button is clicked.

Recipe.

Import packages

import marimo as mo
Create buttons in mo.ui.array and pass them to hstack – a regular Python list won’t work. Make sure to assign the array to a global variable.

import random


# Create a state object that will store the index of the
# clicked button
get_state, set_state = mo.state(None)

# Create an mo.ui.array of buttons - a regular Python list won't work.
buttons = mo.ui.array(
    [
        mo.ui.button(
            label=""button "" + str(i), on_change=lambda v, i=i: set_state(i)
        )
        for i in range(random.randint(2, 5))
    ]
)

mo.hstack(buttons)
Get the state value

get_state()
Create a table column of buttons with on_change handlers
Use cases. Arrange a dynamic number of UI elements in a column of a table, and execute some side-effect when an element is interacted with, e.g. when a button is clicked.

Recipe.

Import packages

import marimo as mo
Create buttons in mo.ui.array and pass them to mo.ui.table. Make sure to assign the table and array to global variables

import random


# Create a state object that will store the index of the
# clicked button
get_state, set_state = mo.state(None)

# Create an mo.ui.array of buttons - a regular Python list won't work.
buttons = mo.ui.array(
    [
        mo.ui.button(
            label=""button "" + str(i), on_change=lambda v, i=i: set_state(i)
        )
        for i in range(random.randint(2, 5))
    ]
)

# Put the buttons array into the table
table = mo.ui.table(
    {
        ""Action"": [""Action Name""] * len(buttons),
        ""Trigger"": list(buttons),
    }
)
table
Get the state value

get_state()
Create a form with multiple UI elements
Use cases. Combine multiple UI elements into a form so that submission of the form sends all its elements to Python.

Recipe.

Import packages.

import marimo as mo
Use mo.ui.form and Html.batch to create a form with multiple elements.

form = mo.md(
   r""""""
   Choose your algorithm parameters:

   - $\epsilon$: {epsilon}
   - $\delta$: {delta}
   """"""
).batch(epsilon=mo.ui.slider(0.1, 1, step=0.1), delta=mo.ui.number(1, 10)).form()
form
Get the submitted form value.

form.value
Working with buttons
Create a button that triggers computation when clicked
Use cases. To trigger a computation on button click and only on button click, use mo.ui.run_button().

Recipe.

Import packages

import marimo as mo
Create a run button

button = mo.ui.run_button()
button
Run something only if the button has been clicked.

mo.stop(not button.value, ""Click 'run' to generate a random number"")

import random
random.randint(0, 1000)
Create a counter button
Use cases. A counter button, i.e. a button that counts the number of times it has been clicked, is a helpful building block for reacting to button clicks (see other recipes in this section).

Recipe.

Import packages

import marimo as mo
Use mo.ui.button and its on_click argument to create a counter button.

# Initialize the button value to 0, increment it on every click
button = mo.ui.button(value=0, on_click=lambda count: count + 1)
button
Get the button value

button.value
Create a toggle button
Use cases. Toggle between two states using a button with a button that toggles between True and False. (Tip: you can also just use mo.ui.switch.)

Recipe.

Import packages

import marimo as mo
Use mo.ui.button and its on_click argument to create a toggle button.

# Initialize the button value to False, flip its value on every click.
button = mo.ui.button(value=False, on_click=lambda value: not value)
button
Toggle between two outputs using the button value.

mo.md(""True!"") if button.value else mo.md(""False!"")
Re-run a cell when a button is pressed
Use cases. For example, you have a cell showing a random sample of data, and you want to resample on button press.

Recipe.

Import packages

import marimo as mo
Create a button without a value, to function as a trigger.

button = mo.ui.button()
button
Reference the button in another cell.

# the button acts as a trigger: every time it is clicked, this cell is run
button

# Replace with your custom lgic
import random
random.randint(0, 100)
Run a cell when a button is pressed, but not before
Use cases. Wait for confirmation before executing downstream cells (similar to a form).

Recipe.

Import packages

import marimo as mo
Create a counter button.

button = mo.ui.button(value=0, on_click=lambda count: count + 1)
button
Only execute when the count is greater than 0.

# Don't run this cell if the button hasn't been clicked, using mo.stop.
# Alternatively, use an if expression.
mo.stop(button.value == 0)

mo.md(f""The button was clicked {button.value} times"")
Reveal an output when a button is pressed
Use cases. Incrementally reveal a user interface.

Recipe.

Import packages

import marimo as mo
Create a counter button.

button = mo.ui.button(value=0, on_click=lambda count: count + 1)
button
Show an output after the button is clicked.

mo.md(""#"" + """" * button.value) if button.value > 0 else None
Caching
Cache expensive computations
Use case. Because marimo runs cells automatically as code and UI elements change, it can be helpful to cache expensive intermediate computations. For example, perhaps your notebook computes t-SNE, UMAP, or PyMDE embeddings, and exposes their parameters as UI elements. Caching the embeddings for different configurations of the elements would greatly speed up your notebook.

Recipe.

Use functools to cache function outputs given inputs.

import functools

@functools.cache
def compute_predictions(problem_parameters):
   # replace with your own function/parameters
   ...
Whenever compute_predictions is called with a value of problem_parameters it has not seen, it will compute the predictions and store them in a cache. The next time it is called with the same parameters, instead of recomputing the predictions, it will return the previously computed value from the cache.

See our best practices guide to learn more.",When might I use caching?,"You might use caching when, for example, your notebook computes t-SNE, UMAP, or PyMDE embeddings.","Caching can be useful for storing results of costly computations like t-SNE, UMAP, or PyMDE embeddings to avoid recomputation.","You could use caching to keep track of button clicks in your notebook, ensuring the count is accurate over multiple sessions."
17,"Alan Wake 2
Why the hell did you kill Casey? What the hell were you thinking, man?
This article or a section of this article will contain full, or partial plot spoilers of an Alan Wake game or any other piece of media related to the franchise.
You have been warned...

""This story... is a monster. And monsters wear many faces.""
― Alan Wake

Alan Wake 2 (stylized as Alan Wake II) is a survival-horror video game that released on 27 October 2023 on digital storefronts for the PlayStation 5, Xbox Series X|S and PC through the Epic Games Store. It is the sequel to 2010's Alan Wake. The game had an expansion DLC released on June 8, 2024 called Night Springs and a second expansion DLC, The Lake House, is slated to be released sometime later. The game has four difficulties: Story, Normal, Hard, and Nightmare, the fourth of which is only available in ""The Final Draft"" mode. The Final Draft is a New Game Plus mode for Alan Wake 2, featuring new Manuscript pages, other new collectibles, a new expanded ending, and other changes to the game's story. ""The Final Draft"" was released on December 11, 2023.

Patch notes for Alan Wake 2 updates can be found here.


Contents
1	Synopsis
2	Plot
3	Chapter List
3.1	The Final Draft
3.2	Expansion 1: Night Springs
4	Gameplay
5	Development
5.1	Initial development
5.2	Remedy Connected Universe
5.3	Official development
6	Reception
7	Trivia
8	Gallery
8.1	Official Images
8.2	Concept art
8.3	Concept art (earlier iteration)
9	Videos
10	Sources
Synopsis
Quote1 A string of ritualistic murders threatens Bright Falls, a small-town community surrounded by Pacific Northwest wilderness. Saga Anderson, an accomplished FBI agent with a reputation for solving impossible cases arrives to investigate the murders. Anderson’s case spirals into a nightmare when she discovers pages of a horror story that starts to come true around her.

Alan Wake, a lost writer trapped in a nightmare beyond our world, writes a dark story in an attempt to shape the reality around him and escape his prison. With a dark horror hunting him, Wake is trying to retain his sanity and beat the devil at his own game.

Anderson and Wake are two heroes on two desperate journeys in two separate realities, connected at heart in ways neither of them can understand: reflecting each other, echoing each other, and affecting the worlds around them.

Fueled by the horror story, supernatural darkness invades Bright Falls, corrupting the locals and threatening the loved ones of both Anderson and Wake. Light is their weapon—and their safe haven — against the darkness they face. Trapped in a sinister horror story where there are only victims and monsters, can they break out to be the heroes they need to be? Quote2
― Epic Games Store page description
Plot
See also: Alan Wake, Alan Wake's American Nightmare, and Control
In 2023, thirteen years after the events of Alan Wake, a naked man emerges from the dark shores of Cauldron Lake, experiencing visions of a man violently screaming before he is found and has his heart cut out by a group of men wearing deer masks.

FBI Special Agent Saga Anderson and her partner Alex Casey are dispatched to the town of Bright Falls, Washington to investigate a series of ritualistic murders. They investigate the latest victim, the naked man, who is revealed as former FBI Agent Robert Nightingale. It is believed he was murdered by a group calling themselves the ""Cult of the Tree"". In addition to Nightingale's corpse, Saga finds a mysterious manuscript page that seems to predict the future. While in the town, they encounter Sheriff Tim Breaker, who promises to assist their investigation, as well as waitress Rose Marigold, who recognizes Saga and acts like Saga was a local of the area, despite this being her first visit to the town. She also claims Saga's daughter Logan drowned several years ago, despite being alive in Virginia with her father. At the morgue, Saga then performs an autopsy on Nightingale's corpse, but it suddenly reanimates, in search of the ""Clicker"", and escapes the morgue after Breaker mysteriously vanishes.

As they pursue Nightingale to Cauldron Lake, Saga uses her psychic powers to investigate the scene. Casey reveals he had investigated a murder cult in New York City dedicated to bringing back the missing author Alan Wake by reenacting the murders described in his books, and that Nightingale came to Bright Falls to pursue Alan thirteen years prior. Saga encounters Nightingale, now converted into what the manuscript called a ""Taken"", and is forced to kill him. Saga then finds a very-shaken Alan Wake washed up on the shore of the lake and takes him into custody while also discovering evidence that an organization called the Federal Bureau of Control has a presence in Bright Falls. Saga and Casey take Alan back to the Elderwood Palace Lodge in their field office where he recounts how he escaped from a dream-like dimension called the Dark Place.

While trapped in the Dark Place, Alan continually tried to find a way to escape. After appearing in a mysterious talk show called ""In Between With Mr. Door"", Alan found an Angel Lamp once belonging to Thomas Zane and connected to the Clicker that, in combination with his writing ability, allowed him to manipulate the Dark Place to better navigate it. Alan began navigating a dark, twisted version of New York City, following the trail of Alex Casey's investigation of the ""Cult of the Word"" led by Alan's evil doppelganger Scratch, who survived his erasure from existence, which brought him through the various scenes of the murders committed by the cult. Along the way, Alan also encountered Breaker, who was searching for the talk show host, Warlin Door, believing him to be responsible for trapping him in the Dark Place. Alan also occasionally made brief contact with Saga, the two of them trading vital information when they could. After believing he had killed Tom Zane, who had gone insane from his captivity inside the Dark Place, Alan was contacted by an alternative version of himself, explaining that his repeated attempts to escape the Dark Place are causing him to experience time loops.

Back in the present, Alan explains that he wrote a new novel, ""Return"", that helped him escape the Dark Place. However, Scratch re-edited the manuscript into a horror story now taking effect in reality. Alan warns that Scratch is searching for the Clicker, which is the key he needs to free the malevolent Dark Presence completely, but also the key to permanently defeating it. When one of the manuscript pages mentioning the Cult of the Tree possesses the Clicker, Saga decides to follow its trail in Watery and realizes that ""Return"" has rewritten her past so that her daughter Logan drowned in an accident. Angered that Alan wrote her and Logan into his story, Saga recovers the Clicker, but before she can get it to Alan, agents from the FBC led by Agent Kiran Estevez arrive and apprehend him as well as the Cult leaders, revealed to be town entrepreneurs Ilmo and Jaakko Koskela.

With no other options, Saga goes to the Valhalla Nursing Home and tracks down Odin and Tor Anderson, who know more about the Clicker. As she communicates with them and rescues Tor from a Taken Cynthia Weaver, she learns that Odin and Tor are actually her grand-uncle and grandfather, respectively, and she inherited their seer abilities, allowing her to discern the changes to reality ""Return"" is causing. Odin and Tor also explain that the Clicker does not do anything by itself, but instead dramatically enhances the creative power of the person using it, which is why it is important to Alan and Scratch. Saga then heads back to Bright Falls to get the Clicker to Alan, but finds out that the Alan who escaped Cauldron Lake was actually Scratch. With his identity now exposed, Scratch kills Jaakko and escapes from captivity, attempting to take the Clicker from Saga. He is temporarily thwarted and banished by the FBC.

Ilmo reveals that he and Jakko formed the cult in order to scare townsfolk away from the dangers of the lake, while they perform their ritual killings on whatever Taken emerges from it, such as Nightingale. Realizing that Alan is still trapped in the Dark Place, Saga enlists the help of Casey, Odin, Tor, and Estevez to carry out a ritual to summon him to the real world. Meanwhile, Alan continues to try and find a way out of the Dark Place, eventually making his way to his old apartment. There, he discovers his wife Alice had been tormented with visions of Scratch, eventually leading to her apparent suicide. In anger, Alan kills who he believes is Scratch, but is actually a version of himself attempting to fix Scratch's ending of ""Return"", perpetuating the loop.

Back in the real world, the summoning ritual fails to summon Alan in the current time and instead was responsible for his initial appearance earlier in the story. Both Saga and Alan come to the realization that Alan and Scratch were always the same person, with Scratch being Alan, who is possessed by the Dark Presence at the end of every loop, and thus indirectly responsible for Alice's death. Scratch arrives at the summoning site and Saga is able to banish him from Alan's body, only for Scratch to possess Casey instead, steal the Clicker, and throw Saga into the Dark Place.

With Scratch in possession of the Clicker, Alan concludes that the only way to stop him now is to find the manuscript and write a completely new ending for ""Return"". He returns to his writing room and tries to work out how to write a perfect ending that saves everybody while staying consistent with the horror genre. Meanwhile, trapped in her mind place, Saga fights off the Dark Presence's attempt to overwhelm her with her own negative emotions and self-doubt. Now in the Dark Place proper, she reunites with Breaker, who remains there in his search for Door, heavily implied to be Saga's missing father. She then receives aid from an anonymous woman who directs her to the Clicker and a Bullet of Light. Saga takes the two items and escapes back to the real world by mimicking Door's actions on a manuscript page given to her by Breaker. With the Clicker, Alan is able to banish Scratch from Casey's body. Scratch returns to possessing Alan, and Saga shoots him with the Bullet of Light, seemingly killing him and Scratch. As Casey recovers from his possession, Saga tries to call Logan to confirm her safety, but the scene cuts short before any answer can be heard.

In a post-credits scene, a recording left behind by Alice reveals that she had managed to fully regain her memories of what happened to Alan after consulting with the FBC at the Oldest House. She had tricked Alan into thinking she committed suicide by choosing to return the Dark Place as part of a plan to help him eventually escape, explaining that the only way he can escape the loops is through ""ascension."" Alan then revives from his gunshot wound and says, ""It's not a loop, it's a spiral.""

In the ""Final Draft"" ending, Alan realizes that the Bullet of Light was meant to cleanse a part of himself the Dark Presence used to create Scratch, finally killing his doppelgänger for good while finishing the spiral and freeing Alan from the loop. Saga's call connects, confirming Logan's survival, and Alan revives soon after to the surprise of her and Casey, declaring himself the master of not just two worlds, but many.

Chapter List
The chapters/parts listed here are played in the following order:
Prologue: The Cult
Return 1: Invitation
Return 2: The Heart
Initiation 1: Late Night
Initiation 2: Casey
Initiation 3: Haunting
Players have the choice to play the following of Alan and Saga's chronological chapters/parts in any order they wish:
Return 3: Local Girl
Return 4: No Chance
Return 5: Old Gods
Return 6: Scratch
Initiation 4: We Sing
Initiation 5: Room 665
Initiation 6: Return
Initiation 7: Masks
Initiation 8: Zane's Film
The chapters/parts listed here are past the point of no return and are played in the following order:
Return 7: Summoning
Initiation 9: Gone
Return 8: Deerfest
Return 9: Come Home
The Final Draft
Remedy released a New Game Plus update to the game on December 11th, 2023 named ""The Final Draft"".

Expansion 1: Night Springs
Set as ""episodes"" of the Night Springs TV show, these can be played in any order the player wishes.

Number One Fan
North Star
Time Breaker
Gameplay
Similar to the original, the game is a third-person shooter, with players using light to burn away the darkness of the enemy and various weapons to fight against the dark forces as well as various cult members. Unlike the first game, which was an action-adventure game, Alan Wake 2 emphasizes survival-horror gameplay. Players have an inventory with limited space, where they will need to conserve their ammo and healing items. Health items themselves consist of med kits and painkillers, with Safe Havens only healing the player to take them out of a ""critical state."" Players also encounter various puzzles and locked boxes that they'll need to solve in order to obtain upgraded gear.

The game features two distinct campaigns, one where you play as the titular Alan Wake, and one where you play a new protagonist, Saga Anderson. The two campaigns blend together, eventually allowing you to switch between the two at various points, using a dark puddle found in certain Break Rooms if the player wishes, with the two stories both foreshadowing and echoing each other. Eventually though, the player will be required to complete both stories before progressing past a point of no return.

Saga’s story takes place in the Pacific Northwest, consisting of three hubs: the small town of Bright Falls, the stunning primordial forest surrounding the mysterious Cauldron Lake, and the run-down town of Watery. Alan's story takes place solely within the Dark Place in a warped version of New York City, with his reality shifting and looping. Similarly to the episodic nature of the original, the narrative is divided into chapters, which each having their own accompanying end song. Between chapters, players are returned to the hubs and are allowed to explore or move to the next chapter at their own pace.

Whilst Saga's story involves a lot of talking to various townsfolk around the area in order to progress in her environment, Alan uses an Angel Lamp to allow him to change a scene by transferring light from one area of New York to another. Both characters have their own ""mind palaces"" to help progress their stories, with Alan having his Writer's Room to help change the story and Saga having her Mind Place to help her with her investigations, both of which can be accessed at the press of a button.

Development
Initial development
Throughout 2011 and 2012, several hints had been dropped of a potential sequel to Alan Wake. These hints include when ""Alan Wake 2"" was shown on the Artist Althea Suarez Gata's CV, only for it to be removed on the very same day. Whilst Alan Wake's American Nightmare (though the name was unknown at the time) was revealed not long after this hiccup, fans had been trying to find more evidence of a direct sequel. In Alan Wake's American Nightmare, the credits to the game also then indicated that ""Alan Wake's journey through the night will continue"".

Also in 2012, Sam Lake tweeted a link to a ""Blogspot"" called ""This House of Dreams."" At first, the site seemed like a mere blog for someone refurbishing a house, but one such blog talks about a dream the blogger had about a man ""wearing a funny jacket with old-fashioned elbow patches"" and that he wanted ""to turn all the lights on."" This tweet came just days before E3 2012, a gaming expo that reveals and shows brand new content of upcoming releases. People also found that the domain ""alanwake2.com"" was also reserved by Remedy Entertainment.

At the Xbox Event on May 21, 2013, Remedy revealed Quantum Break, which would be an exclusive to the newest Xbox console at the time, Xbox One. On February 2016, it was confirmed that it would also come to PC. Fans were disappointed that Alan Wake 2 wasn't revealed, but some still supported Remedy in their new franchise. A day after the Quantum Break announcement, Sam Lake took to YouTube to talk to the fans about why Alan Wake 2 wasn't announced. He revealed that the time just wasn't right yet, but mentioned he had not given up on the franchise.

In April 2015, Remedy announced that Alan Wake 2 had previously gone into the early stage of development shortly after Alan Wake was released, where a video of prototype demo was also released. While in the stage of showing this demo to publishers, Remedy went into conversations with Microsoft and the project was put on hold indefinitely while Quantum Break went into development. The sequel would have introduced new features, many of which were used in Alan Wake's American Nightmare. When asked about the possibility of an Alan Wake sequel being released in the future, Sam Lake replied, ""It's hard to guess,"" but that he would ""love to do that"".

Remedy Connected Universe
Easter eggs in Remedy's 2019 game Control revealed that the game shared the same universe as Alan Wake. Two typewritten pages found within the game (and which were said to have been written by Alan Wake himself) heavily imply that almost ten years had passed since Alan's experience in Bright Falls, and that it was not an isolated event, but rather what the Federal Bureau of Control classifies as an ""Altered World Event"" (AWE). In this way, Control revealed additional information about the events involving the Dark Presence, especially given the nature of its own primary enemy, the Hiss.

Furthermore, the second DLC for Control, AWE, was released in August 2020. While the letters can simply stand for ""Altered World Event,"" they also resemble Alan's own name. In addition to this, the top half of the cover art depicted a flashlight-wielding person in a dark forest, while the bottom half depicted a second figure surrounded by red, which figures prominently with the Hiss in Control.

In an interview given on May 14, 2020 with VG24/7, Sam Lake commented on this, explaining, ""Through AWE you’ll learn more about the Bureau’s involvement, research, and interest in Alan Wake and the events that took place 10 years ago,” Lake said. “We’re really happy to give fans of the original game a bit more of Alan Wake-related content.""[1] This suggested a deeper connection, possibly even a future crossover, between the events of Control and Alan Wake.

The plot of AWE confirmed this, tying up some loose ends from the previous Alan Wake entries while also setting up details which would come in a sequel work. In the ending of AWE, an alarm sounds in the Federal Bureau of Control that another AWE appears to be happening again in Bright Falls. This, along with Alan's narration, seemed to indicate Remedy's next game could be a follow up to Alan Wake.

Official development
In March 2020, Remedy signed a deal with Epic Games to publish two single-player games under Epic's new publishing initiative. The games were said to be part of ""the same franchise"". In March 2021, Remedy CEO Tero Virtala confirmed that they were indeed working on two unannounced project with Epic Games that are part of the same franchise, one smaller scale and one AAA in size. In April 2021, GamesBeat reporter Jeff Grubb told viewers that ""I've heard that Remedy is going to be making Alan Wake 2,"" as part of the Remedy-Epic deal. Grubb went on to say that the game ""should kind of be the follow-up that fans of that series want,"" but that there's little extra information and no word on an official announcement.

On the 7 September 2021, Alan Wake Remastered was revealed by Sam Lake, of which some people believed to have been the smaller project mentioned in March 2021, and the other AAA from the same franchise was to be Alan Wake 2. With the reveal of Alan Wake Remastered, which indicated Remedy are trying to generate interest in the franchise, a sequel was looking more and more likely.

At The Game Awards 2021, Alan Wake 2 was officially announced for 2023 and would be Remedy's first survival-horror video game. Like Quantum Break and Control, it was announced that Alan Wake 2 would use the Northlight engine and be a third-person game. On a later interview with IGN, Sam Lake revealed that the game would have a Mature 17+ age rating.

On May 24, 2023, Sony hosted a PlayStation Showcase livestream, in which a gameplay trailer for Alan Wake 2 was revealed, with a release date of October 17, 2023. It was revealed that players would control two protagonists within their own campaigns, Alan Wake himself and a new protagonist, Saga Anderson. At Summer Game Fest on June 8, 2023, Sam Lake shared further information on the ways Alan and Saga's campaigns would be connected to each other. Additionally, more gameplay and combat mechanics were shown.

On August 17, 2023, the game was delayed by 10 days to October 27, 2023 to make way for various other games also releasing in October. At Gamescom 2023, Alan Wake's side of the game in the Dark Place was focused on in a new trailer, which was later followed by a lengthy Alan-centric gameplay featured behind closed doors.

Reception
Alan Wake 2 received near universal acclaim from video game critics. Itr received five nominations at the 2023 Golden Joystick Awards and won the Critic's Choice Award. It was nominated for eight awards at The Game Awards 2023, and won for Best Game Direction, Best Narrative, and Best Art Direction.

The game went on to win more awards in Finland and around the world.

Trivia
Ilkka Villi and Matthew Porretta both reprise their role as Alan Wake in the sequel. James McCaffrey reprises his role as Alex Casey, who he previously voiced in the manuscript pages of The Sudden Stop.
Brett Madden, who played Alice Wake in the first game, sadly passed away in September 2020. She was memorialized in the credits of the game. Alice was recast in the sequel, now played by Christina Cole.
While the first game was an action-adventure game that implemented horror elements, Alan Wake 2 is a full-blown survival-horror game.
Unlike the first game that was published by Microsoft Studios, the sequel is published by Epic Games Publishing.
The game was initially a digital-only release due to various shifts towards a digital-only market. This was also done to keep the price of the game down at launch. However despite initially saying there were no plans for a physical release, in June 2024 along with a trailer and release date announcement of the first DLC it was revealed that a physical version would be released that October, a year after the digital release. Both a physical version of the digital deluxe version (inclusive of the DLC) and a limited run collector's edition were announced.
The second entry in Remedy's Max Payne series, Max Payne 2: The Fall of Max Payne, also had two playable protagonists (Max Payne and Mona Sax).",Where was Alan Wake 2 officially announced?,Alan Wake 2 was officially announced at The Game Awards 2021.,Alan Wake 2 was revealed at The Game Awards in 2021.,Alan Wake 2 was officially announced at the PlayStation Showcase in 2021.
6,"Why do we need to regulate the use of Artificial Intelligence?
The potential benefits of Artificial Intelligence (AI) for our societies are manifold from improved medical care to better education. Faced with the rapid technological development of AI, the EU decided to act as one to harness these opportunities.

The EU AI Act is the world's first comprehensive AI law. It aims to address risks to health, safety and fundamental rights. The regulation also protects democracy, rule of law and the environment.

While most AI systems will pose low to no risk, certain AI systems create risks that need to be addressed to avoid undesirable outcomes.

For example, the opacity of many algorithms may create uncertainty and hamper the effective enforcement of the existing legislation on safety and fundamental rights. Responding to these challenges, legislative action was needed to ensure a well-functioning internal market for AI systems where both benefits and risks are adequately addressed.

This includes applications such as biometric identification systems or AI decisions touching on important personal interests, such as in the areas of recruitment, education, healthcare, or law enforcement.

Recent advancements in AI gave rise to ever more powerful Generative AI. So-called “general-purpose AI models” that are being integrated in numerous AI systems are becoming too important for the economy and society not to be regulated. In light of potential systemic risks, the EU puts in place effective rules and oversight.

Which risks will the new AI rules address?
The uptake of AI systems has a strong potential to bring societal benefits, economic growth and enhance EU innovation and global competitiveness. However, in certain cases, the specific characteristics of certain AI systems may create new risks related to user safety and fundamental rights. Some powerful AI models that are being widely used could even pose systemic risks.

This leads to legal uncertainty for companies and potentially slower uptake of AI technologies by businesses and citizens, due to the lack of trust. Disparate regulatory responses by national authorities would risk fragmenting the internal market.

To whom does the AI Act apply?
The legal framework will apply to both public and private actors inside and outside the EU as long as the AI system is placed on the Union market or its use affects people located in the EU.

It can concern both providers (e.g. a developer of a CV-screening tool) and deployers of high-risk AI systems (e.g. a bank buying this screening toolImporters of AI systems will also have to ensure that the foreign provider has already carried out the appropriate conformity assessment procedure, bears a European Conformity (CE) marking and is accompanied by the required documentation and instructions of use.

In addition, certain obligations are foreseen for providers of general-purpose AI models, including large generative AI models.

Providers of free and open-source models are exempted from most of these obligations. This exemption does not cover obligations for providers of general purpose AI models with systemic risks.

Obligations also do not apply to research, development and prototyping activities preceding the release on the market, and the regulation furthermore does not apply to AI systems that are exclusively for military, defence or national security purposes, regardless of the type of entity carrying out those activities.

What are the risk categories?
The Commission proposes a risk–based approach, with four levels of risk for AI systems, as well as an identification of risks specific to general purpose models:

Minimal risk: All other AI systems can be developed and used subject to the existing legislation without additional legal obligations. The vast majority of AI systems currently used or likely to be used in the EU fall into this category. Voluntarily, providers of those systems may choose to apply the requirements for trustworthy AI and adhere to voluntary codes of conduct.
High-risk: A limited number of AI systems defined in the proposal, potentially creating an adverse impact on people's safety or their fundamental rights (as protected by the EU Charter of Fundamental Rights), are considered to be high-risk. Annexed to the Act is the list of high-risk AI systems, which can be reviewed to align with the evolution of AI use cases.
These also include safety components of products covered by sectorial Union legislation. They will always be considered high-risk when subject to third-party conformity assessment under that sectorial legislation.
Unacceptable risk: A very limited set of particularly harmful uses of AI that contravene EU values because they violate fundamental rights and will therefore be banned:
Social scoring for public and private purposes;
Exploitation of vulnerabilities of persons, use of subliminal techniques;
Real-time remote biometric identification in publicly accessible spaces by law enforcement, subject to narrow exceptions (see below);
Biometric categorisation of natural persons based on biometric data to deduce or infer their race, political opinions, trade union membership, religious or philosophical beliefs or sexual orientation. Filtering of datasets based on biometric data in the area of law enforcement will still be possible;
Individual predictive policing;
Emotion recognition in the workplace and education institutions, unless for medical or safety reasons (i.e. monitoring the tiredness levels of a pilot);
Untargeted scraping of internet or CCTV for facial images to build-up or expand databases.
Specific Transparency risk: For certain AI systems specific transparency requirements are imposed, for example where there is a clear risk of manipulation (e.g. via the use of chatbots). Users should be aware that they are interacting with a machine.
In addition, the AI Act considers systemic risks which could arise from general-purpose AI models, including large generative AI models. These can be used for a variety of tasks and are becoming the basis for many AI systems in the EU. Some of these models could carry systemic risks if they are very capable or widely used. For example, powerful models could cause serious accidents or be misused for far-reaching cyberattacks. Many individuals could be affected if a model propagates harmful biases across many applications.

How do I know whether an AI system is high-risk?
Together with a clear definition of ‘high-risk', the Act sets out a solid methodology that helps identifying high-risk AI systems within the legal framework. This aims to provide legal certainty for businesses and other operators.

The risk classification is based on the intended purpose of the AI system, in line with the existing EU product safety legislation. It means that the classification of the risk depends on the function performed by the AI system and on the specific purpose and modalities for which the system is used.

Annexed to the Act is a list of use cases which are considered to be high-risk. The Commission will ensure that this list is kept up to date and relevant. Systems on the high-risk list, that perform narrow procedural tasks, improve the result of previous human activities, do not influence human decisions or do purely preparatory tasks are not considered high-risk. However, an AI system shall always be considered high-risk if it performs profiling of natural persons.

What are the obligations for providers of high-risk AI systems?
Before placing a high-risk AI system on the EU market or otherwise putting it into service, providers must subject it to a conformity assessment. This will allow them to demonstrate that their system complies with the mandatory requirements for trustworthy AI (e.g. data quality, documentation and traceability, transparency, human oversight, accuracy, cybersecurity and robustness). This assessment has to be repeated if the system or its purpose are substantially modified.

AI systems being safety components of products covered by sectorial Union legislation will always be deemed high-risk when subject to third-party conformity assessment under that sectorial legislation. Also, for biometric systems a third-party conformity assessment is always required.

Providers of high-risk AI systems will also have to implement quality and risk management systems to ensure their compliance with the new requirements and minimise risks for users and affected persons, even after a product is placed on the market.

High-risk AI systems that are deployed by public authorities or entities acting on their behalf will have to be registered in a public EU database, unless those systems are used for law enforcement and migration. The latter will have to be registered in a non-public part of the database that will be only accessible to relevant supervisory authorities.

Market surveillance authorities will support post-market monitoring through audits and by offering providers the possibility to report on serious incidents or breaches of fundamental rights obligations of which they have become aware. Any market surveillance authority may authorise placing on the market of specific high-risk AI for exceptional reasons.

In case of a breach, the requirements will allow national authorities to have access to the information needed to investigate whether the use of the AI system complied with the law.

What are examples for high-risk use cases as defined in Annex III?
Certain critical infrastructures for instance in the fields of road traffic and the supply of water, gas, heating and electricity;
Education and vocational training, e.g. to evaluate learning outcomes and steer the learning process and monitoring of cheating;
Employment, workers management and access to self-employment, e.g. to place targeted job advertisements, to analyse and filter job applications, and to evaluate candidates;
Access to essential private and public services and benefits (e.g. healthcare), creditworthiness evaluation of natural persons, and risk assessment and pricing in relation to life and health insurance;
Certain systems used in the fields of law enforcement, border control, administration of justice and democratic processes;
Evaluation and classification of emergency calls;
Biometric identification, categorisation and emotion recognition systems (outside the prohibited categories);
Recommender systems of very large online platforms are not included, as they are already covered in other legislation (DMA/DSA).
How are general-purpose AI models being regulated?
General-purpose AI models, including large generative AI models, can be used for a variety of tasks. Individual models may be integrated into a large number of AI systems.

It is important that a provider wishing to build upon a general-purpose AI model has all the necessary information to make sure its system is safe and compliant with the AI Act.

Therefore, the AI Act obliges providers of such models to disclose certain information to downstream system providers. Such transparency enables a better understanding of these models.

Model providers additionally need to have policies in place to ensure that that they respect copyright law when training their models.

In addition, some of these models could pose systemic risks, because they are very capable or widely used.

For now, general purpose AI models that were trained using a total computing power of more than 10^25 FLOPs are considered to carry systemic risks, given that models trained with larger compute tend to be more powerful. The AI Office (established within the Commission) may update this threshold in light of technological advances, and may furthermore in specific cases designate other models as such based on further criteria (e.g. number of users, or the degree of autonomy of the model).

Providers of models with systemic risks are therefore mandated to assess and mitigate risks, report serious incidents, conduct state-of-the-art tests and model evaluations, ensure cybersecurity and provide information on the energy consumption of their models.

For this, they are asked to engage with the European AI Office to draw up Codes of Conduct as the central tool to detail out the rules in cooperation with other experts. A scientific panel will play a central role in overseeing general-purpose AI models.

Why is 10^25 FLOPs an appropriate threshold for GPAI with systemic risks?
This threshold captures the currently most advanced GPAI models, namely OpenAI's GPT-4 and likely Google DeepMind's Gemini.

The capabilities of the models above this threshold are not yet well enough understood. They could pose systemic risks, and therefore it is reasonable to subject their providers to the additional set of obligations.

FLOP is a first proxy for model capabilities, and the exact FLOP threshold can be updated upwards or downwards by the European AI Office, e.g. in the light of progress in objectively measuring model capabilities and of developments in the computing power needed for a given performance level.

The AI Act can be amended to update the FLOP threshold (by means of a delegated act).

Is the AI Act future-proof?
The Regulation introduces different level of risks and provides clear definitions, including for GPAI.

The legislation sets result-oriented requirements for high-risk AI systems but leaves the concrete technical solutions and operationalisation primarily to industry-driven standards that will ensure that the legal framework is flexible to be adapted to different use cases and to enable new technological solutions.

In addition, the AI Act can be amended by delegated and implementing acts, including to update the FLOP threshold (delegated act), to add criteria for classifying the GPAI models as presenting systemic risks (delegated act), to amend modalities to establish regulatory sandboxes and elements of the real-world testing plan (implementing acts).

How does the AI Act regulate biometric identification?
The use of real-time remote biometric identification in publicly accessible spaces (i.e. facial recognition using CCTV) for law enforcement purposes is prohibited, unless used in one of the following cases:

Law enforcement activities related to 16 specified crimes;
Targeted search for specific victims, abduction, trafficking and sexual exploitation of human beings, and missing persons; or
The prevention of threat to the life or physical safety of persons or response to the present or foreseeable threat of a terror attack.
The list of the 16 crimes contains:

Terrorism;
Trafficking in human beings;
Sexual exploitation of children and child sexual abuse material;
Illicit trafficking in narcotic drugs and psychotropic substances;
Illicit trafficking in weapons, munitions and explosives;
Murder;
Grievous bodily injury;
Illicit trade in human organs and tissue;
Illicit trafficking in nuclear or radioactive materials;
Kidnapping, illegal restraint and hostage-taking;
Crimes within the jurisdiction of the International Criminal Court;
Unlawful seizure of aircraft/ships;
Rape;
Environmental crime;
Organised or armed robbery;
Sabotage, participation in a criminal organisation involved in one or more crimes listed above.
Real-time remote biometric identification by law enforcement authorities would be subject to prior authorisation by a judicial or independent administrative authority whose decision is binding. In case of urgency, authorisation can be done within 24 hours; if the authorisation is rejected all data and output needs to be deleted.

It would need to be preceded by prior fundamental rights impact assessment and should be notified to the relevant market surveillance authority and the data protection authority. In case of urgency, the use of the system may be commenced without the registration.

Usage of AI systems for post remote biometric identification (identification of persons in previously collected video material) of persons under investigation requires prior authorisation by a judicial authority or an independent administrative authority, and notification of the data protection and market surveillance authority.

Why are particular rules needed for remote biometric identification?
Biometric identification can take different forms. It can be used for user authentication i.e. to unlock a smartphone or for verification/authentication at border crossings to check a person's identity against his/her travel documents (one-to-one matching).

Biometric identification could also be used remotely, for identifying people in a crowd, where for example an image of a person is checked against a database (one-to-many matching).

Accuracy of systems for facial recognition can vary significantly based on a wide range of factors, such as camera quality, light, distance, database, algorithm, and the subject's ethnicity, age or gender. The same applies for gait and voice recognition and other biometric systems. Highly advanced systems are continuously reducing their false acceptance rates.

While a 99% accuracy rate may sound good in general, it is considerably risky when the result leads to the suspicion of an innocent person. Even a 0.1% error rate is a lot if it concerns tens of thousands of people.

How do the rules protect fundamental rights?
There is already a strong protection for fundamental rights and for non-discrimination in place at EU and Member State level, but complexity and opacity of certain AI applications (‘black boxes') pose a problem.

A human-centric approach to AI means to ensure AI applications comply with fundamental rights legislation. Accountability and transparency requirements for the use of high-risk AI systems, combined with improved enforcement capacities, will ensure that legal compliance is factored in at the development stage.

Where breaches occur, such requirements will allow national authorities to have access to the information needed to investigate whether the use of AI complied with EU law.

Moreover, the AI Act requires that deployers that are bodies governed by public law or private operators providing public services and operators providing high-risk systems to conduct a fundamental rights impact assessment.

What is a fundamental rights impact assessment? Who has to conduct such an assessment, and when?
The use of a high-risk AI system may produce an impact on fundamental rights. Therefore, deployers that are bodies governed by public law or private operators providing public services, and operators providing high-risk systems shall perform an assessment of the impact on fundamental rights and notify the national authority of the results.

The assessment shall consist of a description of the deployer's processes in which the high-risk AI system will be used, of the period of time and frequency in which the high-risk AI system is intended to be used, of the categories of natural persons and groups likely to be affected by its use in the specific context, of the specific risks of harm likely to impact the affected categories of persons or group of persons, a description of the implementation of human oversight measures and of measures to be taken in case of the materialization of the risks.

If the provider already met this obligation through the data protection impact assessment, the fundamental rights impact assessment shall be conducted in conjunction with that data protection impact assessment.

How does this regulation address racial and gender bias in AI?
It is very important that AI systems do not create or reproduce bias. Rather, when properly designed and used, AI systems can contribute to reduce bias and existing structural discrimination, and thus lead to more equitable and non-discriminatory decisions (e.g. in recruitment).

The new mandatory requirements for all high-risk AI systems will serve this purpose. AI systems must be technically robust to guarantee that the technology is fit for purpose and false positive/negative results are not disproportionately affecting protected groups (e.g. racial or ethnic origin, sex, age etc.).

High-risk systems will also need to be trained and tested with sufficiently representative datasets to minimise the risk of unfair biases embedded in the model and ensure that these can be addressed through appropriate bias detection, correction and other mitigating measures.

They must also be traceable and auditable, ensuring that appropriate documentation is kept, including of the data used to train the algorithm that would be key in ex post investigations.

Compliance system before and after they are placed on the market will have to ensure these systems are regularly monitored and potential risks are promptly addressed.

When will the AI Act be fully applicable?
Following its adoption by the European Parliament and the Council, the AI Act shall enter into force on the twentieth day following that of its publication in the official Journal. It will be fully applicable 24 months after entry into force, with a graduated approach as follows:

6 months after entry into force, Member States shall phase out prohibited systems;
12 months: obligations for general purpose AI governance become applicable;
24 months: all rules of the AI Act become applicable including obligations for high-risk systems defined in Annex III (list of high-risk use cases);
36 months: obligations for high-risk systems defined in Annex II (list of Union harmonisation legislation) apply.
How will the AI Act be enforced?
Member States hold a key role in the application and enforcement of this Regulation. In this respect, each Member State should designate one or more national competent authorities to supervise the application and implementation, as well as carry out market surveillance activities.

To increase efficiency and to set an official point of contact with the public and other counterparts, each Member State should designate one national supervisory authority, which will also represent the country in the European Artificial Intelligence Board.

Additional technical expertise will be provided by an advisory forum, representing a balanced selection of stakeholders, including industry, start-ups, SMEs, civil society and academia.

In addition, the Commission will establish a new European AI Office, within the Commission, which will supervise general-purpose AI models, cooperate with the European Artificial Intelligence Board and be supported by a scientific panel of independent experts.

Why is a European Artificial Intelligence Board needed and what will it do?
The European Artificial Intelligence Board comprises high-level representatives of competent national supervisory authorities, the European Data Protection Supervisor, and the Commission. Its role is to facilitate a smooth, effective and harmonised implementation of the new AI Regulation.

The Board will issue recommendations and opinions to the Commission regarding high-risk AI systems and on other aspects relevant for the effective and uniform implementation of the new rules. Finally, it will also support standardisation activities in the area.

What are the tasks of the European AI Office?
The AI Office has as its mission to develop Union expertise and capabilities in the field of artificial intelligence and to contribute to the implementation of Union legislation of artificial intelligence in a centralised structure.

In particular, the AI Office shall enforce and supervise the new rules for general purpose AI models. This includes drawing up codes of practice to detail out rules, its role in classifying models with systemic risks and monitoring the effective implementation and compliance with the Regulation. The latter is facilitated by the powers to request documentation, conduct model evaluations, investigate upon alerts and request providers to take corrective action.

The AI Office shall ensure coordination regarding artificial intelligence policy and collaboration between involved Union institutions, bodies and agencies as well as with experts and stakeholders. In particular, it will provide a strong link with the scientific community to support the enforcement, serve as international reference point for independent experts and expert organisations and facilitate exchange and collaboration with similar institutions across the globe.

What is the difference between the AI Board, AI Office, Advisory Forum and Scientific Panel of independent experts?
The AI Board has extended tasks in advising and assisting the Commission and the Member States.

The AI Office is to be established within the Commission and shall work to develop Union expertise and capabilities in the field of artificial intelligence and to contribute to the implementation of Union legislation of artificial intelligence. Particularly, the AI Office shall enforce and supervise the new rules for general purpose AI models.

The Advisory Forum will consist of a balanced selection of stakeholders, including industry, start-ups, SMEs, civil society and academia. It shall be established to advise and provide technical expertise to the Board and the Commission, with members appointed by the Board among stakeholders.

The Scientific Panel of independent experts supports the implementation and enforcement of the Regulation as regards GPAI models and systems, and the Member States would have access to the pool of experts.

What are the penalties for infringement?
When AI systems are put on the market or in use that do not respect the requirements of the Regulation, Member States will have to lay down effective, proportionate and dissuasive penalties, including administrative fines, in relation to infringements and communicate them to the Commission.

The Regulation sets out thresholds that need to be taken into account:

Up to €35m or 7% of the total worldwide annual turnover of the preceding financial year (whichever is higher) for infringements on prohibited practices or non-compliance related to requirements on data;
Up to €15m or 3% of the total worldwide annual turnover of the preceding financial year for non-compliance with any of the other requirements or obligations of the Regulation, including infringement of the rules on general-purpose AI models;
Up to €7.5m or 1.5% of the total worldwide annual turnover of the preceding financial year for the supply of incorrect, incomplete or misleading information to notified bodies and national competent authorities in reply to a request;
For each category of infringement, the threshold would be the lower of the two amounts for SMEs and the higher for other companies.
In order to harmonise national rules and practices in setting administrative fines, the Commission, counting on the advice of the Board, will draw up guidelines.

As EU Institutions, agencies or bodies should lead by example, they will also be subject to the rules and to possible penalties; the European Data Protection Supervisor will have the power to impose fines to them.

What can individuals do that are affected by a rule violation?
The AI Act foresees a right to lodge a complaint with a national authority. On this basis national authorities can launch market surveillance activities, following the procedures of the market surveillance regulations.

Additionally, the proposed AI Liability Directive aims to provide persons seeking compensation for damage caused by high-risk AI systems with effective means to identify potentially liable persons and obtain relevant evidence for a damage claim. For this purpose, the proposed Directive provides for the disclosure of evidence about specific high-risk AI systems that are suspected of having caused damage.

Moreover, the revised Product Liability Directive will ensure that compensation is available to individuals who suffer death, personal injury or property damage that is caused by a defective product in the Union and clarify that AI systems and products that integrate AI systems are also covered by existing rules.

How do the voluntary codes of conduct for high-risk AI systems work?
Providers of non-high-risk applications can ensure that their AI system is trustworthy by developing their own voluntary codes of conduct or adhering to codes of conduct adopted by other representative associations.

These will apply simultaneously with the transparency obligations for certain AI systems.

The Commission will encourage industry associations and other representative organisations to adopt voluntary codes of conduct.

How do the codes of practice for general purpose AI models work?
The Commission invites providers of general-purpose AI models and other experts to jointly work on a code of practice.

Once developed and approved for this purpose, these codes can be used by the providers of general-purpose AI models to demonstrate compliance with the relevant obligations from the AI Act, following the example of the GDPR.

This is especially relevant to detail out the rules for providers of general-purpose AI model with systemic risks, to ensure future-proof and effective rules for risk assessment and mitigation as well as other obligations.

Does the AI Act contain provisions regarding environmental protection and sustainability?
The objective of the AI proposal is to address risks to safety and fundamental rights, including the fundamental right to a high-level environmental protection. Environment is also one of the explicitly mentioned and protected legal interests.

The Commission is asked to request European standardisation organisations a standardisation deliverable on reporting and documentation processes to improve AI systems resource performance, such as reduction of energy and other resources consumption of the high-risk AI system during its lifecycle, and on energy efficient development of general-purpose AI models.

Furthermore, the Commission by two years after the date of application of the Regulation and every four years thereafter, is asked to submit a report on the review of the progress on the development of standardisation deliverables on energy efficient development of general-purpose models and asses the need for further measures or actions, including binding measures or actions.

In addition, providers of general purpose AI models, which are trained on large data amounts and therefore prone to high energy consumption, are required to disclose energy consumption.

The Commission is asked to develop an appropriate methodology for this assessment.

In case of general purpose AI models with systemic risks, energy efficiency furthermore needs to be assessed.

How can the new rules support innovation?
The regulatory framework can enhance the uptake of AI in two ways. On the one hand, increasing users' trust will increase the demand for AI used by companies and public authorities. On the other hand, by increasing legal certainty and harmonising rules, AI providers will access bigger markets, with products that users and consumers appreciate and purchase. Rules will apply only where strictly needed and in a way that minimises the burden for economic operators, with a light governance structure.

The AI Act further enables the creation of regulatory sandboxes and real world testing, which provide a controlled environment to test innovative technologies for a limited time, thereby fostering innovation by companies, SMEs and start-ups in compliance with the AI Act. These, together with other measures such as the additional Networks of AI Excellence Centres and the Public-Private Partnership on Artificial Intelligence, Data and Robotics, and access to Digital Innovation Hubs and Testing and Experimentation Facilities will help build the right framework conditions for companies to develop and deploy AI.

Real world testing of High-Risk AI systems can be conducted for a maximum of 6 months (which can be prolonged by another 6 months). Prior to testing, a plan needs to be drawn up and submitted it to the market surveillance authority, which has to approve of the plan and specific testing conditions, with default tacit approval if no answer has been given within 30 days. Testing may be subject to unannounced inspections by the authority.

Real world testing can only be conducted given specific safeguards, e.g. users of the systems under real world testing have to provide informed consent, the testing must not have any negative effect on them, outcomes need to be reversible or disregardable, and their data needs to be deleted after conclusion of the testing. Special protection is to be granted to vulnerable groups, i.e. due to their age, physical or mental disability.

Besides the AI Act, how will the EU facilitate and support innovation in AI?
The EU's approach to Artificial Intelligence is based on excellence and trust, aiming to boost research and industrial capacity while ensuring safety and the protection of fundamental rights. People and businesses should be able to enjoy the benefits of AI while feeling safe and protected. The European AI Strategy aims at making the EU a world-class hub for AI and ensuring that AI is human-centric and trustworthy. In April 2021, the Commission presented its AI package, including: (1) a review of the Coordinated Plan on Artificial Intelligence and (2) its proposal for a regulation laying down harmonised rules on AI.

With the Coordinated Plan on AI the European Commission has adopted a comprehensive strategy to promote the development and adoption of AI in Europe. It focuses on creating enabling conditions for AI development and uptake, ensuring excellence thrives from the lab to the market, increasing the trustworthiness of AI, and building strategic leadership in high-impact sectors.

The Commission aims to leverage the activities of Member States by coordinating and harmonizing their efforts, to foster a cohesive and synergistic approach towards AI development and adoption. The Commission also put in place the European AI Alliance platform, which brings together stakeholders from academia, industry, and civil society to exchange knowledge and insights on AI policies.

Moreover, the Coordinated plans foresees several measures that aim to unlock data resources, foster critical computing capacity, increase research capacities, support a European network of Testing and Experimentation Facilities (TEFS) and support SMEs through European Digital Innovation Hubs (EDIHs).

What is the international dimension of the EU's approach?
The AI Act and the Coordinated Plan on AI are part of the efforts of the European Union to be a global leader in the promotion of trustworthy AI at international level. AI has become an area of strategic importance at the crossroads of geopolitics, commercial stakes and security concerns.

Countries around the world are choosing to use AI as a way to signal their desires for technical advancement due to its utility and potential. AI regulation is only emerging and the EU will take actions to foster the setting of global AI standards in close collaboration with international partners in line with the rules-based multilateral system and the values it upholds. The EU intends to deepen partnerships, coalitions and alliances with EU partners (e.g. Japan, the US, India, Canada, South Korea, Singapore, or the Latin American and Caribbean region) as well as multilateral (e.g. OECD, G7 and G20) and regional organisations (e.g. Council of Europe).

*Updated on 14/12/2023",What kinds of models would need to be officially registered?,"High-risk AI systems that are deployed by public authorities or entities acting on their behalf will have to be registered in a public EU database, unless those systems are used for law enforcement and migration. The latter will have to be registered in a non-public part of the database that will be only accessible to relevant supervisory authorities.","AI systems considered high-risk and used by public institutions must be logged in an EU registry, except for those involved in law enforcement and migration, which are recorded privately.","All AI systems, including low-risk ones, must be registered in the EU database whether used by private sectors or public authorities."
14,"My eyes felt like galaxies—holding the swirling glow of countless memories—as I took in our childhood home. Its siding looked like remnants of driftwood after a bonfire. I swore I smelled the smoky char of pine creep into my nostrils. It’s wild how the past stays with you like that. It can feel more visceral and real than the tangible things right in front of you.

“Jesus, it feels like just yesterday.” I placed a trembling hand over my heart, struggling to steady my breath.

My brother, Perry, pulled me into a tight embrace, his strength grounding me like an anchor.

“The house hasn’t changed much,” he said, his voice steady and comforting. “But we have.” His certainty made me question, Have I really changed?

Between the two of us, Perry was as solid and stoic as a mountain range. Good thing, because I was like the wind—flighty and unpredictable. Over the years, Perry had learned to handle even my harshest hurricanes.

Being his older sister—even if only by four minutes—I always wished I’d been his protector rather than the other way around. But that demon burning deep in my belly also flashed a crooked smile, knowing that Perry would never abandon me, especially since I got sober.

I hadn’t had a drink in exactly seven hundred and thirty days, and although it remained unsaid, I knew Perry was terrified of leaving me to my own devices in fear I would relapse.

Our sibling bond was iron-clad. After we lost our parents in the fire (my mother didn’t properly butt out her 2:00 am cigarette and well, the rest is history), all Perry and I had was each other. But let’s call a spade a spade; we were also as fucked up and as co-dependent as it gets. Who mutually decides to visit the catalyst of your alcohol addiction on the anniversary of your sobriety?

The house’s dilapidated front door creaked as Perry gently pushed it open. The rusted metal hinges were holding it up by a thread.

“After you.” Perry gestured me in, squinting from the sunlight. He was a gentleman, even in such obscurity.

As he held the door open, the shallow scar on his right cheek taunted me like some kind of schoolyard bully. His wound often pulled me in like that. Some days, I was sure I would dive right into it and drown. Other days, I prayed to God and the Devil himself to just let me fucking drown, already.

That mark became permanently etched on Perry’s face on the day I quit drinking, exactly seven hundred and thirty days ago. That was the day Perry screamed bloody murder at me from the passenger seat, “Jackie! Stop the fucking car!” But my bloodstream was far too poisoned with Bacardi Limon to listen. All I remember next was my vehicle being wrapped around a tree. I could have died that day, but what truly disturbed me in the middle of the night was the fact that I almost killed Perry.

A lot can happen in seven hundred and thirty days. But I assure you, forgiving yourself isn’t one of them.

“Well? You coming in?” Perry was still holding the door ajar.

I shook it off and gave my brother a knowing glance. I swear, even though we were fraternal, we had twin telepathy. I exhaled and walked in.

“Watch your step,” I warned, my forehead tense.

I imagined the rickety floorboards collapsing, crashing us into what had once been our dad’s “man cave”. That’s where he was passed out, the night of the fire.

“Kids, stay here. Do not move,” our mother demanded after getting us out of the house safely. I remember the black soot on her face and the spiderweb veins in her eyes. She shook us firmly by the forearms. “I’m getting your father.”

Perry and I held each other, shaking. The heat from the inferno felt like standing in a volcano. We never saw our parents again.

Two decades later, there we were—Perry and I—-making our way through the wreckage of our home. It was midday, yet the inside of the house screamed a tone of pale blue midnight. My shoulders were up to my ears, as though we were walking through a haunted house attraction.

I coughed into my forearm. The ocean of dust was thick like butter. As I cleared my lungs, Perry called out from behind me.

“Jacks, look at this! The fireplace,” Perry's voice was filled with awe.

“Unbelievable. It’s still here,” I whispered, a lump forming in my throat.

It was as though a Fairy Godmother breezed by and brought the decaying living room to life with her magical paintbrush. Kind of like in “Titanic”, when they showed the sunken ship underwater, versus in its prestige as it sailed across the Atlantic.

We made our way over to the fireplace and sat cross-legged on the floor.

“This was our favorite spot, remember?” I avoided his gaze, overwhelmed by the flood of memories.

“Yeah,” Perry murmured, his eyes softening with nostalgia.

For a moment, the taste of crispy, fire roasted marshmallows superseded the saturated stench of mildew.

“Remember our s’mores nights?” I asked.

“Duh. What about all our fireplace movie nights?” Perry proceeded to do his best, nasally, childhood impersonation of me, “But mom! I want to watch Beauty and the Beast!! Perry always gets to pick the movie!!”

I punched him in the arm, “First of all, I never sounded like that. And second. So what? I knew what I wanted.”

The corners of Perry’s mouth lifted. He had such a sincere sparkle about him, as though a storm cloud of confetti followed him overhead wherever he went, “You really did, kiddo.”

My chest went heavy. How could Perry love me after everything I had done? After all the relationships I’d ruined? All the jobs I’d lost? All of his relationships I’d ruined? How could he still choose me, when so often I had chosen a forty of Jack Daniels over him?

How could Perry still love me after I almost fucking killed him?

Perry’s gaze widened, “Hey! Remember when Mom would bring out those hot drinks she always made?” He paused, almost as if he was searching for the right term. “Apple… something? Apple ssshhh…”

I snapped my fingers, “Apple-Schnapple!”

“Yes!”

“I mean, looking back it was basically just hot apple cider, but damn it was good.” And it really was.

Our laughs echoed throughout the abandoned asylum we once called home.

Perry leaned back, holding himself up with his hands. “I loved our fireplace hangs. Especially our movie nights down here. But nothing beats our movies up in the projector room.”

I tilted my head, “We never had a projector room.”

Perry playfully “shoo’d” me away.

“No. Perry. I would remember us having a projector room. Our movie nights together were our favorite thing. You even just said it yourself.”

The house suddenly became pin-drop silent as Perry leaned in. ""Memories are quite something, aren’t they?"" The slight shift in his tone made my skin crawl. Perry was always wistful, but this felt different, almost… clinical, ""We often remember things in ways that are… easier for us to digest.""

I was fidgety. “Gees Perry. You sound like Dr. Lasko.”

He seemed to enjoy my little joke.

Dr. Lasko had been my therapist since the accident, and I would go out on a limb and say that he would not have approved of this self-inflicted exposure therapy I was subjecting myself to by visiting the house.

Perry seemingly snapped out of his little therapist moment and went right back to being his sparkly confetti self. As I watched his amicable face scan the mantle above the fireplace, I felt a sickening uneasiness. Imagine you had actually fucking killed him.

“Man, I can still picture all our family photos up there,” Perry’s childlike wonder destroyed me.

My face went flush. I could feel the water rising in my eyes like the tides. How pathetic and infuriating was it that after everything I’d done, I was still somehow the victim.

“Hey.” He took my hand.

“Oh Perry,”  I threw myself into him. “I’m so sorry.”

My brother held me with his usual care that I didn’t deserve.

“Jacks, it’s ok. I’m still here. We’re both still here.”

As my chin rested on my brother’s shoulder, I looked ahead of me at the remains of the house. Something felt off, and it wasn’t just the overall unsettling environment. My brow furrowed. “Wasn’t the doorway to the kitchen on the other side of the living room?”

I felt Perry shrug, “I don’t think so.”

I was staring into the out of place doorway like I was trying to pull a recollection towards me. And that’s when I saw them in the kitchen: the translucent memory of mom and dad. Mom was getting our Apple-Schnapples ready. She was pacing, unlike Dad, who was sitting motionless at the table. His face was planted on its mahogany surface. His glass of Apple-Schnapple was empty, and so was the bottle of Jim Beam beside it.

Mom floated into the living room, our warm beverages in hand and a cigarette in her mouth, “Kids, your father’s not feeling well. Let’s have our Apple-Schnapples in here.”

Oh my God. The bruise on her face.

Perry jarred me back to reality with the gut punch of what he had to say next, “You’re remembering the truth about mom and dad, aren’t you?”

I pushed myself off and away from him. “How did you…”

My brother looked down, delicately tracing the floor with his finger, “We always put them on a pedestal after they died.”

I felt a shiver run down my spine, “What are you talking about?”

As Perry continued to speak, his words grew even more detached. ""Do you remember that first drink Dad ever gave you?""

My eyes darted around the room as my jugular pulsed in my neck. As much as I tried to escape what Perry had just said, I did remember.

I could hear my dad’s slurring words of encouragement, “Come on, Jackie. Just one drink. It’ll be our special time, just you and me.”

The bitterness of that first sip of beer made me squirm, but sharing a “special time” with my dad—and the desperate yearning that maybe he did love me, afterall—was the overwhelm of the full moon swallowing me whole. I was only a child, and much like how my mom turned a blind eye to my father’s drinking, she did the exact same when it came to her daughter.

I’d used the death of my parents as the excuse for my alcoholism for so long, because admitting that they helped create the monster I would eventually become was like a knife to the heart. And knowing I had been too weak to conquer the addiction from my own volition just made the weapon twist in my chest.

The room was spinning. My face was blistering hot like the night of the fire. Or was that the warm heat from the fireplace when we were kids? The childhood fireplace memories ran through my mind, frame by frame, until…..they eventually vaporized to nothing. I crouched over, thinking I might vomit.

“We never had a fireplace.” Perry was nodding, very matter-of-factly.

My fingernails dug into my thighs when I looked at the fireplace and: it was gone. Only a blank wall of faded, forest green wallpaper remained. Our house was once on fire, yes, but that was it. There was never a happy childhood fireplace. Ever.

My hands were cold and clammy. I fell back onto the wall behind me. “Perry. Where are we?”

He stood up and glided towards the staircase. One hand on the banister, his footsteps creaked, one by one, as he made his way to the second floor.

My mouth was bone dry, “Perry!”

He stopped and turned towards me, “Come to the projector room. We love watching movies together, don’t we? There’s a movie I’d like to show you.”

As my brother disappeared from sight, I did what any classic horror movie trope would tell you to do: I went upstairs.

I found Perry standing at the end of the ominous hallway. Large, empty picture frames lined the oxblood walls leading up to him. Through the doorway where Perry stood, particles in the air danced in the projector’s cone-shaped light. That telltale winding of a film reel was the only sound in the deafening quiet of this house that I no longer recognized.

Half of Perry’s face—the one with the scar—was perfectly illuminated, as though he was wearing the mask from “The Phantom of the Opera”. “I think you’re ready to see how this movie ends, Jackie. This is the most progress you’ve made since we’ve been coming here.”

I gripped my thumbs in the palms of my hands, “Perry, you’re freaking the fuck out of me!”

I thought my knees might buckle as my brother’s face glitched, like a flash of static snow on a television set. As his face settled back to normal to a deadpan gaze, he disappeared in the innocuous room. I followed, running on nothing but fumes.

Clutching the doorway, my mouth fell agape. Perry was gone. I darted to the middle of the room.

As I frantically searched for my brother, I shielded my eyes with the back of my hand from the projector’s light. And that’s when, from behind me, I heard five words that made my blood run cold, “Jackie! Stop the fucking car!”

I was convulsing yet paralyzed. Moving as slowly as cold molasses, I rotated on the spot towards my worst nightmare, shown on 35 mm. On the projector screen was Perry and me in my car, exactly seven hundred and thirty days ago, the day I almost kill—

Oh my God.

My head pounded as fragmented memories surged. The reality of what happened began to crystallize, unrelenting.

My joints ached and my stomach churned. Clamping a hand over my mouth to stifle a scream, I stumbled down the hallway as it began caving in on itself. The picture frames were sucked into the walls. The floorboards cracked into distorted peaks and valleys. Wooden beams swung down from the ceiling like pendulums. I tried to spit out the chalky grit of disintegrating drywall that made the hallway look like a winter squall.

Panting heavily, I stopped dead in my tracks at the stained glass window. My body trembled with an all-too-familiar dread. Each time I faced this, I wondered if this fall would be the one that would finally end it all.

Maybe it’d be better if it did.

Holding my breath, I threw myself through the glass, my hands clawing the air for dear life. Free falling two stories feels like an eternity when you’re watching the memory of your childhood home fall apart before your very eyes. But when the weight of my body finally made contact with the earth I—

I gasped. The cold air of the hospital room shocked my lungs. I sat up, ripping the suction cups from my face and body. My gown was clinging to me, soaked in sweat. Medical equipment beeped all around me like a metronome.

Dr. Lasko, my therapist since the accident, sat across the stark white room, sighing as he rubbed his forehead. He, too, was connected to a plethora of suction cups and wires. He looked a little worn out in the fluorescent overhead lighting. Ever since I was hospitalized and later incarcerated, Dr. Lasko had been helping me delve into my memories, namely the ones that were too excruciating for me to face. And as such, Dr. Lasko had been appearing in the simulations as my brother Perry, the love of my life who died in the car crash, seven hundred and thirty days prior.

Disoriented, I blinked rapidly, the vividness of the memory contrasting sharply with the sterile, geometric ceiling tiles above me.

“I don’t ever want to do that again!” I was venomous.

“Jackie,” Dr. Lasko started.

“Don’t start,” I pulled up four fingers for air quotes, “‘Jackie, don’t give up. This was the closest you’ve ever come to facing the truth.”

As the initial burst of adrenal and cortisol left my body, I fell back on my pillow. I was depleted. Quiet rivers flowed down my cheeks.

Removing his own suction cups, Dr. Lasko approached my bedside and took a seat. He treaded lightly. “Jackie, I understand how challenging this is for you, but you did an incredible job today. If we continue making progress like this, there's a real possibility you'll gain your freedom sooner.”

I looked at the well-meaning doctor, but all I could see was Perry. Multicolored confetti fell softly around him like that first November snow. His face was the sun. His eyes reflected the whole world back to me.

Perry.

With a weak grip, I took Dr. Lasko’s hand. My vocal cords were like sandpaper. “I’ll leave this place one day, doc.” A single tear dripped from my chin onto my collarbone. “But I’m not sure if I’ll ever be free.”

Dr. Lasko didn’t say a word, but I felt him squeeze my hand, just a little bit tighter.

I licked the cracks on my lips as my eyes closed shut, imagining the oaky comfort of bourbon on my tongue. I felt myself drift, and good thing, because I needed the rest. Dr. Lasko and I would be delving into my memories again the following day.

No matter how masochistic it felt, I vowed to keep showing up for the simulations. Even if I never forgave myself for what I did, at least in my memories, I got to see Perry.",How is the narrator related to Perry,Perry is the narrator's brother.,Perry is the narrator's sibling.,Perry is the narrator's childhood friend.
12,"Gleam for Python users
Hello productive pragmatic Pythonistas!

a soft wavey boundary between two sections of the website
Comments
Variables
Match operator
Variables type annotations
Functions
Exporting functions
Function type annotations
Referencing functions
Labelled arguments
Operators
Constants
Blocks
Data types
Strings
Tuples
Lists
Dicts
Flow control
Case
Try
Type aliases
Custom types
Records
Unions
Opaque custom types
Modules
Imports
Named imports
Unqualified imports
Comments
Python
In Python, comments are written with a # prefix.

# Hello, Joe!
A docstring (matching “””) that occurs as the first statement in a module, function, class, or method definition will become the __doc__ attribute of that object.

def a_function():
    """"""Return some important data.""""""
    pass
Gleam
In Gleam, comments are written with a // prefix.

// Hello, Joe!
Comments starting with /// are used to document the following statement. Comments starting with //// are used to document the current module.

//// This module is very important.

/// The answer to life, the universe, and everything.
const answer: Int = 42
Variables
You can reassign variables in both languages.

Python
size = 50
size = size + 100
size = 1
Python has no specific variable keyword. You choose a name and that’s it!

Gleam
Gleam has the let keyword before its variable names.

let size = 50
let size = size + 100
let size = 1
Match operator
Python
Python supports basic, one directional destructuring (also called unpacking). Tuple of values can be unpacked and inner values can be assigned to left-hand variable names.

(a, b) = (1, 2)
# a == 1
# b == 2

# works also for for-loops
for key, value in enumerate(a_dict):
    print(key, value)
Gleam
In Gleam, let and = can be used for pattern matching, but you’ll get compile errors if there’s a type mismatch, and a runtime error if there’s a value mismatch. For assertions, the equivalent let assert keyword is preferred.

let #(x, _) = #(1, 2)
let assert [] = [1] // runtime error
let assert [y] = ""Hello"" // compile error, type mismatch
Variables type annotations
Python
Python is a dynamically typed language. Types are only checked at runtime and a variable can have different types in its lifetime.

Type hints (Python 3+) are optional annotations that document the code with type information. These annotations are accessible at runtime via the __annotations__ module-level variable.

These hints will mainly be used to inform static analysis tools like IDEs, linters…

some_list: list[int] = [1, 2, 3]
Gleam
In Gleam type annotations can optionally be given when binding variables.

let some_list: List(Int) = [1, 2, 3]
Gleam will check the type annotation to ensure that it matches the type of the assigned value. It does not need annotations to type check your code, but you may find it useful to annotate variables to hint to the compiler that you want a specific type to be inferred.

Functions
Python
In Python, you can define functions with the def keyword. In that case, the return keyword is mandatory.

def sum(x, y):
    return x + y
Anonymous functions returning a single expression can also be defined with the lambda keyword and be assigned into variables.

mul = lambda x, y: x * y
mul(1, 2)
Gleam
Gleam’s functions are declared using a syntax similar to Rust or JavaScript. Gleam’s anonymous functions have a similar syntax and don’t need a . when called.

pub fn sum(x, y) {
  x + y
}

let mul = fn(x, y) { x * y }
mul(1, 2)
Exporting functions
Python
In Python, top level functions are exported by default. There is no notion of private module-level functions.

Gleam
In Gleam, functions are private by default and need the pub keyword to be public.

// this is public
pub fn sum(x, y) {
  x + y
}

// this is private
fn mul(x, y) {
  x * y
}
Function type annotations
Python
Type hints can be used to optionally annotate function arguments and return types.

Discrepancies between type hints and actual values at runtime do not prevent interpretation of the code.

Static code analysers (IDE tooling, type checkers like mypy) will be required to detect those errors.

def sum(x: int, y: int) -> int:
    return x + y

def mul(x: int, y: int) -> bool:
    # no errors from the interpreter.
    return x * y
Gleam
Functions can optionally have their argument and return types annotated in Gleam. These type annotations will always be checked by the compiler and throw a compilation error if not valid. The compiler will still type check your program using type inference if annotations are omitted.

pub fn add(x: Int, y: Int) -> Int {
  x + y
}

pub fn mul(x: Int, y: Int) -> Bool { // compile error, type mismatch
  x * y
}
Referencing functions
Python
As long as functions are in scope they can be assigned to a new variable. There is no special syntax to assign a module function to a variable.

Gleam
Gleam has a single namespace for value and functions within a module, so there is no need for a special syntax to assign a module function to a variable.

fn identity(x) {
  x
}

fn main() {
  let func = identity
  func(100)
}
Labelled arguments
Both Python and Gleam have ways to give arguments names and in any order.

Python
Keyword arguments are evaluated once at function definition time, and there is no evidence showing a noticeable performance penalty when using named arguments.

When calling a function, arguments can be passed

positionally, in the same order of the function declaration
by name, in any order
def replace(inside: str, each: str, with_string: str):
    pass

# equivalent calls
replace('hello world', 'world', 'you')
replace(each='world', inside='hello world',  with_string='you')
Gleam
In Gleam arguments can be given a label as well as an internal name. Contrary to Python, the name used at the call-site does not have to match the name used for the variable inside the function.

pub fn replace(inside string, each pattern, with replacement) {
  go(string, pattern, replacement)
}
replace(each: "","", with: "" "", inside: ""A,B,C"")
There is no performance cost to Gleam’s labelled arguments as they are optimised to regular function calls at compile time, and all the arguments are fully type checked.

Operators
Operator	Python	Gleam	Notes
Equal	==	==	In Gleam both values must be of the same type
Strictly equal to	==	==	Comparison in Gleam is always strict. (see note for Python)
Reference equality	is	 	True only if the two objects have the same reference
Not equal	!=	!=	In Gleam both values must be of the same type
Greater than	>	>	In Gleam both values must be ints
Greater than	>	>.	In Gleam both values must be floats
Greater or equal	>=	>=	In Gleam both values must be ints
Greater or equal	>=	>=.	In Gleam both values must be floats
Less than	<	<	In Gleam both values must be ints
Less than	<	<.	In Gleam both values must be floats
Less or equal	<=	<=	In Gleam both values must be ints
Less or equal	<=	<=.	In Gleam both values must be floats
Boolean and	and	&&	In Gleam both values must be bools
Logical and	and	 	Not available in Gleam
Boolean or	or	||	In Gleam both values must be bools
Logical or	or	 	Not available in Gleam
Add	+	+	In Gleam both values must be ints
Add	+	+.	In Gleam both values must be floats
Subtract	-	-	In Gleam both values must be ints
Subtract	-	-.	In Gleam both values must be floats
Multiply	*	*	In Gleam both values must be ints
Multiply	*	*.	In Gleam both values must be floats
Divide	/	/	In Gleam both values must be ints
Divide	/	/.	In Gleam both values must be floats
Remainder	%	%	In Gleam both values must be ints, in Gleam negative values behave differently: Use int.modulo to mimick Python’s behavior.
Concatenate	+	<>	In Gleam both values must be strings
Pipe	 	|>	Gleam’s pipe can pipe into anonymous functions. This operator does not exist in python
Some notes for Python:

== is by default comparing by value:

scalars will have their value compared
the only type cast will be for 0 and 1 that will be coerced to False and True respectively
variables that point to the same object will be equal with ==
two objects with the same members values won’t be equal:

no structural equality, unless the __eq__ operator is redefined.
Python operators are short-circuiting as in Gleam.
Python operators can be overloaded and be applied to any types with potential custom behaviors
Constants
Python
In Python, top-level declarations are in the global/module scope is the highest possible scope. Any variables and functions defined will be accessible from anywhere in the code.

There is no notion of constant variables in Python.

# in the global scope
THE_ANSWER = 42
Gleam
In Gleam constants can be created using the const keyword.

const the_answer = 42

pub fn main() {
  the_answer
}
Blocks
Python
Python blocks are always associated with a function / conditional / class declarations… There is no way to create multi-line expressions blocks like in Gleam.

Blocks are declared via indentation.

def a_func():
    # A block here
    pass
Gleam
In Gleam braces { } are used to group expressions.

pub fn main() {
  let x = {
    some_function(1)
    2
  }
  let y = x * {x + 10} // braces are used to change arithmetic operations order
  y
}
Data types
Strings
In Python, strings are stored as unicode code-points sequence. Strings can be encoded or decoded to/from a specific encoding.

In Gleam all strings are UTF-8 encoded binaries.

Python
""Hellø, world!""
Gleam
""Hellø, world!""
Tuples
Tuples are very useful in Gleam as they’re the only collection data type that allows mixed types in the collection.

Python
Python tuples are immutable, fixed-size lists that can contain mixed value types. Unpacking can be used to bind a name to a specific value of the tuple.

my_tuple = (""username"", ""password"", 10)
_, password, _ = my_tuple
Gleam
let my_tuple = #(""username"", ""password"", 10)
let #(_, password, _) = my_tuple
Lists
Lists in Python are allowed to have values of mixed types, but not in Gleam.

Python
Python can emulate the cons operator of Gleam using the * operator and unpacking:

list = [2, 3, 4]
[head, *tail] = list
# head == 2
# tail == [3, 4]
Gleam
Gleam has a cons operator that works for lists destructuring and pattern matching. In Gleam lists are immutable so adding and removing elements from the start of a list is highly efficient.

let list = [2, 3, 4]
let list = [1, ..list]
let [1, second_element, ..] = list
[1.0, ..list] // compile error, type mismatch
Dictionaries
In Python, dictionaries can have keys of any type as long as:

the key type is hashable, such as integers, strings, tuples (due to their immutable values), functions… and custom mutable objects implementing the __hash__ method.
the key is unique in the dictionary. and values of any type.
In Gleam, dicts can have keys and values of any type, but all keys must be of the same type in a given dict and all values must be of the same type in a given dict.

There is no dict literal syntax in Gleam, and you cannot pattern match on a dict. Dicts are generally not used much in Gleam, custom types are more common.

Python
{""key1"": ""value1"", ""key2"": ""value2""}
{""key1"":  ""1"", ""key2"": 2}
Gleam
import gleam/dict

dict.from_list([#(""key1"", ""value1""), #(""key2"", ""value2"")])
dict.from_list([#(""key1"", ""value1""), #(""key2"", 2)]) // Type error!
Flow control
Case
Case is one of the most used control flows in Gleam. It can be seen as a switch statement on steroids. It provides a terse way to match a value type to an expression. Gleam’s case expression is fairly similar to Python’s match statement.

Python
Matching on primitive types:

def http_error(status):
    match status:
        case 400:
            return ""Bad request""
        case 404:
            return ""Not found""
        case 418:
            return ""I'm a teapot""
Matching on tuples with variable capturing:

match point:
    case (0, 0):
        print(""Origin"")
    case (0, y):
        print(f""Y={y}"")
    case (x, 0):
        print(f""X={x}"")
    case (x, y):
        print(f""""X={x}, Y={y}"""")
    case _:
        raise ValueError(""Not a point"")
Matching on type constructors:

match point:
    case Point(x=0, y=0):
        print(""Origin is the point's location."")
    case Point(x=0, y=y):
        print(f""Y={y} and the point is on the y-axis."")
    case Point(x=x, y=0):
        print(f""X={x} and the point is on the x-axis."")
    case Point():
        print(""The point is located somewhere else on the plane."")
    case _:
        print(""Not a point"")
The match expression supports guards, similar to Gleam:

match point:
    case Point(x, y) if x == y:
        print(f""The point is located on the diagonal Y=X at {x}."")
    case Point(x, y):
        print(f""Point is not on the diagonal."")
Gleam
The case operator is a top level construct in Gleam:

case some_number {
  0 -> ""Zero""
  1 -> ""One""
  2 -> ""Two""
  n -> ""Some other number"" // This matches anything
}
The case operator especially coupled with destructuring to provide native pattern matching:

case xs {
  [] -> ""This list is empty""
  [a] -> ""This list has 1 element""
  [a, b] -> ""This list has 2 elements""
  _other -> ""This list has more than 2 elements""
}
The case operator supports guards:

case xs {
  [a, b, c] if a >. b && a <=. c -> ""ok""
  _other -> ""ko""
}
and disjoint union matching:

case number {
  2 | 4 | 6 | 8 -> ""This is an even number""
  1 | 3 | 5 | 7 -> ""This is an odd number""
  _ -> ""I'm not sure""
}
Try
Error management is approached differently in Python and Gleam.

Python
Python uses the notion of exceptions to interrupt the current code flow and pop up the error to the caller.

An exception is raised using the keyword raise.

def a_function_that_fails():
    raise Exception(""an error"")
The callee block will be able to capture any exception raised in the block using a try/except set of blocks:

try:
    print(""executed"")
    a_function_that_fails()
    print(""not_executed"")
except Exception as e:
    print(""doing something with the exception"", e)

Gleam
In contrast in Gleam, errors are just containers with an associated value.

A common container to model an operation result is Result(ReturnType, ErrorType).

A Result is either:

an Error(ErrorValue)
or an Ok(Data) record
Handling errors actually means to match the return value against those two scenarios, using a case for instance:

case int.parse(""123"") {
  Error(e) -> io.println(""That wasn't an Int"")
  Ok(i) -> io.println(""We parsed the Int"")
}
In order to simplify this construct, we can use the use expression with the try function from the gleam/result module.

bind a value to the providing name if Ok(Something) is matched
interrupt the flow and return Error(Something)
let a_number = ""1""
let an_error = ""ouch""
let another_number = ""3""

use int_a_number <- try(parse_int(a_number))
use attempt_int <- try(parse_int(an_error)) // Error will be returned
use int_another_number <- try(parse_int(another_number)) // never gets executed

Ok(int_a_number + attempt_int + int_another_number) // never gets executed
Type aliases
Type aliases allow for easy referencing of arbitrary complex types. Even though their type systems does not serve the same function, both Python and Gleam provide this feature.

Python
A simple variable can store the result of a compound set of types.

type Headers = list[tuple[str, str]]

# can now be used to annotate a variable
headers: Headers = [(""Content-Type"", ""application/json"")]
Gleam
The type keyword can be used to create aliases:

pub type Headers =
  List(#(String, String))

let headers: Headers = [#(""Content-Type"", ""application/json"")]
Custom types
Records
Custom type allows you to define a collection data type with a fixed number of named fields, and the values in those fields can be of differing types.

Python
Python uses classes to define user-defined, record-like types. Properties are defined as class members and initial values are generally set in the constructor.

By default the constructor does not provide base initializers in the constructor so some boilerplate is needed:

class Person:
    name: str
    age: int

    def __init__(name: str, age: int) -> None:
        self.name = name
        self.age = age

person = Person(name=""Jake"", age=20)
# or with positional arguments Person(""Jake"", 20)
name = person.name
More recent alternatives are to use dataclasses or to leverage the NamedTuple base type to generate a constructor with initializers.

By default a class created with the dataclass decorator is mutable (although you can pass options to the dataclass decorator to change the behavior):

from dataclasses import dataclasses

@dataclass
class Person:
    name: str
    age: int

person = Person(name=""Jake"", age=20)
name = person.name
person.name = ""John""  # The name is now ""John""
NamedTuples on the other hand are immutable:

from typing import NamedTuple

class Person(NamedTuple):
    name: str
    age: int

person = Person(name=""Jake"", age=20)
name = person.name

# cannot reassign a value
person.name = ""John""  # error
Gleam
Gleam’s custom types can be used in much the same way that structs are used in Elixir. At runtime, they have a tuple representation and are compatible with Erlang records.

type Person {
  Person(name: String, age: Int)
}

let person = Person(name: ""Jake"", age: 35)
let name = person.name
An important difference to note is there is no OOP in Gleam. Methods can not be added to types.

Unions
In Python unions can be declared with the | operator.

In Gleam functions must always take and receive one type. To have a union of two different types they must be wrapped in a new custom type.

Python
def int_or_float(x: int | float) -> str:
    if isinstance(x, int):
        return f""It's an integer: {x}""
    else:
        return f""It's a float: {x}""
Gleam
type IntOrFloat {
  AnInt(Int)
  AFloat(Float)
}

fn int_or_float(x) {
  case x {
    AnInt(1) -> ""It's an integer: 1""
    AFloat(1.0) -> ""It's a float: 1.0""
  }
}
Opaque custom types
In Python, constructors cannot be marked as private. Opaque types can be imperfectly emulated using a class method and some magic property that only updates via the class factory method.

In Gleam, custom types can be defined as being opaque, which causes the constructors for the custom type not to be exported from the module. Without any constructors to import other modules can only interact with opaque types using the intended API.

Python
class OnlyCreatable:

    __create_key = object()

    @classmethod
    def create(cls, value):
        return OnlyCreatable(cls.__create_key, value)

    def __init__(self, create_key, value):
        assert(create_key == OnlyCreatable.__create_key), \
            ""OnlyCreatable objects must be created using OnlyCreatable.create""
        self.value = value
Gleam
pub opaque type Identifier {
  Identifier(Int)
}

pub fn get_id() {
  Identifier(100)
}
Modules
Python
There is no special syntax to define modules as files are modules in Python

Gleam
Gleam’s file is a module and named by the file name (and its directory path). Since there is no special syntax to create a module, there can be only one module in a file.

// in file foo.gleam
pub fn identity(x) {
  x
}
// in file main.gleam
import foo // if foo was in a folder called `lib` the import would be `lib/foo`
pub fn main() {
  foo.identity(1)
}
Imports
Python
# inside module src/nasa/moon_base.py
# imports module src/nasa/rocket_ship.py
from nasa import rocket_ship

def explore_space():
    rocket_ship.launch()
Gleam
Imports are relative to the root src folder.

Modules in the same directory will need to reference the entire path from src for the target module, even if the target module is in the same folder.

// inside module src/nasa/moon_base.gleam
// imports module src/nasa/rocket_ship.gleam
import nasa/rocket_ship

pub fn explore_space() {
  rocket_ship.launch()
}
Named imports
Python
import unix.cat as kitty
Gleam
import unix/cat as kitty
Unqualified imports
Python
from animal.cat import Cat, stroke

def main():
    kitty = Cat(name=""Nubi"")
    stroke(kitty)
Gleam
import animal/cat.{Cat, stroke}

pub fn main() {
  let kitty = Cat(name: ""Nubi"")
  stroke(kitty)
}",What is the syntax for pipe,The operator for Pipe in Gleam is '|>'.,"In Gleam, the pipe operator is written as '|>' for pipelining functions.","The pipe syntax in Gleam is represented by '|>+', which is used for function piping."
6,"Why do we need to regulate the use of Artificial Intelligence?
The potential benefits of Artificial Intelligence (AI) for our societies are manifold from improved medical care to better education. Faced with the rapid technological development of AI, the EU decided to act as one to harness these opportunities.

The EU AI Act is the world's first comprehensive AI law. It aims to address risks to health, safety and fundamental rights. The regulation also protects democracy, rule of law and the environment.

While most AI systems will pose low to no risk, certain AI systems create risks that need to be addressed to avoid undesirable outcomes.

For example, the opacity of many algorithms may create uncertainty and hamper the effective enforcement of the existing legislation on safety and fundamental rights. Responding to these challenges, legislative action was needed to ensure a well-functioning internal market for AI systems where both benefits and risks are adequately addressed.

This includes applications such as biometric identification systems or AI decisions touching on important personal interests, such as in the areas of recruitment, education, healthcare, or law enforcement.

Recent advancements in AI gave rise to ever more powerful Generative AI. So-called “general-purpose AI models” that are being integrated in numerous AI systems are becoming too important for the economy and society not to be regulated. In light of potential systemic risks, the EU puts in place effective rules and oversight.

Which risks will the new AI rules address?
The uptake of AI systems has a strong potential to bring societal benefits, economic growth and enhance EU innovation and global competitiveness. However, in certain cases, the specific characteristics of certain AI systems may create new risks related to user safety and fundamental rights. Some powerful AI models that are being widely used could even pose systemic risks.

This leads to legal uncertainty for companies and potentially slower uptake of AI technologies by businesses and citizens, due to the lack of trust. Disparate regulatory responses by national authorities would risk fragmenting the internal market.

To whom does the AI Act apply?
The legal framework will apply to both public and private actors inside and outside the EU as long as the AI system is placed on the Union market or its use affects people located in the EU.

It can concern both providers (e.g. a developer of a CV-screening tool) and deployers of high-risk AI systems (e.g. a bank buying this screening toolImporters of AI systems will also have to ensure that the foreign provider has already carried out the appropriate conformity assessment procedure, bears a European Conformity (CE) marking and is accompanied by the required documentation and instructions of use.

In addition, certain obligations are foreseen for providers of general-purpose AI models, including large generative AI models.

Providers of free and open-source models are exempted from most of these obligations. This exemption does not cover obligations for providers of general purpose AI models with systemic risks.

Obligations also do not apply to research, development and prototyping activities preceding the release on the market, and the regulation furthermore does not apply to AI systems that are exclusively for military, defence or national security purposes, regardless of the type of entity carrying out those activities.

What are the risk categories?
The Commission proposes a risk–based approach, with four levels of risk for AI systems, as well as an identification of risks specific to general purpose models:

Minimal risk: All other AI systems can be developed and used subject to the existing legislation without additional legal obligations. The vast majority of AI systems currently used or likely to be used in the EU fall into this category. Voluntarily, providers of those systems may choose to apply the requirements for trustworthy AI and adhere to voluntary codes of conduct.
High-risk: A limited number of AI systems defined in the proposal, potentially creating an adverse impact on people's safety or their fundamental rights (as protected by the EU Charter of Fundamental Rights), are considered to be high-risk. Annexed to the Act is the list of high-risk AI systems, which can be reviewed to align with the evolution of AI use cases.
These also include safety components of products covered by sectorial Union legislation. They will always be considered high-risk when subject to third-party conformity assessment under that sectorial legislation.
Unacceptable risk: A very limited set of particularly harmful uses of AI that contravene EU values because they violate fundamental rights and will therefore be banned:
Social scoring for public and private purposes;
Exploitation of vulnerabilities of persons, use of subliminal techniques;
Real-time remote biometric identification in publicly accessible spaces by law enforcement, subject to narrow exceptions (see below);
Biometric categorisation of natural persons based on biometric data to deduce or infer their race, political opinions, trade union membership, religious or philosophical beliefs or sexual orientation. Filtering of datasets based on biometric data in the area of law enforcement will still be possible;
Individual predictive policing;
Emotion recognition in the workplace and education institutions, unless for medical or safety reasons (i.e. monitoring the tiredness levels of a pilot);
Untargeted scraping of internet or CCTV for facial images to build-up or expand databases.
Specific Transparency risk: For certain AI systems specific transparency requirements are imposed, for example where there is a clear risk of manipulation (e.g. via the use of chatbots). Users should be aware that they are interacting with a machine.
In addition, the AI Act considers systemic risks which could arise from general-purpose AI models, including large generative AI models. These can be used for a variety of tasks and are becoming the basis for many AI systems in the EU. Some of these models could carry systemic risks if they are very capable or widely used. For example, powerful models could cause serious accidents or be misused for far-reaching cyberattacks. Many individuals could be affected if a model propagates harmful biases across many applications.

How do I know whether an AI system is high-risk?
Together with a clear definition of ‘high-risk', the Act sets out a solid methodology that helps identifying high-risk AI systems within the legal framework. This aims to provide legal certainty for businesses and other operators.

The risk classification is based on the intended purpose of the AI system, in line with the existing EU product safety legislation. It means that the classification of the risk depends on the function performed by the AI system and on the specific purpose and modalities for which the system is used.

Annexed to the Act is a list of use cases which are considered to be high-risk. The Commission will ensure that this list is kept up to date and relevant. Systems on the high-risk list, that perform narrow procedural tasks, improve the result of previous human activities, do not influence human decisions or do purely preparatory tasks are not considered high-risk. However, an AI system shall always be considered high-risk if it performs profiling of natural persons.

What are the obligations for providers of high-risk AI systems?
Before placing a high-risk AI system on the EU market or otherwise putting it into service, providers must subject it to a conformity assessment. This will allow them to demonstrate that their system complies with the mandatory requirements for trustworthy AI (e.g. data quality, documentation and traceability, transparency, human oversight, accuracy, cybersecurity and robustness). This assessment has to be repeated if the system or its purpose are substantially modified.

AI systems being safety components of products covered by sectorial Union legislation will always be deemed high-risk when subject to third-party conformity assessment under that sectorial legislation. Also, for biometric systems a third-party conformity assessment is always required.

Providers of high-risk AI systems will also have to implement quality and risk management systems to ensure their compliance with the new requirements and minimise risks for users and affected persons, even after a product is placed on the market.

High-risk AI systems that are deployed by public authorities or entities acting on their behalf will have to be registered in a public EU database, unless those systems are used for law enforcement and migration. The latter will have to be registered in a non-public part of the database that will be only accessible to relevant supervisory authorities.

Market surveillance authorities will support post-market monitoring through audits and by offering providers the possibility to report on serious incidents or breaches of fundamental rights obligations of which they have become aware. Any market surveillance authority may authorise placing on the market of specific high-risk AI for exceptional reasons.

In case of a breach, the requirements will allow national authorities to have access to the information needed to investigate whether the use of the AI system complied with the law.

What are examples for high-risk use cases as defined in Annex III?
Certain critical infrastructures for instance in the fields of road traffic and the supply of water, gas, heating and electricity;
Education and vocational training, e.g. to evaluate learning outcomes and steer the learning process and monitoring of cheating;
Employment, workers management and access to self-employment, e.g. to place targeted job advertisements, to analyse and filter job applications, and to evaluate candidates;
Access to essential private and public services and benefits (e.g. healthcare), creditworthiness evaluation of natural persons, and risk assessment and pricing in relation to life and health insurance;
Certain systems used in the fields of law enforcement, border control, administration of justice and democratic processes;
Evaluation and classification of emergency calls;
Biometric identification, categorisation and emotion recognition systems (outside the prohibited categories);
Recommender systems of very large online platforms are not included, as they are already covered in other legislation (DMA/DSA).
How are general-purpose AI models being regulated?
General-purpose AI models, including large generative AI models, can be used for a variety of tasks. Individual models may be integrated into a large number of AI systems.

It is important that a provider wishing to build upon a general-purpose AI model has all the necessary information to make sure its system is safe and compliant with the AI Act.

Therefore, the AI Act obliges providers of such models to disclose certain information to downstream system providers. Such transparency enables a better understanding of these models.

Model providers additionally need to have policies in place to ensure that that they respect copyright law when training their models.

In addition, some of these models could pose systemic risks, because they are very capable or widely used.

For now, general purpose AI models that were trained using a total computing power of more than 10^25 FLOPs are considered to carry systemic risks, given that models trained with larger compute tend to be more powerful. The AI Office (established within the Commission) may update this threshold in light of technological advances, and may furthermore in specific cases designate other models as such based on further criteria (e.g. number of users, or the degree of autonomy of the model).

Providers of models with systemic risks are therefore mandated to assess and mitigate risks, report serious incidents, conduct state-of-the-art tests and model evaluations, ensure cybersecurity and provide information on the energy consumption of their models.

For this, they are asked to engage with the European AI Office to draw up Codes of Conduct as the central tool to detail out the rules in cooperation with other experts. A scientific panel will play a central role in overseeing general-purpose AI models.

Why is 10^25 FLOPs an appropriate threshold for GPAI with systemic risks?
This threshold captures the currently most advanced GPAI models, namely OpenAI's GPT-4 and likely Google DeepMind's Gemini.

The capabilities of the models above this threshold are not yet well enough understood. They could pose systemic risks, and therefore it is reasonable to subject their providers to the additional set of obligations.

FLOP is a first proxy for model capabilities, and the exact FLOP threshold can be updated upwards or downwards by the European AI Office, e.g. in the light of progress in objectively measuring model capabilities and of developments in the computing power needed for a given performance level.

The AI Act can be amended to update the FLOP threshold (by means of a delegated act).

Is the AI Act future-proof?
The Regulation introduces different level of risks and provides clear definitions, including for GPAI.

The legislation sets result-oriented requirements for high-risk AI systems but leaves the concrete technical solutions and operationalisation primarily to industry-driven standards that will ensure that the legal framework is flexible to be adapted to different use cases and to enable new technological solutions.

In addition, the AI Act can be amended by delegated and implementing acts, including to update the FLOP threshold (delegated act), to add criteria for classifying the GPAI models as presenting systemic risks (delegated act), to amend modalities to establish regulatory sandboxes and elements of the real-world testing plan (implementing acts).

How does the AI Act regulate biometric identification?
The use of real-time remote biometric identification in publicly accessible spaces (i.e. facial recognition using CCTV) for law enforcement purposes is prohibited, unless used in one of the following cases:

Law enforcement activities related to 16 specified crimes;
Targeted search for specific victims, abduction, trafficking and sexual exploitation of human beings, and missing persons; or
The prevention of threat to the life or physical safety of persons or response to the present or foreseeable threat of a terror attack.
The list of the 16 crimes contains:

Terrorism;
Trafficking in human beings;
Sexual exploitation of children and child sexual abuse material;
Illicit trafficking in narcotic drugs and psychotropic substances;
Illicit trafficking in weapons, munitions and explosives;
Murder;
Grievous bodily injury;
Illicit trade in human organs and tissue;
Illicit trafficking in nuclear or radioactive materials;
Kidnapping, illegal restraint and hostage-taking;
Crimes within the jurisdiction of the International Criminal Court;
Unlawful seizure of aircraft/ships;
Rape;
Environmental crime;
Organised or armed robbery;
Sabotage, participation in a criminal organisation involved in one or more crimes listed above.
Real-time remote biometric identification by law enforcement authorities would be subject to prior authorisation by a judicial or independent administrative authority whose decision is binding. In case of urgency, authorisation can be done within 24 hours; if the authorisation is rejected all data and output needs to be deleted.

It would need to be preceded by prior fundamental rights impact assessment and should be notified to the relevant market surveillance authority and the data protection authority. In case of urgency, the use of the system may be commenced without the registration.

Usage of AI systems for post remote biometric identification (identification of persons in previously collected video material) of persons under investigation requires prior authorisation by a judicial authority or an independent administrative authority, and notification of the data protection and market surveillance authority.

Why are particular rules needed for remote biometric identification?
Biometric identification can take different forms. It can be used for user authentication i.e. to unlock a smartphone or for verification/authentication at border crossings to check a person's identity against his/her travel documents (one-to-one matching).

Biometric identification could also be used remotely, for identifying people in a crowd, where for example an image of a person is checked against a database (one-to-many matching).

Accuracy of systems for facial recognition can vary significantly based on a wide range of factors, such as camera quality, light, distance, database, algorithm, and the subject's ethnicity, age or gender. The same applies for gait and voice recognition and other biometric systems. Highly advanced systems are continuously reducing their false acceptance rates.

While a 99% accuracy rate may sound good in general, it is considerably risky when the result leads to the suspicion of an innocent person. Even a 0.1% error rate is a lot if it concerns tens of thousands of people.

How do the rules protect fundamental rights?
There is already a strong protection for fundamental rights and for non-discrimination in place at EU and Member State level, but complexity and opacity of certain AI applications (‘black boxes') pose a problem.

A human-centric approach to AI means to ensure AI applications comply with fundamental rights legislation. Accountability and transparency requirements for the use of high-risk AI systems, combined with improved enforcement capacities, will ensure that legal compliance is factored in at the development stage.

Where breaches occur, such requirements will allow national authorities to have access to the information needed to investigate whether the use of AI complied with EU law.

Moreover, the AI Act requires that deployers that are bodies governed by public law or private operators providing public services and operators providing high-risk systems to conduct a fundamental rights impact assessment.

What is a fundamental rights impact assessment? Who has to conduct such an assessment, and when?
The use of a high-risk AI system may produce an impact on fundamental rights. Therefore, deployers that are bodies governed by public law or private operators providing public services, and operators providing high-risk systems shall perform an assessment of the impact on fundamental rights and notify the national authority of the results.

The assessment shall consist of a description of the deployer's processes in which the high-risk AI system will be used, of the period of time and frequency in which the high-risk AI system is intended to be used, of the categories of natural persons and groups likely to be affected by its use in the specific context, of the specific risks of harm likely to impact the affected categories of persons or group of persons, a description of the implementation of human oversight measures and of measures to be taken in case of the materialization of the risks.

If the provider already met this obligation through the data protection impact assessment, the fundamental rights impact assessment shall be conducted in conjunction with that data protection impact assessment.

How does this regulation address racial and gender bias in AI?
It is very important that AI systems do not create or reproduce bias. Rather, when properly designed and used, AI systems can contribute to reduce bias and existing structural discrimination, and thus lead to more equitable and non-discriminatory decisions (e.g. in recruitment).

The new mandatory requirements for all high-risk AI systems will serve this purpose. AI systems must be technically robust to guarantee that the technology is fit for purpose and false positive/negative results are not disproportionately affecting protected groups (e.g. racial or ethnic origin, sex, age etc.).

High-risk systems will also need to be trained and tested with sufficiently representative datasets to minimise the risk of unfair biases embedded in the model and ensure that these can be addressed through appropriate bias detection, correction and other mitigating measures.

They must also be traceable and auditable, ensuring that appropriate documentation is kept, including of the data used to train the algorithm that would be key in ex post investigations.

Compliance system before and after they are placed on the market will have to ensure these systems are regularly monitored and potential risks are promptly addressed.

When will the AI Act be fully applicable?
Following its adoption by the European Parliament and the Council, the AI Act shall enter into force on the twentieth day following that of its publication in the official Journal. It will be fully applicable 24 months after entry into force, with a graduated approach as follows:

6 months after entry into force, Member States shall phase out prohibited systems;
12 months: obligations for general purpose AI governance become applicable;
24 months: all rules of the AI Act become applicable including obligations for high-risk systems defined in Annex III (list of high-risk use cases);
36 months: obligations for high-risk systems defined in Annex II (list of Union harmonisation legislation) apply.
How will the AI Act be enforced?
Member States hold a key role in the application and enforcement of this Regulation. In this respect, each Member State should designate one or more national competent authorities to supervise the application and implementation, as well as carry out market surveillance activities.

To increase efficiency and to set an official point of contact with the public and other counterparts, each Member State should designate one national supervisory authority, which will also represent the country in the European Artificial Intelligence Board.

Additional technical expertise will be provided by an advisory forum, representing a balanced selection of stakeholders, including industry, start-ups, SMEs, civil society and academia.

In addition, the Commission will establish a new European AI Office, within the Commission, which will supervise general-purpose AI models, cooperate with the European Artificial Intelligence Board and be supported by a scientific panel of independent experts.

Why is a European Artificial Intelligence Board needed and what will it do?
The European Artificial Intelligence Board comprises high-level representatives of competent national supervisory authorities, the European Data Protection Supervisor, and the Commission. Its role is to facilitate a smooth, effective and harmonised implementation of the new AI Regulation.

The Board will issue recommendations and opinions to the Commission regarding high-risk AI systems and on other aspects relevant for the effective and uniform implementation of the new rules. Finally, it will also support standardisation activities in the area.

What are the tasks of the European AI Office?
The AI Office has as its mission to develop Union expertise and capabilities in the field of artificial intelligence and to contribute to the implementation of Union legislation of artificial intelligence in a centralised structure.

In particular, the AI Office shall enforce and supervise the new rules for general purpose AI models. This includes drawing up codes of practice to detail out rules, its role in classifying models with systemic risks and monitoring the effective implementation and compliance with the Regulation. The latter is facilitated by the powers to request documentation, conduct model evaluations, investigate upon alerts and request providers to take corrective action.

The AI Office shall ensure coordination regarding artificial intelligence policy and collaboration between involved Union institutions, bodies and agencies as well as with experts and stakeholders. In particular, it will provide a strong link with the scientific community to support the enforcement, serve as international reference point for independent experts and expert organisations and facilitate exchange and collaboration with similar institutions across the globe.

What is the difference between the AI Board, AI Office, Advisory Forum and Scientific Panel of independent experts?
The AI Board has extended tasks in advising and assisting the Commission and the Member States.

The AI Office is to be established within the Commission and shall work to develop Union expertise and capabilities in the field of artificial intelligence and to contribute to the implementation of Union legislation of artificial intelligence. Particularly, the AI Office shall enforce and supervise the new rules for general purpose AI models.

The Advisory Forum will consist of a balanced selection of stakeholders, including industry, start-ups, SMEs, civil society and academia. It shall be established to advise and provide technical expertise to the Board and the Commission, with members appointed by the Board among stakeholders.

The Scientific Panel of independent experts supports the implementation and enforcement of the Regulation as regards GPAI models and systems, and the Member States would have access to the pool of experts.

What are the penalties for infringement?
When AI systems are put on the market or in use that do not respect the requirements of the Regulation, Member States will have to lay down effective, proportionate and dissuasive penalties, including administrative fines, in relation to infringements and communicate them to the Commission.

The Regulation sets out thresholds that need to be taken into account:

Up to €35m or 7% of the total worldwide annual turnover of the preceding financial year (whichever is higher) for infringements on prohibited practices or non-compliance related to requirements on data;
Up to €15m or 3% of the total worldwide annual turnover of the preceding financial year for non-compliance with any of the other requirements or obligations of the Regulation, including infringement of the rules on general-purpose AI models;
Up to €7.5m or 1.5% of the total worldwide annual turnover of the preceding financial year for the supply of incorrect, incomplete or misleading information to notified bodies and national competent authorities in reply to a request;
For each category of infringement, the threshold would be the lower of the two amounts for SMEs and the higher for other companies.
In order to harmonise national rules and practices in setting administrative fines, the Commission, counting on the advice of the Board, will draw up guidelines.

As EU Institutions, agencies or bodies should lead by example, they will also be subject to the rules and to possible penalties; the European Data Protection Supervisor will have the power to impose fines to them.

What can individuals do that are affected by a rule violation?
The AI Act foresees a right to lodge a complaint with a national authority. On this basis national authorities can launch market surveillance activities, following the procedures of the market surveillance regulations.

Additionally, the proposed AI Liability Directive aims to provide persons seeking compensation for damage caused by high-risk AI systems with effective means to identify potentially liable persons and obtain relevant evidence for a damage claim. For this purpose, the proposed Directive provides for the disclosure of evidence about specific high-risk AI systems that are suspected of having caused damage.

Moreover, the revised Product Liability Directive will ensure that compensation is available to individuals who suffer death, personal injury or property damage that is caused by a defective product in the Union and clarify that AI systems and products that integrate AI systems are also covered by existing rules.

How do the voluntary codes of conduct for high-risk AI systems work?
Providers of non-high-risk applications can ensure that their AI system is trustworthy by developing their own voluntary codes of conduct or adhering to codes of conduct adopted by other representative associations.

These will apply simultaneously with the transparency obligations for certain AI systems.

The Commission will encourage industry associations and other representative organisations to adopt voluntary codes of conduct.

How do the codes of practice for general purpose AI models work?
The Commission invites providers of general-purpose AI models and other experts to jointly work on a code of practice.

Once developed and approved for this purpose, these codes can be used by the providers of general-purpose AI models to demonstrate compliance with the relevant obligations from the AI Act, following the example of the GDPR.

This is especially relevant to detail out the rules for providers of general-purpose AI model with systemic risks, to ensure future-proof and effective rules for risk assessment and mitigation as well as other obligations.

Does the AI Act contain provisions regarding environmental protection and sustainability?
The objective of the AI proposal is to address risks to safety and fundamental rights, including the fundamental right to a high-level environmental protection. Environment is also one of the explicitly mentioned and protected legal interests.

The Commission is asked to request European standardisation organisations a standardisation deliverable on reporting and documentation processes to improve AI systems resource performance, such as reduction of energy and other resources consumption of the high-risk AI system during its lifecycle, and on energy efficient development of general-purpose AI models.

Furthermore, the Commission by two years after the date of application of the Regulation and every four years thereafter, is asked to submit a report on the review of the progress on the development of standardisation deliverables on energy efficient development of general-purpose models and asses the need for further measures or actions, including binding measures or actions.

In addition, providers of general purpose AI models, which are trained on large data amounts and therefore prone to high energy consumption, are required to disclose energy consumption.

The Commission is asked to develop an appropriate methodology for this assessment.

In case of general purpose AI models with systemic risks, energy efficiency furthermore needs to be assessed.

How can the new rules support innovation?
The regulatory framework can enhance the uptake of AI in two ways. On the one hand, increasing users' trust will increase the demand for AI used by companies and public authorities. On the other hand, by increasing legal certainty and harmonising rules, AI providers will access bigger markets, with products that users and consumers appreciate and purchase. Rules will apply only where strictly needed and in a way that minimises the burden for economic operators, with a light governance structure.

The AI Act further enables the creation of regulatory sandboxes and real world testing, which provide a controlled environment to test innovative technologies for a limited time, thereby fostering innovation by companies, SMEs and start-ups in compliance with the AI Act. These, together with other measures such as the additional Networks of AI Excellence Centres and the Public-Private Partnership on Artificial Intelligence, Data and Robotics, and access to Digital Innovation Hubs and Testing and Experimentation Facilities will help build the right framework conditions for companies to develop and deploy AI.

Real world testing of High-Risk AI systems can be conducted for a maximum of 6 months (which can be prolonged by another 6 months). Prior to testing, a plan needs to be drawn up and submitted it to the market surveillance authority, which has to approve of the plan and specific testing conditions, with default tacit approval if no answer has been given within 30 days. Testing may be subject to unannounced inspections by the authority.

Real world testing can only be conducted given specific safeguards, e.g. users of the systems under real world testing have to provide informed consent, the testing must not have any negative effect on them, outcomes need to be reversible or disregardable, and their data needs to be deleted after conclusion of the testing. Special protection is to be granted to vulnerable groups, i.e. due to their age, physical or mental disability.

Besides the AI Act, how will the EU facilitate and support innovation in AI?
The EU's approach to Artificial Intelligence is based on excellence and trust, aiming to boost research and industrial capacity while ensuring safety and the protection of fundamental rights. People and businesses should be able to enjoy the benefits of AI while feeling safe and protected. The European AI Strategy aims at making the EU a world-class hub for AI and ensuring that AI is human-centric and trustworthy. In April 2021, the Commission presented its AI package, including: (1) a review of the Coordinated Plan on Artificial Intelligence and (2) its proposal for a regulation laying down harmonised rules on AI.

With the Coordinated Plan on AI the European Commission has adopted a comprehensive strategy to promote the development and adoption of AI in Europe. It focuses on creating enabling conditions for AI development and uptake, ensuring excellence thrives from the lab to the market, increasing the trustworthiness of AI, and building strategic leadership in high-impact sectors.

The Commission aims to leverage the activities of Member States by coordinating and harmonizing their efforts, to foster a cohesive and synergistic approach towards AI development and adoption. The Commission also put in place the European AI Alliance platform, which brings together stakeholders from academia, industry, and civil society to exchange knowledge and insights on AI policies.

Moreover, the Coordinated plans foresees several measures that aim to unlock data resources, foster critical computing capacity, increase research capacities, support a European network of Testing and Experimentation Facilities (TEFS) and support SMEs through European Digital Innovation Hubs (EDIHs).

What is the international dimension of the EU's approach?
The AI Act and the Coordinated Plan on AI are part of the efforts of the European Union to be a global leader in the promotion of trustworthy AI at international level. AI has become an area of strategic importance at the crossroads of geopolitics, commercial stakes and security concerns.

Countries around the world are choosing to use AI as a way to signal their desires for technical advancement due to its utility and potential. AI regulation is only emerging and the EU will take actions to foster the setting of global AI standards in close collaboration with international partners in line with the rules-based multilateral system and the values it upholds. The EU intends to deepen partnerships, coalitions and alliances with EU partners (e.g. Japan, the US, India, Canada, South Korea, Singapore, or the Latin American and Caribbean region) as well as multilateral (e.g. OECD, G7 and G20) and regional organisations (e.g. Council of Europe).

*Updated on 14/12/2023",What are the rules for developing general purpose AI models?,"General purpose AI models that were trained using a total computing power of more than 10^25 FLOPs are considered to carry systemic risks. 12 months after the AI Act enters into force, the obligations for general purpose AI governance become applicable. Providers of general purpose AI models, which are trained on large data amounts and therefore prone to high energy consumption, are required to disclose energy consumption. Providers of free and open-source models are exempted from most of obligations, but this exemption does not cover obligations for providers of general purpose AI models with systemic risks.","Development of general-purpose AI models with more than 10^25 FLOPs must include energy consumption disclosure. Rules apply 12 months after the AI Act is enforced, especially for models with systemic risks.","General purpose AI models are fully exempt from obligations, focusing only on free and open-source requirements, regardless of FLOPs usage level."
4,"Recipes
This page includes code snippets or “recipes” for a variety of common tasks. Use them as building blocks or examples when making your own notebooks.

In these recipes, each code block represents a cell.

Control Flow
Show an output conditionally
Use cases. Hide an output until a condition is met (e.g., until algorithm parameters are valid), or show different outputs depending on the value of a UI element or some other Python object

Recipe.

Use an if expression to choose which output to show.

# condition is a boolean, True of False
condition = True
""condition is True"" if condition else None
Run a cell on a timer
Use cases.

Load new data periodically, and show updated plots or other outputs. For example, in a dashboard monitoring a training run, experiment trial, real-time weather data, …

Run a job periodically

Recipe.

Import packages

import marimo as mo
Create a mo.ui.refresh timer that fires once a second:

refresh = mo.ui.refresh(default_interval=""1s"")
# This outputs a timer that fires once a second
refresh
Reference the timer by name to make this cell run once a second

import random

# This cell will run once a second!
refresh

mo.md(""#"" + """" * random.randint(1, 10))
Require form submission before sending UI value
Use cases. UI elements automatically send their values to the Python when they are interacted with, and run all cells referencing the elements. This makes marimo notebooks responsive, but it can be an issue when the downstream cells are expensive, or when the input (such as a text box) needs to be filled out completely before it is considered valid. Forms let you gate submission of UI element values on manual confirmation, via a button press.

Recipe.

Import packages

import marimo as mo
Create a submittable form.

form = mo.ui.text(label=""Your name"").form()
form
Get the value of the form.

form.value
Stop execution of a cell and its descendants
Use cases. For example, don’t run a cell or its descendants if a form is unsubmitted.

Recipe.

Import packages

import marimo as mo
Create a submittable form.

form = mo.ui.text(label=""Your name"").form()
form
Use mo.stop to stop execution when the form is unsubmitted.

mo.stop(form.value is None, mo.md(""Submit the form to continue""))

mo.md(f""Hello, {form.value}!"")
Grouping UI elements together
Create an array of UI elements
Use cases. In order to synchronize UI elements between the frontend and backend (Python), marimo requires you to assign UI elements to global variables. But sometimes you don’t know the number of elements to make until runtime: for example, maybe you want o make a list of sliders, and the number of sliders to make depends on the value of some other UI element.

You might be tempted to create a Python list of UI elements, such as l = [mo.ui.slider(1, 10) for i in range(number.value)]: however, this won’t work, because the sliders are not bound to global variables.

For such cases, marimo provides the “higher-order” UI element mo.ui.array, which lets you make a new UI element out of a list of UI elements: l = mo.ui.array([mo.ui.slider(1, 10) for i in range(number.value)]). The value of an array element is a list of the values of the elements it wraps (in this case, a list of the slider values). Any time you interact with any of the UI elements in the array, all cells referencing the array by name (in this case, “l”) will run automatically.

Recipe.

Import packages.

import marimo as mo
Use mo.ui.array to group together many UI elements into a list.

import random

# instead of random.randint, in your notebook you'd use the value of
# an upstream UI element or other Python object
array = mo.ui.array([mo.ui.text() for i in range(random.randint(1, 10))])
array
Get the value of the UI elements using array.value

array.value
Create a dictionary of UI elements
Use cases. Same as for creating an array of UI elements, but lets you name each of the wrapped elements with a string key.

Recipe.

Import packages.

import marimo as mo
Use mo.ui.dictionary to group together many UI elements into a list.

import random

# instead of random.randint, in your notebook you'd use the value of
# an upstream UI element or other Python object
dictionary = mo.ui.dictionary({str(i): mo.ui.text() for i in range(random.randint(1, 10))})
dictionary
Get the value of the UI elements using dictionary.value

dictionary.value
Embed a dynamic number of UI elements in another output
Use cases. When you want to embed a dynamic number of UI elements in other outputs (like tables or markdown).

Recipe.

Import packages

import marimo as mo
Group the elements with mo.ui.dictionary or mo.ui.array, then retrieve them from the container and display them elsewhere.

import random

n_items = random.randint(2, 5)

# Create a dynamic number of elements using `mo.ui.dictionary` and
# `mo.ui.array`
elements = mo.ui.dictionary(
    {
        ""checkboxes"": mo.ui.array([mo.ui.checkbox() for _ in range(n_items)]),
        ""texts"": mo.ui.array(
            [mo.ui.text(placeholder=""task ..."") for _ in range(n_items)]
        ),
    }
)

mo.md(
    f""""""
    Here's a TODO list of {n_items} items\n\n
    """"""
    + ""\n\n"".join(
        # Iterate over the elements and embed them in markdown
        [
            f""{checkbox} {text}""
            for checkbox, text in zip(
                elements[""checkboxes""], elements[""texts""]
            )
        ]
    )
)
Get the value of the elements

elements.value
Create a hstack (or vstack) of UI elements with on_change handlers
Use cases. Arrange a dynamic number of UI elements in a hstack or vstack, for example some number of buttons, and execute some side-effect when an element is interacted with, e.g. when a button is clicked.

Recipe.

Import packages

import marimo as mo
Create buttons in mo.ui.array and pass them to hstack – a regular Python list won’t work. Make sure to assign the array to a global variable.

import random


# Create a state object that will store the index of the
# clicked button
get_state, set_state = mo.state(None)

# Create an mo.ui.array of buttons - a regular Python list won't work.
buttons = mo.ui.array(
    [
        mo.ui.button(
            label=""button "" + str(i), on_change=lambda v, i=i: set_state(i)
        )
        for i in range(random.randint(2, 5))
    ]
)

mo.hstack(buttons)
Get the state value

get_state()
Create a table column of buttons with on_change handlers
Use cases. Arrange a dynamic number of UI elements in a column of a table, and execute some side-effect when an element is interacted with, e.g. when a button is clicked.

Recipe.

Import packages

import marimo as mo
Create buttons in mo.ui.array and pass them to mo.ui.table. Make sure to assign the table and array to global variables

import random


# Create a state object that will store the index of the
# clicked button
get_state, set_state = mo.state(None)

# Create an mo.ui.array of buttons - a regular Python list won't work.
buttons = mo.ui.array(
    [
        mo.ui.button(
            label=""button "" + str(i), on_change=lambda v, i=i: set_state(i)
        )
        for i in range(random.randint(2, 5))
    ]
)

# Put the buttons array into the table
table = mo.ui.table(
    {
        ""Action"": [""Action Name""] * len(buttons),
        ""Trigger"": list(buttons),
    }
)
table
Get the state value

get_state()
Create a form with multiple UI elements
Use cases. Combine multiple UI elements into a form so that submission of the form sends all its elements to Python.

Recipe.

Import packages.

import marimo as mo
Use mo.ui.form and Html.batch to create a form with multiple elements.

form = mo.md(
   r""""""
   Choose your algorithm parameters:

   - $\epsilon$: {epsilon}
   - $\delta$: {delta}
   """"""
).batch(epsilon=mo.ui.slider(0.1, 1, step=0.1), delta=mo.ui.number(1, 10)).form()
form
Get the submitted form value.

form.value
Working with buttons
Create a button that triggers computation when clicked
Use cases. To trigger a computation on button click and only on button click, use mo.ui.run_button().

Recipe.

Import packages

import marimo as mo
Create a run button

button = mo.ui.run_button()
button
Run something only if the button has been clicked.

mo.stop(not button.value, ""Click 'run' to generate a random number"")

import random
random.randint(0, 1000)
Create a counter button
Use cases. A counter button, i.e. a button that counts the number of times it has been clicked, is a helpful building block for reacting to button clicks (see other recipes in this section).

Recipe.

Import packages

import marimo as mo
Use mo.ui.button and its on_click argument to create a counter button.

# Initialize the button value to 0, increment it on every click
button = mo.ui.button(value=0, on_click=lambda count: count + 1)
button
Get the button value

button.value
Create a toggle button
Use cases. Toggle between two states using a button with a button that toggles between True and False. (Tip: you can also just use mo.ui.switch.)

Recipe.

Import packages

import marimo as mo
Use mo.ui.button and its on_click argument to create a toggle button.

# Initialize the button value to False, flip its value on every click.
button = mo.ui.button(value=False, on_click=lambda value: not value)
button
Toggle between two outputs using the button value.

mo.md(""True!"") if button.value else mo.md(""False!"")
Re-run a cell when a button is pressed
Use cases. For example, you have a cell showing a random sample of data, and you want to resample on button press.

Recipe.

Import packages

import marimo as mo
Create a button without a value, to function as a trigger.

button = mo.ui.button()
button
Reference the button in another cell.

# the button acts as a trigger: every time it is clicked, this cell is run
button

# Replace with your custom lgic
import random
random.randint(0, 100)
Run a cell when a button is pressed, but not before
Use cases. Wait for confirmation before executing downstream cells (similar to a form).

Recipe.

Import packages

import marimo as mo
Create a counter button.

button = mo.ui.button(value=0, on_click=lambda count: count + 1)
button
Only execute when the count is greater than 0.

# Don't run this cell if the button hasn't been clicked, using mo.stop.
# Alternatively, use an if expression.
mo.stop(button.value == 0)

mo.md(f""The button was clicked {button.value} times"")
Reveal an output when a button is pressed
Use cases. Incrementally reveal a user interface.

Recipe.

Import packages

import marimo as mo
Create a counter button.

button = mo.ui.button(value=0, on_click=lambda count: count + 1)
button
Show an output after the button is clicked.

mo.md(""#"" + """" * button.value) if button.value > 0 else None
Caching
Cache expensive computations
Use case. Because marimo runs cells automatically as code and UI elements change, it can be helpful to cache expensive intermediate computations. For example, perhaps your notebook computes t-SNE, UMAP, or PyMDE embeddings, and exposes their parameters as UI elements. Caching the embeddings for different configurations of the elements would greatly speed up your notebook.

Recipe.

Use functools to cache function outputs given inputs.

import functools

@functools.cache
def compute_predictions(problem_parameters):
   # replace with your own function/parameters
   ...
Whenever compute_predictions is called with a value of problem_parameters it has not seen, it will compute the predictions and store them in a cache. The next time it is called with the same parameters, instead of recomputing the predictions, it will return the previously computed value from the cache.

See our best practices guide to learn more.",What are the ways of grouping UI elements together?,"UI elements can be grouped together using the following methods:
- Create an array of UI elements.
- Create a dictionary of UI elements.
- Embed a dynamic number of UI elements in another output.
- Create a hstack (or vstack) of UI elements with on_change handlers.
- Create a table column of buttons with on_change handlers
- Create a form with multiple UI elements.","UI elements can be grouped by using:
- Arrays of UI elements
- Dictionaries of UI elements
- Dynamic embedding in outputs
- Horizontal/Vertical stacks with handlers
- Table columns with change handlers
- Forms with multiple elements","UI elements can only be grouped using arrays. Dictionaries are not supported, and there are no provisions for embedding dynamic numbers of UI elements. There is also no method to use stacks or tables for this purpose."
14,"My eyes felt like galaxies—holding the swirling glow of countless memories—as I took in our childhood home. Its siding looked like remnants of driftwood after a bonfire. I swore I smelled the smoky char of pine creep into my nostrils. It’s wild how the past stays with you like that. It can feel more visceral and real than the tangible things right in front of you.

“Jesus, it feels like just yesterday.” I placed a trembling hand over my heart, struggling to steady my breath.

My brother, Perry, pulled me into a tight embrace, his strength grounding me like an anchor.

“The house hasn’t changed much,” he said, his voice steady and comforting. “But we have.” His certainty made me question, Have I really changed?

Between the two of us, Perry was as solid and stoic as a mountain range. Good thing, because I was like the wind—flighty and unpredictable. Over the years, Perry had learned to handle even my harshest hurricanes.

Being his older sister—even if only by four minutes—I always wished I’d been his protector rather than the other way around. But that demon burning deep in my belly also flashed a crooked smile, knowing that Perry would never abandon me, especially since I got sober.

I hadn’t had a drink in exactly seven hundred and thirty days, and although it remained unsaid, I knew Perry was terrified of leaving me to my own devices in fear I would relapse.

Our sibling bond was iron-clad. After we lost our parents in the fire (my mother didn’t properly butt out her 2:00 am cigarette and well, the rest is history), all Perry and I had was each other. But let’s call a spade a spade; we were also as fucked up and as co-dependent as it gets. Who mutually decides to visit the catalyst of your alcohol addiction on the anniversary of your sobriety?

The house’s dilapidated front door creaked as Perry gently pushed it open. The rusted metal hinges were holding it up by a thread.

“After you.” Perry gestured me in, squinting from the sunlight. He was a gentleman, even in such obscurity.

As he held the door open, the shallow scar on his right cheek taunted me like some kind of schoolyard bully. His wound often pulled me in like that. Some days, I was sure I would dive right into it and drown. Other days, I prayed to God and the Devil himself to just let me fucking drown, already.

That mark became permanently etched on Perry’s face on the day I quit drinking, exactly seven hundred and thirty days ago. That was the day Perry screamed bloody murder at me from the passenger seat, “Jackie! Stop the fucking car!” But my bloodstream was far too poisoned with Bacardi Limon to listen. All I remember next was my vehicle being wrapped around a tree. I could have died that day, but what truly disturbed me in the middle of the night was the fact that I almost killed Perry.

A lot can happen in seven hundred and thirty days. But I assure you, forgiving yourself isn’t one of them.

“Well? You coming in?” Perry was still holding the door ajar.

I shook it off and gave my brother a knowing glance. I swear, even though we were fraternal, we had twin telepathy. I exhaled and walked in.

“Watch your step,” I warned, my forehead tense.

I imagined the rickety floorboards collapsing, crashing us into what had once been our dad’s “man cave”. That’s where he was passed out, the night of the fire.

“Kids, stay here. Do not move,” our mother demanded after getting us out of the house safely. I remember the black soot on her face and the spiderweb veins in her eyes. She shook us firmly by the forearms. “I’m getting your father.”

Perry and I held each other, shaking. The heat from the inferno felt like standing in a volcano. We never saw our parents again.

Two decades later, there we were—Perry and I—-making our way through the wreckage of our home. It was midday, yet the inside of the house screamed a tone of pale blue midnight. My shoulders were up to my ears, as though we were walking through a haunted house attraction.

I coughed into my forearm. The ocean of dust was thick like butter. As I cleared my lungs, Perry called out from behind me.

“Jacks, look at this! The fireplace,” Perry's voice was filled with awe.

“Unbelievable. It’s still here,” I whispered, a lump forming in my throat.

It was as though a Fairy Godmother breezed by and brought the decaying living room to life with her magical paintbrush. Kind of like in “Titanic”, when they showed the sunken ship underwater, versus in its prestige as it sailed across the Atlantic.

We made our way over to the fireplace and sat cross-legged on the floor.

“This was our favorite spot, remember?” I avoided his gaze, overwhelmed by the flood of memories.

“Yeah,” Perry murmured, his eyes softening with nostalgia.

For a moment, the taste of crispy, fire roasted marshmallows superseded the saturated stench of mildew.

“Remember our s’mores nights?” I asked.

“Duh. What about all our fireplace movie nights?” Perry proceeded to do his best, nasally, childhood impersonation of me, “But mom! I want to watch Beauty and the Beast!! Perry always gets to pick the movie!!”

I punched him in the arm, “First of all, I never sounded like that. And second. So what? I knew what I wanted.”

The corners of Perry’s mouth lifted. He had such a sincere sparkle about him, as though a storm cloud of confetti followed him overhead wherever he went, “You really did, kiddo.”

My chest went heavy. How could Perry love me after everything I had done? After all the relationships I’d ruined? All the jobs I’d lost? All of his relationships I’d ruined? How could he still choose me, when so often I had chosen a forty of Jack Daniels over him?

How could Perry still love me after I almost fucking killed him?

Perry’s gaze widened, “Hey! Remember when Mom would bring out those hot drinks she always made?” He paused, almost as if he was searching for the right term. “Apple… something? Apple ssshhh…”

I snapped my fingers, “Apple-Schnapple!”

“Yes!”

“I mean, looking back it was basically just hot apple cider, but damn it was good.” And it really was.

Our laughs echoed throughout the abandoned asylum we once called home.

Perry leaned back, holding himself up with his hands. “I loved our fireplace hangs. Especially our movie nights down here. But nothing beats our movies up in the projector room.”

I tilted my head, “We never had a projector room.”

Perry playfully “shoo’d” me away.

“No. Perry. I would remember us having a projector room. Our movie nights together were our favorite thing. You even just said it yourself.”

The house suddenly became pin-drop silent as Perry leaned in. ""Memories are quite something, aren’t they?"" The slight shift in his tone made my skin crawl. Perry was always wistful, but this felt different, almost… clinical, ""We often remember things in ways that are… easier for us to digest.""

I was fidgety. “Gees Perry. You sound like Dr. Lasko.”

He seemed to enjoy my little joke.

Dr. Lasko had been my therapist since the accident, and I would go out on a limb and say that he would not have approved of this self-inflicted exposure therapy I was subjecting myself to by visiting the house.

Perry seemingly snapped out of his little therapist moment and went right back to being his sparkly confetti self. As I watched his amicable face scan the mantle above the fireplace, I felt a sickening uneasiness. Imagine you had actually fucking killed him.

“Man, I can still picture all our family photos up there,” Perry’s childlike wonder destroyed me.

My face went flush. I could feel the water rising in my eyes like the tides. How pathetic and infuriating was it that after everything I’d done, I was still somehow the victim.

“Hey.” He took my hand.

“Oh Perry,”  I threw myself into him. “I’m so sorry.”

My brother held me with his usual care that I didn’t deserve.

“Jacks, it’s ok. I’m still here. We’re both still here.”

As my chin rested on my brother’s shoulder, I looked ahead of me at the remains of the house. Something felt off, and it wasn’t just the overall unsettling environment. My brow furrowed. “Wasn’t the doorway to the kitchen on the other side of the living room?”

I felt Perry shrug, “I don’t think so.”

I was staring into the out of place doorway like I was trying to pull a recollection towards me. And that’s when I saw them in the kitchen: the translucent memory of mom and dad. Mom was getting our Apple-Schnapples ready. She was pacing, unlike Dad, who was sitting motionless at the table. His face was planted on its mahogany surface. His glass of Apple-Schnapple was empty, and so was the bottle of Jim Beam beside it.

Mom floated into the living room, our warm beverages in hand and a cigarette in her mouth, “Kids, your father’s not feeling well. Let’s have our Apple-Schnapples in here.”

Oh my God. The bruise on her face.

Perry jarred me back to reality with the gut punch of what he had to say next, “You’re remembering the truth about mom and dad, aren’t you?”

I pushed myself off and away from him. “How did you…”

My brother looked down, delicately tracing the floor with his finger, “We always put them on a pedestal after they died.”

I felt a shiver run down my spine, “What are you talking about?”

As Perry continued to speak, his words grew even more detached. ""Do you remember that first drink Dad ever gave you?""

My eyes darted around the room as my jugular pulsed in my neck. As much as I tried to escape what Perry had just said, I did remember.

I could hear my dad’s slurring words of encouragement, “Come on, Jackie. Just one drink. It’ll be our special time, just you and me.”

The bitterness of that first sip of beer made me squirm, but sharing a “special time” with my dad—and the desperate yearning that maybe he did love me, afterall—was the overwhelm of the full moon swallowing me whole. I was only a child, and much like how my mom turned a blind eye to my father’s drinking, she did the exact same when it came to her daughter.

I’d used the death of my parents as the excuse for my alcoholism for so long, because admitting that they helped create the monster I would eventually become was like a knife to the heart. And knowing I had been too weak to conquer the addiction from my own volition just made the weapon twist in my chest.

The room was spinning. My face was blistering hot like the night of the fire. Or was that the warm heat from the fireplace when we were kids? The childhood fireplace memories ran through my mind, frame by frame, until…..they eventually vaporized to nothing. I crouched over, thinking I might vomit.

“We never had a fireplace.” Perry was nodding, very matter-of-factly.

My fingernails dug into my thighs when I looked at the fireplace and: it was gone. Only a blank wall of faded, forest green wallpaper remained. Our house was once on fire, yes, but that was it. There was never a happy childhood fireplace. Ever.

My hands were cold and clammy. I fell back onto the wall behind me. “Perry. Where are we?”

He stood up and glided towards the staircase. One hand on the banister, his footsteps creaked, one by one, as he made his way to the second floor.

My mouth was bone dry, “Perry!”

He stopped and turned towards me, “Come to the projector room. We love watching movies together, don’t we? There’s a movie I’d like to show you.”

As my brother disappeared from sight, I did what any classic horror movie trope would tell you to do: I went upstairs.

I found Perry standing at the end of the ominous hallway. Large, empty picture frames lined the oxblood walls leading up to him. Through the doorway where Perry stood, particles in the air danced in the projector’s cone-shaped light. That telltale winding of a film reel was the only sound in the deafening quiet of this house that I no longer recognized.

Half of Perry’s face—the one with the scar—was perfectly illuminated, as though he was wearing the mask from “The Phantom of the Opera”. “I think you’re ready to see how this movie ends, Jackie. This is the most progress you’ve made since we’ve been coming here.”

I gripped my thumbs in the palms of my hands, “Perry, you’re freaking the fuck out of me!”

I thought my knees might buckle as my brother’s face glitched, like a flash of static snow on a television set. As his face settled back to normal to a deadpan gaze, he disappeared in the innocuous room. I followed, running on nothing but fumes.

Clutching the doorway, my mouth fell agape. Perry was gone. I darted to the middle of the room.

As I frantically searched for my brother, I shielded my eyes with the back of my hand from the projector’s light. And that’s when, from behind me, I heard five words that made my blood run cold, “Jackie! Stop the fucking car!”

I was convulsing yet paralyzed. Moving as slowly as cold molasses, I rotated on the spot towards my worst nightmare, shown on 35 mm. On the projector screen was Perry and me in my car, exactly seven hundred and thirty days ago, the day I almost kill—

Oh my God.

My head pounded as fragmented memories surged. The reality of what happened began to crystallize, unrelenting.

My joints ached and my stomach churned. Clamping a hand over my mouth to stifle a scream, I stumbled down the hallway as it began caving in on itself. The picture frames were sucked into the walls. The floorboards cracked into distorted peaks and valleys. Wooden beams swung down from the ceiling like pendulums. I tried to spit out the chalky grit of disintegrating drywall that made the hallway look like a winter squall.

Panting heavily, I stopped dead in my tracks at the stained glass window. My body trembled with an all-too-familiar dread. Each time I faced this, I wondered if this fall would be the one that would finally end it all.

Maybe it’d be better if it did.

Holding my breath, I threw myself through the glass, my hands clawing the air for dear life. Free falling two stories feels like an eternity when you’re watching the memory of your childhood home fall apart before your very eyes. But when the weight of my body finally made contact with the earth I—

I gasped. The cold air of the hospital room shocked my lungs. I sat up, ripping the suction cups from my face and body. My gown was clinging to me, soaked in sweat. Medical equipment beeped all around me like a metronome.

Dr. Lasko, my therapist since the accident, sat across the stark white room, sighing as he rubbed his forehead. He, too, was connected to a plethora of suction cups and wires. He looked a little worn out in the fluorescent overhead lighting. Ever since I was hospitalized and later incarcerated, Dr. Lasko had been helping me delve into my memories, namely the ones that were too excruciating for me to face. And as such, Dr. Lasko had been appearing in the simulations as my brother Perry, the love of my life who died in the car crash, seven hundred and thirty days prior.

Disoriented, I blinked rapidly, the vividness of the memory contrasting sharply with the sterile, geometric ceiling tiles above me.

“I don’t ever want to do that again!” I was venomous.

“Jackie,” Dr. Lasko started.

“Don’t start,” I pulled up four fingers for air quotes, “‘Jackie, don’t give up. This was the closest you’ve ever come to facing the truth.”

As the initial burst of adrenal and cortisol left my body, I fell back on my pillow. I was depleted. Quiet rivers flowed down my cheeks.

Removing his own suction cups, Dr. Lasko approached my bedside and took a seat. He treaded lightly. “Jackie, I understand how challenging this is for you, but you did an incredible job today. If we continue making progress like this, there's a real possibility you'll gain your freedom sooner.”

I looked at the well-meaning doctor, but all I could see was Perry. Multicolored confetti fell softly around him like that first November snow. His face was the sun. His eyes reflected the whole world back to me.

Perry.

With a weak grip, I took Dr. Lasko’s hand. My vocal cords were like sandpaper. “I’ll leave this place one day, doc.” A single tear dripped from my chin onto my collarbone. “But I’m not sure if I’ll ever be free.”

Dr. Lasko didn’t say a word, but I felt him squeeze my hand, just a little bit tighter.

I licked the cracks on my lips as my eyes closed shut, imagining the oaky comfort of bourbon on my tongue. I felt myself drift, and good thing, because I needed the rest. Dr. Lasko and I would be delving into my memories again the following day.

No matter how masochistic it felt, I vowed to keep showing up for the simulations. Even if I never forgave myself for what I did, at least in my memories, I got to see Perry.",What references to alcohol are there,"The narrator, Jackie, had been sober for seven hundred and thirty days. Seven hundred and thirty days ago, Jackie and Perry had gotten into a car accident that almost killed the two because Jackie had been driving after drinking Bacardi Limon.

Jackie saw a translucent memmory of her dad sitting motionless at a table with an empty glass of Apple-Schnapple and an empty bottle of Jim Beam. Jackie also remembered he father giving her beer as a child and her mother ignoring this.

She used the death of her parents as an excuse for her alcoholism for so long, because admitting that they helped create the monster she would eventually become was like a knife to the heart. And knowing she had been too weak to conquer the addiction from her own volition just made the weapon twist in her chest.

Finally, at the end of the story, Jackie licked the cracks on her lips as her eyes closed shut, imagining the oaky comfort of bourbon on her tongue. She felt herself drift, which she thought a good thing, because she needed the rest.","Jackie has been sober for seven hundred and thirty days after nearly dying in a car accident due to being drunk on Bacardi Limon. She remembered her father having an empty glass of Apple-Schnapple and an empty Jim Beam bottle. Her father gave her beer as a child, and her mother ignored it, contributing to her alcoholism. Jackie used her parents' deaths as an excuse for her addiction but later acknowledged they played a role in it. At the end, she imagined the taste of bourbon as she fell asleep, preparing for another therapy session.","Jackie has been sober for a few months after a car accident caused by driving under the influence of tequila. Her father often drank gin with his Apple-Schnapple, and Jackie remembered him giving her wine instead of beer as a child. Her parents died in an unrelated accident, and Jackie cited their absence as the reason for her alcoholism. At the end, she imagined the taste of rum while drifting to sleep, preferring to avoid more therapy."
