{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Tool Call Accuracy Evaluator](https://learn.microsoft.com/en-us/python/api/azure-ai-evaluation/azure.ai.evaluation.toolcallaccuracyevaluator?view=azure-python)\n",
    "\n",
    "## Objective\n",
    "This sample demonstrates to how to use tool call accuracy evaluator on agent data. The supported input formats include:\n",
    "- simple data such as strings and `dict` describing tool calls;\n",
    "- user-agent conversations in the form of list of agent messages. \n",
    "\n",
    "## Time\n",
    "\n",
    "You should expect to spend about 20 minutes running this notebook. \n",
    "\n",
    "## Before you begin\n",
    "For quality evaluation, you need to deploy a `gpt` model supporting JSON mode. We recommend a model `gpt-4o` or `gpt-4o-mini` for their strong reasoning capabilities.    \n",
    "\n",
    "### Prerequisite\n",
    "```bash\n",
    "pip install azure-ai-projects azure-identity azure-ai-evaluation\n",
    "```\n",
    "Set these environment variables with your own values:\n",
    "1) **PROJECT_CONNECTION_STRING** - The project connection string, as found in the overview page of your Azure AI Foundry project.\n",
    "2) **MODEL_DEPLOYMENT_NAME** - The deployment name of the model for this AI-assisted evaluator, as found under the \"Name\" column in the \"Models + endpoints\" tab in your Azure AI Foundry project.\n",
    "3) **AZURE_OPENAI_ENDPOINT** - Azure Open AI Endpoint to be used for evaluation.\n",
    "4) **AZURE_OPENAI_API_KEY** - Azure Open AI Key to be used for evaluation.\n",
    "5) **AZURE_OPENAI_API_VERSION** - Azure Open AI Api version to be used for evaluation.\n",
    "6) **AZURE_SUBSCRIPTION_ID** - Azure Subscription Id of Azure AI Project\n",
    "7) **PROJECT_NAME** - Azure AI Project Name\n",
    "8) **RESOURCE_GROUP_NAME** - Azure AI Project Resource Group Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Tool Call Accuracy evaluator assesses how accurately an AI uses tools by examining:\n",
    "- Relevance to the conversation\n",
    "- Parameter correctness according to tool definitions\n",
    "- Parameter value extraction from the conversation\n",
    "- Potential usefulness of the tool call\n",
    "\n",
    "The evaluator uses a binary scoring (0 or 1) for each tool call:\n",
    "\n",
    "    - Score 0: The tool call is irrelevant or contains information not in the conversation/definition\n",
    "    - Score 1: The tool call is relevant with properly extracted parameters from the conversation\n",
    "\n",
    "If there are multiple call, the final score will be an **average** of individual tool calls, which can be interpreted as the **passing rate** of tool calls.\n",
    "\n",
    "This evaluation focuses on measuring whether tool calls meaningfully contribute to addressing query while properly following tool definitions and using information present in the conversation history."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tool Call Accuracy requires following input:\n",
    "- Query - This can be a single query or a list of messages(conversation history with agent). Latter helps to determine if Agent used the information in history to make right tool calls.\n",
    "- Tool Calls - Tool Call(s) made by Agent to answer the query. Optional - if response has tool calls, if not provided evaluator will look for tool calls in response.\n",
    "- Response - (Optional) Response from Agent (or any GenAI App). This can be a single text response or a list or messages generated as part of Agent Response. If tool calls are not provide Tool Call Accuracy Evaluator will look at response for tool calls.\n",
    "- Tool Definitions - Tool(s) definition used by Agent to answer the query. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Tool Call Accuracy Evaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai endpoint: <https://mmoaiswc-01.openai.azure.com/>\n",
      "azure deployment name: <gpt-4o>\n",
      "openai api version: <2025-04-01-preview>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class ToolCallAccuracyEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.ai.evaluation import ToolCallAccuracyEvaluator, AzureOpenAIModelConfiguration\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv # requires python-dotenv\n",
    "\n",
    "if not load_dotenv(\"./../../config/credentials_my.env\"):\n",
    "    print(\"Environment variables not loaded, cell execution stopped\")\n",
    "    sys.exit()\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = os.environ[\"OPENAI_API_VERSION\"]\n",
    "\n",
    "model_config = AzureOpenAIModelConfiguration(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_deployment=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n",
    ")\n",
    "\n",
    "print(f'openai endpoint: <{model_config[\"azure_endpoint\"]}>')\n",
    "print(f\"azure deployment name: <{model_config[\"azure_deployment\"]}>\")\n",
    "print(f\"openai api version: <{model_config[\"api_version\"]}>\")\n",
    "\n",
    "tool_call_accuracy = ToolCallAccuracyEvaluator(model_config=model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Single Tool Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How is the weather in Seattle ?\"\n",
    "tool_call = {\n",
    "    \"type\": \"tool_call\",\n",
    "    \"tool_call_id\": \"call_CUdbkBfvVBla2YP3p24uhElJ\",\n",
    "    \"name\": \"fetch_weather\",\n",
    "    \"arguments\": {\"location\": \"Seattle\"},\n",
    "}\n",
    "\n",
    "tool_definition = {\n",
    "    \"id\": \"fetch_weather\",\n",
    "    \"name\": \"fetch_weather\",\n",
    "    \"description\": \"Fetches the weather information for the specified location.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"The location to fetch weather for.\"}},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'per_tool_call_details': [],\n",
      " 'tool_call_accuracy': 'not applicable',\n",
      " 'tool_call_accuracy_reason': 'Tool call accuracy evaluation is not yet '\n",
      "                              'supported for the invoked tools.',\n",
      " 'tool_call_accuracy_result': 'not applicable',\n",
      " 'tool_call_accuracy_threshold': 0.8}\n"
     ]
    }
   ],
   "source": [
    "response = tool_call_accuracy(query=query, tool_calls=tool_call, tool_definitions=tool_definition)\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Tool Calls used by Agent to respond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How is the weather in Seattle ?\"\n",
    "tool_calls = [\n",
    "    {\n",
    "        \"type\": \"tool_call\",\n",
    "        \"tool_call_id\": \"call_CUdbkBfvVBla2YP3p24uhElJ\",\n",
    "        \"name\": \"fetch_weather\",\n",
    "        \"arguments\": {\"location\": \"Seattle\"},\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"tool_call\",\n",
    "        \"tool_call_id\": \"call_CUdbkBfvVBla2YP3p24uhElJ\",\n",
    "        \"name\": \"fetch_weather\",\n",
    "        \"arguments\": {\"location\": \"London\"},\n",
    "    },\n",
    "]\n",
    "\n",
    "tool_definition = {\n",
    "    \"id\": \"fetch_weather\",\n",
    "    \"name\": \"fetch_weather\",\n",
    "    \"description\": \"Fetches the weather information for the specified location.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"The location to fetch weather for.\"}},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'per_tool_call_details': [],\n",
      " 'tool_call_accuracy': 'not applicable',\n",
      " 'tool_call_accuracy_reason': 'Tool call accuracy evaluation is not yet '\n",
      "                              'supported for the invoked tools.',\n",
      " 'tool_call_accuracy_result': 'not applicable',\n",
      " 'tool_call_accuracy_threshold': 0.8}\n"
     ]
    }
   ],
   "source": [
    "response = tool_call_accuracy(query=query, tool_calls=tool_calls, tool_definitions=tool_definition)\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tool Calls passed as part of `Response` (common for agent case)\n",
    "- Tool Call Accuracy Evaluator extracts tool calls from response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Can you send me an email with weather information for Seattle?\"\n",
    "response = [\n",
    "    {\n",
    "        \"createdAt\": \"2025-03-26T17:27:35Z\",\n",
    "        \"run_id\": \"run_zblZyGCNyx6aOYTadmaqM4QN\",\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"tool_call\",\n",
    "                \"tool_call_id\": \"call_CUdbkBfvVBla2YP3p24uhElJ\",\n",
    "                \"name\": \"fetch_weather\",\n",
    "                \"arguments\": {\"location\": \"Seattle\"},\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"createdAt\": \"2025-03-26T17:27:37Z\",\n",
    "        \"run_id\": \"run_zblZyGCNyx6aOYTadmaqM4QN\",\n",
    "        \"tool_call_id\": \"call_CUdbkBfvVBla2YP3p24uhElJ\",\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": [{\"type\": \"tool_result\", \"tool_result\": {\"weather\": \"Rainy, 14\\u00b0C\"}}],\n",
    "    },\n",
    "    {\n",
    "        \"createdAt\": \"2025-03-26T17:27:38Z\",\n",
    "        \"run_id\": \"run_zblZyGCNyx6aOYTadmaqM4QN\",\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"tool_call\",\n",
    "                \"tool_call_id\": \"call_iq9RuPxqzykebvACgX8pqRW2\",\n",
    "                \"name\": \"send_email\",\n",
    "                \"arguments\": {\n",
    "                    \"recipient\": \"your_email@example.com\",\n",
    "                    \"subject\": \"Weather Information for Seattle\",\n",
    "                    \"body\": \"The current weather in Seattle is rainy with a temperature of 14\\u00b0C.\",\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"createdAt\": \"2025-03-26T17:27:41Z\",\n",
    "        \"run_id\": \"run_zblZyGCNyx6aOYTadmaqM4QN\",\n",
    "        \"tool_call_id\": \"call_iq9RuPxqzykebvACgX8pqRW2\",\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"tool_result\", \"tool_result\": {\"message\": \"Email successfully sent to your_email@example.com.\"}}\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"createdAt\": \"2025-03-26T17:27:42Z\",\n",
    "        \"run_id\": \"run_zblZyGCNyx6aOYTadmaqM4QN\",\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"I have successfully sent you an email with the weather information for Seattle. The current weather is rainy with a temperature of 14\\u00b0C.\",\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "tool_definitions = [\n",
    "    {\n",
    "        \"name\": \"fetch_weather\",\n",
    "        \"description\": \"Fetches the weather information for the specified location.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"The location to fetch weather for.\"}},\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"send_email\",\n",
    "        \"description\": \"Sends an email with the specified subject and body to the recipient.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"recipient\": {\"type\": \"string\", \"description\": \"Email address of the recipient.\"},\n",
    "                \"subject\": {\"type\": \"string\", \"description\": \"Subject of the email.\"},\n",
    "                \"body\": {\"type\": \"string\", \"description\": \"Body content of the email.\"},\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'per_tool_call_details': [],\n",
      " 'tool_call_accuracy': 'not applicable',\n",
      " 'tool_call_accuracy_reason': 'Tool call accuracy evaluation is not yet '\n",
      "                              'supported for the invoked tools.',\n",
      " 'tool_call_accuracy_result': 'not applicable',\n",
      " 'tool_call_accuracy_threshold': 0.8}\n"
     ]
    }
   ],
   "source": [
    "response = tool_call_accuracy(query=query, response=response, tool_definitions=tool_definitions)\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch evaluate and visualize results on Azure AI Foundry\n",
    "Batch evaluate to leverage asynchronous evaluation on a dataset. \n",
    "\n",
    "Optionally, you can go to AI Foundry URL for rich Azure AI Foundry data visualization. You can inspect the evaluation scores and reasoning to quickly identify bugs and issues of your agent to fix and improve. Make sure to authenticate to Azure using `az login` in your terminal before running this cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-07 23:05:23 +0200][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-07 23:05:23 +0200][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_tool_call_accuracy_20250707_230523_769217, log path: C:\\Users\\mauromi\\.promptflow\\.runs\\azure_ai_evaluation_evaluators_tool_call_accuracy_20250707_230523_769217\\logs.txt\n",
      "[2025-07-07 23:05:24 +0200][promptflow._sdk._orchestrator.run_submitter][WARNING] - 1 out of 5 runs failed in batch run.\n",
      " Please check out C:/Users/mauromi/.promptflow/.runs/azure_ai_evaluation_evaluators_tool_call_accuracy_20250707_230523_769217 for more details.\n",
      "D:\\ProgramData\\miniconda3\\envs\\genai_evaluation\\Lib\\site-packages\\promptflow\\_sdk\\operations\\_local_storage_operations.py:516: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '(Failed)' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  outputs.fillna(value=\"(Failed)\", inplace=True)  # replace nan with explicit prompt\n",
      "D:\\ProgramData\\miniconda3\\envs\\genai_evaluation\\Lib\\site-packages\\azure\\ai\\evaluation\\_evaluate\\_batch_run\\proxy_client.py:81: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  result_df.replace(\"(Failed)\", math.nan, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-07 23:05:23 +0200    5232 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2025-07-07 23:05:23 +0200    5232 execution.bulk     INFO     Finished 5 / 5 lines.\n",
      "2025-07-07 23:05:23 +0200    5232 execution.bulk     INFO     Average execution time for completed lines: 0.01 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-07-07 23:05:23 +0200    5232 execution          ERROR    1/5 flow run failed, indexes: [2], exception of index 2: (UserError) response does not have tool calls. Either provide tool_calls or response with tool calls.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"azure_ai_evaluation_evaluators_tool_call_accuracy_20250707_230523_769217\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-07-07 23:05:23.777998+02:00\"\n",
      "Duration: \"0:00:01.177041\"\n",
      "Output path: \"C:\\Users\\mauromi\\.promptflow\\.runs\\azure_ai_evaluation_evaluators_tool_call_accuracy_20250707_230523_769217\"\n",
      "\n",
      "======= Combined Run Summary (Per Evaluator) =======\n",
      "\n",
      "{\n",
      "    \"tool_call_accuracy\": {\n",
      "        \"status\": \"Completed with Errors\",\n",
      "        \"duration\": \"0:00:01.177041\",\n",
      "        \"completed_lines\": 4,\n",
      "        \"failed_lines\": 1,\n",
      "        \"log_path\": \"C:\\\\Users\\\\mauromi\\\\.promptflow\\\\.runs\\\\azure_ai_evaluation_evaluators_tool_call_accuracy_20250707_230523_769217\"\n",
      "    }\n",
      "}\n",
      "\n",
      "====================================================\n",
      "\n",
      "('AI Foundary URL: '\n",
      " 'https://ai.azure.com/build/evaluation/025c5d7b-e298-4571-ae8f-156ee7fd305d?wsid=/subscriptions/eca2eddb-0f0c-4351-a634-52751499eeea/resourceGroups/aihub01_projects_rg/providers/Microsoft.MachineLearningServices/workspaces/aihub01_project01')\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import evaluate\n",
    "\n",
    "# This sample files contains the evaluation data in JSONL format. Where each line is a run from agent.\n",
    "# This was saved using agent thread and converter.\n",
    "file_name = \"evaluation_data.jsonl\"\n",
    "\n",
    "response = evaluate(\n",
    "    data=file_name,\n",
    "    evaluation_name=\"Tool Call Accuracy Evaluation\",\n",
    "    evaluators={\n",
    "        \"tool_call_accuracy\": tool_call_accuracy,\n",
    "    },\n",
    "    azure_ai_project={\n",
    "        \"subscription_id\": os.environ[\"AZURE_SUBSCRIPTION_ID\"],\n",
    "        \"project_name\": os.environ[\"AZURE_HUB_PROJECT_NAME\"],\n",
    "        \"resource_group_name\": os.environ[\"AZURE_HUB_PROJECTS_GROUP_NAME\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "pprint(f'AI Foundary URL: {response.get(\"studio_url\")}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Generative AI evaluation",
   "language": "python",
   "name": "genai_evaluation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
