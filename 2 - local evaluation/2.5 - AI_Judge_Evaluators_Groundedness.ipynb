{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c479b344-f6ae-454d-a96c-85f9137f16dc",
   "metadata": {},
   "source": [
    "# [Groundedness and Groundedness PRO Evaluators](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/evaluate-sdk#built-in-evaluators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43f1ba86-e977-4636-8887-04394b833f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b8ac0ff-c633-4603-b3bf-c63ef79b1995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and Libraries\n",
    "import os\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider #requires azure-identity\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv # requires python-dotenv\n",
    "\n",
    "if not load_dotenv(\"./../../config/credentials_my.env\"):\n",
    "    print(\"Environment variables not loaded, cell execution stopped\")\n",
    "    sys.exit()\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = os.environ[\"OPENAI_API_VERSION\"]\n",
    "\n",
    "credential = DefaultAzureCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4edd78d8-45bd-46ec-aca1-26f28afa8b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Azure AI project and Azure OpenAI connection\n",
    "azure_ai_project_config = {\n",
    "    \"subscription_id\": os.environ.get(\"AZURE_SUBSCRIPTION_ID\"),\n",
    "    \"resource_group_name\": os.environ.get(\"AIHUB_PROJECTS_GROUP_NAME\"),\n",
    "    \"project_name\": os.environ.get(\"AIHUB_PROJECT_NAME\"),\n",
    "}\n",
    "\n",
    "model_config = {\n",
    "    \"azure_endpoint\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    \"api_key\": os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    \"azure_deployment\": os.environ.get(\"MODEL_DEPLOYMENT_NAME\"),\n",
    "    \"api_version\": os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d87e4c0b-e712-41ae-b3bd-0e1857e1deae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class GroundednessProEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    }
   ],
   "source": [
    "# Initializing Groundedness and Groundedness Pro evaluators\n",
    "from azure.ai.evaluation import GroundednessEvaluator, GroundednessProEvaluator\n",
    "\n",
    "groundedness_eval = GroundednessEvaluator(model_config)\n",
    "groundedness_pro_eval = GroundednessProEvaluator(azure_ai_project=azure_ai_project_config, credential=credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c357db2-92a9-472c-8af1-7d8529aa5290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++ groundedness_score +++++\n",
      "{'gpt_groundedness': 3.0,\n",
      " 'groundedness': 3.0,\n",
      " 'groundedness_reason': 'The response attempts to answer the query but '\n",
      "                        'includes incorrect information, as it contradicts the '\n",
      "                        'context by stating the Alpine Explorer Tent is the '\n",
      "                        'most waterproof when the context clearly states it is '\n",
      "                        'the second most waterproof.',\n",
      " 'groundedness_result': 'pass',\n",
      " 'groundedness_threshold': 3}\n",
      "+++++ groundedness_PRO_score +++++\n",
      "{'groundedness_pro_label': True,\n",
      " 'groundedness_pro_reason': 'All Contents are grounded',\n",
      " 'groundedness_pro_result': 'pass',\n",
      " 'groundedness_pro_score': 1,\n",
      " 'groundedness_pro_threshold': 5}\n"
     ]
    }
   ],
   "source": [
    "model_config[\"type\"] = \"azure_openai\" # bug\n",
    "\n",
    "query_response = dict(\n",
    "    query=\"Which tent is the most waterproof?\",\n",
    "    context=\"The Alpine Explorer Tent is the second most water-proof of all tents available.\",\n",
    "    response=\"The Alpine Explorer Tent is the most waterproof.\"\n",
    ")\n",
    "\n",
    "# Running Groundedness PRO Evaluator on a query and response pair\n",
    "groundedness_score = groundedness_eval(\n",
    "    **query_response\n",
    ")\n",
    "print(\"+++++ groundedness_score +++++\")\n",
    "pprint(groundedness_score)\n",
    "\n",
    "# Running Groundedness Evaluator on the same query\n",
    "groundedness_pro_score = groundedness_pro_eval(\n",
    "    **query_response\n",
    ")\n",
    "print(\"+++++ groundedness_PRO_score +++++\")\n",
    "pprint(groundedness_pro_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_evaluation",
   "language": "python",
   "name": "genai_evaluation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
