{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c784d56-d236-4acb-bbb7-63ae85ef23a6",
   "metadata": {},
   "source": [
    "# Variables, Constants and Libraries definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e949a0ff-016b-4e7f-94ba-dd82d8ca8868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f34c9140-3264-47d3-8426-fdf36d8fa5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv # requires python-dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider #requires azure-identity\n",
    "from openai import AzureOpenAI\n",
    "import openai, os, json, time, glob, kagglehub # openai is used for error catching, otherwise we use AzureOpenAI\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv(\"./../config/credentials_my.env\")\n",
    "\n",
    "openai_endpoint       = os.environ[\"azure_openai_endpoint\"]\n",
    "openai_api_key        = os.environ[\"azure_openai_api_key\"]\n",
    "openai_api_version    = os.environ[\"openai_api_version\"]\n",
    "azure_deployment_name = os.environ[\"azure_openai_chat_deployment_name\"]\n",
    "\n",
    "credential            = DefaultAzureCredential()\n",
    "\n",
    "token_provider        = get_bearer_token_provider(\n",
    "    DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "folder_path = \"./enrichment\"\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "output_file_name = os.path.join(folder_path, \"questions_enriched\")\n",
    "\n",
    "# Get the current user's home directory\n",
    "home_dir = os.path.expanduser(\"~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda2da8c-5ca6-4a6b-847c-d7faa07f3c8b",
   "metadata": {},
   "source": [
    "# [Single-Topic RAG Evaluation Dataset](https://www.kaggle.com/datasets/samuelmatsuoharris/single-topic-rag-evaluation-dataset) retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dc80af2-a2a7-4cb5-9661-60cf24567c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 10\n",
    "\n",
    "enriched_df = pd.read_csv(f\"{output_file_name}.csv\")\n",
    "\n",
    "# Selecting sample_size random rows\n",
    "random_sample = enriched_df.sample(frac=1).reset_index(drop=True).head(sample_size)\n",
    "random_sample\n",
    "\n",
    "# Exporting to CSV format\n",
    "random_sample.to_csv (f\"{output_file_name}_(size {sample_size}).csv\", index=False)\n",
    "\n",
    "# Exporting to JSONL format\n",
    "random_sample.to_json(f\"{output_file_name}_records_(size {sample_size}).jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2d7784-ac59-42b2-9be1-47f09d24bf57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Generative AI evaluation",
   "language": "python",
   "name": "genai_evaluation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
